 [MarkdownContent] Content changed: Thinking
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 
<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 0, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(1), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 0, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "The"
 [LLM API] tagBuffer: The
 [LLM API] Accumulated thinking: 3 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(2), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3, toolingLength: 0, responseLength: 0}
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " user"
 [LLM API] tagBuffer:  user
 [LLM API] Accumulated thinking: 8 chars
 [LLM API] Calling onChunk with: {thinkingLength: 8, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(3), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 8, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 11 chars
 [LLM API] Calling onChunk with: {thinkingLength: 11, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(4), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 11, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " asking"
 [LLM API] tagBuffer:  asking
 [LLM API] Accumulated thinking: 18 chars
 [LLM API] Calling onChunk with: {thinkingLength: 18, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(5), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 18, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " about"
 [LLM API] tagBuffer:  about
 [LLM API] Accumulated thinking: 24 chars
 [LLM API] Calling onChunk with: {thinkingLength: 24, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(6), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 24, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " which"
 [LLM API] tagBuffer:  which
 [LLM API] Accumulated thinking: 30 chars
 [LLM API] Calling onChunk with: {thinkingLength: 30, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(7), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 30, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 40 chars
 [LLM API] Calling onChunk with: {thinkingLength: 40, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(8), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 40, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated thinking: 48 chars
 [LLM API] Calling onChunk with: {thinkingLength: 48, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(9), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 48, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 51 chars
 [LLM API] Calling onChunk with: {thinkingLength: 51, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(10), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 51, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 54 chars
 [LLM API] Calling onChunk with: {thinkingLength: 54, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(11), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 54, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 59 chars
 [LLM API] Calling onChunk with: {thinkingLength: 59, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(12), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 59, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 66 chars
 [LLM API] Calling onChunk with: {thinkingLength: 66, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(13), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 66, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 67 chars
 [LLM API] Calling onChunk with: {thinkingLength: 67, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(14), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 67, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 72 chars
 [LLM API] Calling onChunk with: {thinkingLength: 72, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(15), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 72, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 75 chars
 [LLM API] Calling onChunk with: {thinkingLength: 75, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(16), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 75, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " asking"
 [LLM API] tagBuffer:  asking
 [LLM API] Accumulated thinking: 82 chars
 [LLM API] Calling onChunk with: {thinkingLength: 82, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(17), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 82, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 86 chars
 [LLM API] Calling onChunk with: {thinkingLength: 86, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(18), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 86, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 88 chars
 [LLM API] Calling onChunk with: {thinkingLength: 88, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(19), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 88, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " specific"
 [LLM API] tagBuffer:  specific
 [LLM API] Accumulated thinking: 97 chars
 [LLM API] Calling onChunk with: {thinkingLength: 97, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(20), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 97, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedural"
 [LLM API] tagBuffer:  procedural
 [LLM API] Accumulated thinking: 108 chars
 [LLM API] Calling onChunk with: {thinkingLength: 108, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(21), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 108, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 117 chars
 [LLM API] Calling onChunk with: {thinkingLength: 117, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(22), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 117, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 122 chars
 [LLM API] Calling onChunk with: {thinkingLength: 122, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(23), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 122, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " would"
 [LLM API] tagBuffer:  would
 [LLM API] Accumulated thinking: 128 chars
 [LLM API] Calling onChunk with: {thinkingLength: 128, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(24), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 128, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 131 chars
 [LLM API] Calling onChunk with: {thinkingLength: 131, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(25), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 131, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " managed"
 [LLM API] tagBuffer:  managed
 [LLM API] Accumulated thinking: 139 chars
 [LLM API] Calling onChunk with: {thinkingLength: 139, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(26), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 139, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " through"
 [LLM API] tagBuffer:  through
 [LLM API] Accumulated thinking: 147 chars
 [LLM API] Calling onChunk with: {thinkingLength: 147, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(27), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 147, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 151 chars
 [LLM API] Calling onChunk with: {thinkingLength: 151, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(28), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 151, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " e"
 [LLM API] tagBuffer:  e
 [LLM API] Accumulated thinking: 153 chars
 [LLM API] Calling onChunk with: {thinkingLength: 153, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(29), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 153, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Doc"
 [LLM API] tagBuffer: Doc
 [LLM API] Accumulated thinking: 156 chars
 [LLM API] Calling onChunk with: {thinkingLength: 156, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(30), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 156, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " system"
 [LLM API] tagBuffer:  system
 [LLM API] Accumulated thinking: 163 chars
 [LLM API] Calling onChunk with: {thinkingLength: 163, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(31), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 163, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 164 chars
 [LLM API] Calling onChunk with: {thinkingLength: 164, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(32), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 164, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 166 chars
 [LLM API] Calling onChunk with: {thinkingLength: 166, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(33), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 166, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " should"
 [LLM API] tagBuffer:  should
 [LLM API] Accumulated thinking: 173 chars
 [LLM API] Calling onChunk with: {thinkingLength: 173, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(34), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 173, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 180 chars
 [LLM API] Calling onChunk with: {thinkingLength: 180, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(35), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 180, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 184 chars
 [LLM API] Calling onChunk with: {thinkingLength: 184, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(36), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 184, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 194 chars
 [LLM API] Calling onChunk with: {thinkingLength: 194, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(37), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 194, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 202 chars
 [LLM API] Calling onChunk with: {thinkingLength: 202, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(38), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 202, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 205 chars
 [LLM API] Calling onChunk with: {thinkingLength: 205, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(39), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 205, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 208 chars
 [LLM API] Calling onChunk with: {thinkingLength: 208, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(40), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 208, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 211 chars
 [LLM API] Calling onChunk with: {thinkingLength: 211, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(41), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 211, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 216 chars
 [LLM API] Calling onChunk with: {thinkingLength: 216, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(42), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 216, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 223 chars
 [LLM API] Calling onChunk with: {thinkingLength: 223, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(43), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 223, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 234 chars
 [LLM API] Calling onChunk with: {thinkingLength: 234, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(44), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 234, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 237 chars
 [LLM API] Calling onChunk with: {thinkingLength: 237, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(45), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 237, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Let"
 [LLM API] tagBuffer: Let
 [LLM API] Accumulated thinking: 240 chars
 [LLM API] Calling onChunk with: {thinkingLength: 240, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(46), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 240, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 243 chars
 [LLM API] Calling onChunk with: {thinkingLength: 243, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(47), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 243, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " use"
 [LLM API] tagBuffer:  use
 [LLM API] Accumulated thinking: 247 chars
 [LLM API] Calling onChunk with: {thinkingLength: 247, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(48), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 247, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 251 chars
 [LLM API] Calling onChunk with: {thinkingLength: 251, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(49), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 251, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 258 chars
 [LLM API] Calling onChunk with: {thinkingLength: 258, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(50), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 258, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "doc"
 [LLM API] tagBuffer: doc
 [LLM API] Accumulated thinking: 261 chars
 [LLM API] Calling onChunk with: {thinkingLength: 261, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(51), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 261, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " function"
 [LLM API] tagBuffer:  function
 [LLM API] Accumulated thinking: 270 chars
 [LLM API] Calling onChunk with: {thinkingLength: 270, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(52), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 270, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 273 chars
 [LLM API] Calling onChunk with: {thinkingLength: 273, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(53), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 273, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 280 chars
 [LLM API] Calling onChunk with: {thinkingLength: 280, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(54), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 280, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 284 chars
 [LLM API] Calling onChunk with: {thinkingLength: 284, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(55), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 284, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 294 chars
 [LLM API] Calling onChunk with: {thinkingLength: 294, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(56), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 294, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 302 chars
 [LLM API] Calling onChunk with: {thinkingLength: 302, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(57), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 302, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 305 chars
 [LLM API] Calling onChunk with: {thinkingLength: 305, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(58), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 305, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 308 chars
 [LLM API] Calling onChunk with: {thinkingLength: 308, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(59), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 308, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 311 chars
 [LLM API] Calling onChunk with: {thinkingLength: 311, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(60), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 311, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 316 chars
 [LLM API] Calling onChunk with: {thinkingLength: 316, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(61), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 316, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 323 chars
 [LLM API] Calling onChunk with: {thinkingLength: 323, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(62), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 323, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 324 chars
 [LLM API] Calling onChunk with: {thinkingLength: 324, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(63), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 324, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " specifically"
 [LLM API] tagBuffer:  specifically
 [LLM API] Accumulated thinking: 337 chars
 [LLM API] Calling onChunk with: {thinkingLength: 337, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(64), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 337, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 340 chars
 [LLM API] Calling onChunk with: {thinkingLength: 340, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(65), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 340, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 344 chars
 [LLM API] Calling onChunk with: {thinkingLength: 344, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(66), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 344, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " e"
 [LLM API] tagBuffer:  e
 [LLM API] Accumulated thinking: 346 chars
 [LLM API] Calling onChunk with: {thinkingLength: 346, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(67), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 346, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Doc"
 [LLM API] tagBuffer: Doc
 [LLM API] Accumulated thinking: 349 chars
 [LLM API] Calling onChunk with: {thinkingLength: 349, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(68), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 349, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " collection"
 [LLM API] tagBuffer:  collection
 [LLM API] Accumulated thinking: 360 chars
 [LLM API] Calling onChunk with: {thinkingLength: 360, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(69), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 360, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " since"
 [LLM API] tagBuffer:  since
 [LLM API] Accumulated thinking: 366 chars
 [LLM API] Calling onChunk with: {thinkingLength: 366, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(70), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 366, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 371 chars
 [LLM API] Calling onChunk with: {thinkingLength: 371, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(71), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 371, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " contains"
 [LLM API] tagBuffer:  contains
 [LLM API] Accumulated thinking: 380 chars
 [LLM API] Calling onChunk with: {thinkingLength: 380, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(72), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 380, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " plant"
 [LLM API] tagBuffer:  plant
 [LLM API] Accumulated thinking: 386 chars
 [LLM API] Calling onChunk with: {thinkingLength: 386, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(73), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 386, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-specific"
 [LLM API] tagBuffer: -specific
 [LLM API] Accumulated thinking: 395 chars
 [LLM API] Calling onChunk with: {thinkingLength: 395, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(74), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 395, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 406 chars
 [LLM API] Calling onChunk with: {thinkingLength: 406, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(75), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 406, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 407 chars
 [LLM API] Calling onChunk with: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(76), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(77), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(78), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 407, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: tool: "{\n    \"action\": \"searching for unescort
 [LLM API] FOUND TOOL EVENT, line: tool: "{\n    \"action\": \"searching for unescorted access procedures using the searchdoc function\"\n}"
 [LLM API] Tool string to parse: "{\n    \"action\": \"searching for unescorted access procedures using the searchdoc function\"\n}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'searching for unescorted access procedures using the searchdoc function'}
 [LLM API] toolJson.action value: searching for unescorted access procedures using the searchdoc function
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: searching for unescorted access procedures using the searchdoc function
 [LLM API] Received tool event: searching for unescorted access procedures using the searchdoc function
 [LLM API] Sending chunk after tool event: {thinkingLength: 407, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(79), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 407, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 407, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(80), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 407, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "Based"
 [LLM API] tagBuffer: Based
 [LLM API] Accumulated thinking: 412 chars
 [LLM API] Calling onChunk with: {thinkingLength: 412, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(81), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 412, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated thinking: 415 chars
 [LLM API] Calling onChunk with: {thinkingLength: 415, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(82), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 415, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 419 chars
 [LLM API] Calling onChunk with: {thinkingLength: 419, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(83), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 419, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 426 chars
 [LLM API] Calling onChunk with: {thinkingLength: 426, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(84), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 426, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 434 chars
 [LLM API] Calling onChunk with: {thinkingLength: 434, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(85), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 434, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 435 chars
 [LLM API] Calling onChunk with: {thinkingLength: 435, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(86), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 435, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 437 chars
 [LLM API] Calling onChunk with: {thinkingLength: 437, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(87), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 437, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " can"
 [LLM API] tagBuffer:  can
 [LLM API] Accumulated thinking: 441 chars
 [LLM API] Calling onChunk with: {thinkingLength: 441, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(88), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 441, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 445 chars
 [LLM API] Calling onChunk with: {thinkingLength: 445, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(89), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 445, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " several"
 [LLM API] tagBuffer:  several
 [LLM API] Accumulated thinking: 453 chars
 [LLM API] Calling onChunk with: {thinkingLength: 453, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(90), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 453, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 463 chars
 [LLM API] Calling onChunk with: {thinkingLength: 463, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(91), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 463, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 471 chars
 [LLM API] Calling onChunk with: {thinkingLength: 471, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(92), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 471, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 474 chars
 [LLM API] Calling onChunk with: {thinkingLength: 474, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(93), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 474, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 477 chars
 [LLM API] Calling onChunk with: {thinkingLength: 477, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(94), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 477, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 480 chars
 [LLM API] Calling onChunk with: {thinkingLength: 480, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(95), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 480, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 485 chars
 [LLM API] Calling onChunk with: {thinkingLength: 485, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(96), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 485, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 492 chars
 [LLM API] Calling onChunk with: {thinkingLength: 492, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(97), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 492, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 503 chars
 [LLM API] Calling onChunk with: {thinkingLength: 503, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(98), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 503, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 504 chars
 [LLM API] Calling onChunk with: {thinkingLength: 504, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(99), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 504, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 508 chars
 [LLM API] Calling onChunk with: {thinkingLength: 508, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(100), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 508, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 511 chars
 [LLM API] Calling onChunk with: {thinkingLength: 511, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(101), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 511, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " analyze"
 [LLM API] tagBuffer:  analyze
 [LLM API] Accumulated thinking: 519 chars
 [LLM API] Calling onChunk with: {thinkingLength: 519, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(102), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 519, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " what"
 [LLM API] tagBuffer:  what
 [LLM API] Accumulated thinking: 524 chars
 [LLM API] Calling onChunk with: {thinkingLength: 524, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(103), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 524, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 526 chars
 [LLM API] Calling onChunk with: {thinkingLength: 526, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(104), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 526, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 532 chars
 [LLM API] Calling onChunk with: {thinkingLength: 532, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(105), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 532, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 535 chars
 [LLM API] Calling onChunk with: {thinkingLength: 535, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(106), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 535, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 536 chars
 [LLM API] Calling onChunk with: {thinkingLength: 536, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(107), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 536, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 537 chars
 [LLM API] Calling onChunk with: {thinkingLength: 537, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(108), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 537, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 540 chars
 [LLM API] Calling onChunk with: {thinkingLength: 540, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(109), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 540, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 542 chars
 [LLM API] Calling onChunk with: {thinkingLength: 542, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(110), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 542, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 544 chars
 [LLM API] Calling onChunk with: {thinkingLength: 544, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(111), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 544, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 545 chars
 [LLM API] Calling onChunk with: {thinkingLength: 545, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(112), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 545, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 546 chars
 [LLM API] Calling onChunk with: {thinkingLength: 546, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(113), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 546, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 548 chars
 [LLM API] Calling onChunk with: {thinkingLength: 548, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(114), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 548, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 550 chars
 [LLM API] Calling onChunk with: {thinkingLength: 550, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(115), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 550, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 551 chars
 [LLM API] Calling onChunk with: {thinkingLength: 551, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(116), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 551, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 555 chars
 [LLM API] Calling onChunk with: {thinkingLength: 555, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(117), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 555, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 556 chars
 [LLM API] Calling onChunk with: {thinkingLength: 556, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(118), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 556, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 557 chars
 [LLM API] Calling onChunk with: {thinkingLength: 557, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(119), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 557, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 558 chars
 [LLM API] Calling onChunk with: {thinkingLength: 558, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(120), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 558, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 560 chars
 [LLM API] Calling onChunk with: {thinkingLength: 560, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(121), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 560, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 562 chars
 [LLM API] Calling onChunk with: {thinkingLength: 562, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(122), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 562, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 564 chars
 [LLM API] Calling onChunk with: {thinkingLength: 564, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(123), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 564, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 566 chars
 [LLM API] Calling onChunk with: {thinkingLength: 566, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(124), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 566, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "BACKGROUND"
 [LLM API] tagBuffer: BACKGROUND
 [LLM API] Accumulated thinking: 576 chars
 [LLM API] Calling onChunk with: {thinkingLength: 576, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(125), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 576, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " IN"
 [LLM API] tagBuffer:  IN
 [LLM API] Accumulated thinking: 579 chars
 [LLM API] Calling onChunk with: {thinkingLength: 579, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(126), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 579, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "VEST"
 [LLM API] tagBuffer: VEST
 [LLM API] Accumulated thinking: 583 chars
 [LLM API] Calling onChunk with: {thinkingLength: 583, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(127), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 583, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "IG"
 [LLM API] tagBuffer: IG
 [LLM API] Accumulated thinking: 585 chars
 [LLM API] Calling onChunk with: {thinkingLength: 585, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(128), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 585, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ATIONS"
 [LLM API] tagBuffer: ATIONS
 [LLM API] Accumulated thinking: 591 chars
 [LLM API] Calling onChunk with: {thinkingLength: 591, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(129), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 591, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " FOR"
 [LLM API] tagBuffer:  FOR
 [LLM API] Accumulated thinking: 595 chars
 [LLM API] Calling onChunk with: {thinkingLength: 595, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(130), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 595, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " UN"
 [LLM API] tagBuffer:  UN
 [LLM API] Accumulated thinking: 598 chars
 [LLM API] Calling onChunk with: {thinkingLength: 598, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(131), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 598, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ESC"
 [LLM API] tagBuffer: ESC
 [LLM API] Accumulated thinking: 601 chars
 [LLM API] Calling onChunk with: {thinkingLength: 601, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(132), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 601, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ORT"
 [LLM API] tagBuffer: ORT
 [LLM API] Accumulated thinking: 604 chars
 [LLM API] Calling onChunk with: {thinkingLength: 604, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(133), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 604, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ED"
 [LLM API] tagBuffer: ED
 [LLM API] Accumulated thinking: 606 chars
 [LLM API] Calling onChunk with: {thinkingLength: 606, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(134), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 606, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " ACCESS"
 [LLM API] tagBuffer:  ACCESS
 [LLM API] Accumulated thinking: 613 chars
 [LLM API] Calling onChunk with: {thinkingLength: 613, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(135), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 613, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 614 chars
 [LLM API] Calling onChunk with: {thinkingLength: 614, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(136), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 614, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 616 chars
 [LLM API] Calling onChunk with: {thinkingLength: 616, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(137), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 616, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 621 chars
 [LLM API] Calling onChunk with: {thinkingLength: 621, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(138), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 621, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 629 chars
 [LLM API] Calling onChunk with: {thinkingLength: 629, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(139), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 629, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 632 chars
 [LLM API] Calling onChunk with: {thinkingLength: 632, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(140), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 632, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 635 chars
 [LLM API] Calling onChunk with: {thinkingLength: 635, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(141), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 635, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 639 chars
 [LLM API] Calling onChunk with: {thinkingLength: 639, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(142), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 639, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " main"
 [LLM API] tagBuffer:  main
 [LLM API] Accumulated thinking: 644 chars
 [LLM API] Calling onChunk with: {thinkingLength: 644, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(143), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 644, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 654 chars
 [LLM API] Calling onChunk with: {thinkingLength: 654, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(144), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 654, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 659 chars
 [LLM API] Calling onChunk with: {thinkingLength: 659, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(145), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 659, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated thinking: 667 chars
 [LLM API] Calling onChunk with: {thinkingLength: 667, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(146), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 667, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 670 chars
 [LLM API] Calling onChunk with: {thinkingLength: 670, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(147), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 670, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 673 chars
 [LLM API] Calling onChunk with: {thinkingLength: 673, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(148), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 673, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 678 chars
 [LLM API] Calling onChunk with: {thinkingLength: 678, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(149), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 678, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 685 chars
 [LLM API] Calling onChunk with: {thinkingLength: 685, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(150), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 685, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated thinking: 700 chars
 [LLM API] Calling onChunk with: {thinkingLength: 700, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(151), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 700, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 703 chars
 [LLM API] Calling onChunk with: {thinkingLength: 703, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(152), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 703, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 704 chars
 [LLM API] Calling onChunk with: {thinkingLength: 704, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(153), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 704, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 705 chars
 [LLM API] Calling onChunk with: {thinkingLength: 705, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(154), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 705, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 708 chars
 [LLM API] Calling onChunk with: {thinkingLength: 708, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(155), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 708, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 710 chars
 [LLM API] Calling onChunk with: {thinkingLength: 710, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(156), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 710, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 712 chars
 [LLM API] Calling onChunk with: {thinkingLength: 712, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(157), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 712, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 713 chars
 [LLM API] Calling onChunk with: {thinkingLength: 713, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(158), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 713, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 714 chars
 [LLM API] Calling onChunk with: {thinkingLength: 714, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(159), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 714, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 716 chars
 [LLM API] Calling onChunk with: {thinkingLength: 716, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(160), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 716, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated thinking: 718 chars
 [LLM API] Calling onChunk with: {thinkingLength: 718, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(161), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 718, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 719 chars
 [LLM API] Calling onChunk with: {thinkingLength: 719, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(162), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 719, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 723 chars
 [LLM API] Calling onChunk with: {thinkingLength: 723, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(163), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 723, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 724 chars
 [LLM API] Calling onChunk with: {thinkingLength: 724, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(164), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 724, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 725 chars
 [LLM API] Calling onChunk with: {thinkingLength: 725, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(165), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 725, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "03"
 [LLM API] tagBuffer: 03
 [LLM API] Accumulated thinking: 727 chars
 [LLM API] Calling onChunk with: {thinkingLength: 727, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(166), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 727, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "9"
 [LLM API] tagBuffer: 9
 [LLM API] Accumulated thinking: 728 chars
 [LLM API] Calling onChunk with: {thinkingLength: 728, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(167), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 728, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 730 chars
 [LLM API] Calling onChunk with: {thinkingLength: 730, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(168), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 730, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 732 chars
 [LLM API] Calling onChunk with: {thinkingLength: 732, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(169), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 732, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 734 chars
 [LLM API] Calling onChunk with: {thinkingLength: 734, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(170), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 734, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "PAL"
 [LLM API] tagBuffer: PAL
 [LLM API] Accumulated thinking: 737 chars
 [LLM API] Calling onChunk with: {thinkingLength: 737, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(171), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 737, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "O"
 [LLM API] tagBuffer: O
 [LLM API] Accumulated thinking: 738 chars
 [LLM API] Calling onChunk with: {thinkingLength: 738, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(172), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 738, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " VER"
 [LLM API] tagBuffer:  VER
 [LLM API] Accumulated thinking: 742 chars
 [LLM API] Calling onChunk with: {thinkingLength: 742, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(173), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 742, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DE"
 [LLM API] tagBuffer: DE
 [LLM API] Accumulated thinking: 744 chars
 [LLM API] Calling onChunk with: {thinkingLength: 744, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(174), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 744, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " BAD"
 [LLM API] tagBuffer:  BAD
 [LLM API] Accumulated thinking: 748 chars
 [LLM API] Calling onChunk with: {thinkingLength: 748, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(175), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 748, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "GING"
 [LLM API] tagBuffer: GING
 [LLM API] Accumulated thinking: 752 chars
 [LLM API] Calling onChunk with: {thinkingLength: 752, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(176), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 752, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " PROC"
 [LLM API] tagBuffer:  PROC
 [LLM API] Accumulated thinking: 757 chars
 [LLM API] Calling onChunk with: {thinkingLength: 757, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(177), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 757, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "EDURE"
 [LLM API] tagBuffer: EDURE
 [LLM API] Accumulated thinking: 762 chars
 [LLM API] Calling onChunk with: {thinkingLength: 762, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(178), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 762, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 763 chars
 [LLM API] Calling onChunk with: {thinkingLength: 763, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(179), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 763, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 765 chars
 [LLM API] Calling onChunk with: {thinkingLength: 765, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(180), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 765, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 770 chars
 [LLM API] Calling onChunk with: {thinkingLength: 770, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(181), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 770, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 780 chars
 [LLM API] Calling onChunk with: {thinkingLength: 780, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(182), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 780, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " deals"
 [LLM API] tagBuffer:  deals
 [LLM API] Accumulated thinking: 786 chars
 [LLM API] Calling onChunk with: {thinkingLength: 786, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(183), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 786, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 791 chars
 [LLM API] Calling onChunk with: {thinkingLength: 791, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(184), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 791, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " bad"
 [LLM API] tagBuffer:  bad
 [LLM API] Accumulated thinking: 795 chars
 [LLM API] Calling onChunk with: {thinkingLength: 795, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(185), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 795, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated thinking: 799 chars
 [LLM API] Calling onChunk with: {thinkingLength: 799, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(186), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 799, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 803 chars
 [LLM API] Calling onChunk with: {thinkingLength: 803, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(187), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 803, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " credential"
 [LLM API] tagBuffer:  credential
 [LLM API] Accumulated thinking: 814 chars
 [LLM API] Calling onChunk with: {thinkingLength: 814, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(188), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 814, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " management"
 [LLM API] tagBuffer:  management
 [LLM API] Accumulated thinking: 825 chars
 [LLM API] Calling onChunk with: {thinkingLength: 825, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(189), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 825, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 829 chars
 [LLM API] Calling onChunk with: {thinkingLength: 829, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(190), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 829, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 836 chars
 [LLM API] Calling onChunk with: {thinkingLength: 836, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(191), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 836, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 837 chars
 [LLM API] Calling onChunk with: {thinkingLength: 837, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(192), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 837, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " including"
 [LLM API] tagBuffer:  including
 [LLM API] Accumulated thinking: 847 chars
 [LLM API] Calling onChunk with: {thinkingLength: 847, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(193), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 847, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 850 chars
 [LLM API] Calling onChunk with: {thinkingLength: 850, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(194), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 850, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 853 chars
 [LLM API] Calling onChunk with: {thinkingLength: 853, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(195), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 853, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 858 chars
 [LLM API] Calling onChunk with: {thinkingLength: 858, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(196), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 858, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 865 chars
 [LLM API] Calling onChunk with: {thinkingLength: 865, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(197), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 865, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 868 chars
 [LLM API] Calling onChunk with: {thinkingLength: 868, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(198), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 868, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 869 chars
 [LLM API] Calling onChunk with: {thinkingLength: 869, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(199), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 869, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 870 chars
 [LLM API] Calling onChunk with: {thinkingLength: 870, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(200), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 870, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 873 chars
 [LLM API] Calling onChunk with: {thinkingLength: 873, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(201), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 873, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 875 chars
 [LLM API] Calling onChunk with: {thinkingLength: 875, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(202), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 875, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 877 chars
 [LLM API] Calling onChunk with: {thinkingLength: 877, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(203), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 877, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 878 chars
 [LLM API] Calling onChunk with: {thinkingLength: 878, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(204), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 878, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 879 chars
 [LLM API] Calling onChunk with: {thinkingLength: 879, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(205), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 879, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 881 chars
 [LLM API] Calling onChunk with: {thinkingLength: 881, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(206), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 881, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 883 chars
 [LLM API] Calling onChunk with: {thinkingLength: 883, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(207), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 883, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 884 chars
 [LLM API] Calling onChunk with: {thinkingLength: 884, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(208), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 884, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 888 chars
 [LLM API] Calling onChunk with: {thinkingLength: 888, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(209), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 888, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 889 chars
 [LLM API] Calling onChunk with: {thinkingLength: 889, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(210), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 889, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 890 chars
 [LLM API] Calling onChunk with: {thinkingLength: 890, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(211), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 890, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 891 chars
 [LLM API] Calling onChunk with: {thinkingLength: 891, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(212), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 891, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "30"
 [LLM API] tagBuffer: 30
 [LLM API] Accumulated thinking: 893 chars
 [LLM API] Calling onChunk with: {thinkingLength: 893, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(213), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 893, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 895 chars
 [LLM API] Calling onChunk with: {thinkingLength: 895, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(214), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 895, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 897 chars
 [LLM API] Calling onChunk with: {thinkingLength: 897, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(215), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 897, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 899 chars
 [LLM API] Calling onChunk with: {thinkingLength: 899, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(216), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 899, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "PV"
 [LLM API] tagBuffer: PV
 [LLM API] Accumulated thinking: 901 chars
 [LLM API] Calling onChunk with: {thinkingLength: 901, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(217), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 901, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "NG"
 [LLM API] tagBuffer: NG
 [LLM API] Accumulated thinking: 903 chars
 [LLM API] Calling onChunk with: {thinkingLength: 903, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(218), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 903, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "S"
 [LLM API] tagBuffer: S
 [LLM API] Accumulated thinking: 904 chars
 [LLM API] Calling onChunk with: {thinkingLength: 904, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(219), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 904, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " UN"
 [LLM API] tagBuffer:  UN
 [LLM API] Accumulated thinking: 907 chars
 [LLM API] Calling onChunk with: {thinkingLength: 907, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(220), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 907, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ESC"
 [LLM API] tagBuffer: ESC
 [LLM API] Accumulated thinking: 910 chars
 [LLM API] Calling onChunk with: {thinkingLength: 910, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(221), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 910, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ORT"
 [LLM API] tagBuffer: ORT
 [LLM API] Accumulated thinking: 913 chars
 [LLM API] Calling onChunk with: {thinkingLength: 913, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(222), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 913, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ED"
 [LLM API] tagBuffer: ED
 [LLM API] Accumulated thinking: 915 chars
 [LLM API] Calling onChunk with: {thinkingLength: 915, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(223), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 915, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " ACCESS"
 [LLM API] tagBuffer:  ACCESS
 [LLM API] Accumulated thinking: 922 chars
 [LLM API] Calling onChunk with: {thinkingLength: 922, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(224), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 922, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " SCREEN"
 [LLM API] tagBuffer:  SCREEN
 [LLM API] Accumulated thinking: 929 chars
 [LLM API] Calling onChunk with: {thinkingLength: 929, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(225), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 929, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ING"
 [LLM API] tagBuffer: ING
 [LLM API] Accumulated thinking: 932 chars
 [LLM API] Calling onChunk with: {thinkingLength: 932, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(226), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 932, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 933 chars
 [LLM API] Calling onChunk with: {thinkingLength: 933, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(227), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 933, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 935 chars
 [LLM API] Calling onChunk with: {thinkingLength: 935, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(228), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 935, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 940 chars
 [LLM API] Calling onChunk with: {thinkingLength: 940, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(229), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 940, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 948 chars
 [LLM API] Calling onChunk with: {thinkingLength: 948, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(230), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 948, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 951 chars
 [LLM API] Calling onChunk with: {thinkingLength: 951, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(231), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 951, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 954 chars
 [LLM API] Calling onChunk with: {thinkingLength: 954, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(232), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 954, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " another"
 [LLM API] tagBuffer:  another
 [LLM API] Accumulated thinking: 962 chars
 [LLM API] Calling onChunk with: {thinkingLength: 962, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(233), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 962, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated thinking: 966 chars
 [LLM API] Calling onChunk with: {thinkingLength: 966, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(234), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 966, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 976 chars
 [LLM API] Calling onChunk with: {thinkingLength: 976, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(235), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 976, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 980 chars
 [LLM API] Calling onChunk with: {thinkingLength: 980, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(236), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 980, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 983 chars
 [LLM API] Calling onChunk with: {thinkingLength: 983, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(237), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 983, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 986 chars
 [LLM API] Calling onChunk with: {thinkingLength: 986, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(238), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 986, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 991 chars
 [LLM API] Calling onChunk with: {thinkingLength: 991, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(239), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 991, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 998 chars
 [LLM API] Calling onChunk with: {thinkingLength: 998, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(240), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 998, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " screening"
 [LLM API] tagBuffer:  screening
 [LLM API] Accumulated thinking: 1008 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1008, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(241), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1008, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 1011 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1011, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(242), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1011, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "4"
 [LLM API] tagBuffer: 4
 [LLM API] Accumulated thinking: 1012 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1012, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(243), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1012, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1013 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1013, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(244), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1013, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1016 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1016, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(245), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1016, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1018 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1018, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(246), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1018, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1020 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1020, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(247), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1020, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1021 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1021, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(248), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1021, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1022 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1022, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(249), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1022, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1024 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1024, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(250), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1024, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "46"
 [LLM API] tagBuffer: 46
 [LLM API] Accumulated thinking: 1026 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1026, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(251), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1026, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1027 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1027, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(252), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1027, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 1031 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1031, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(253), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1031, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1032 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1032, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(254), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1032, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1033 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1033, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(255), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1033, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1034 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1034, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(256), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1034, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 1036 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1036, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(257), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1036, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1038 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1038, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(258), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1038, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1040 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1040, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(259), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1040, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 1042 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1042, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(260), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1042, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "Person"
 [LLM API] tagBuffer: Person
 [LLM API] Accumulated thinking: 1048 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1048, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(261), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1048, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "nel"
 [LLM API] tagBuffer: nel
 [LLM API] Accumulated thinking: 1051 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1051, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(262), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1051, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1058 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1058, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(263), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1058, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Data"
 [LLM API] tagBuffer:  Data
 [LLM API] Accumulated thinking: 1063 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1063, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(264), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1063, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " System"
 [LLM API] tagBuffer:  System
 [LLM API] Accumulated thinking: 1070 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1070, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(265), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1070, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1072 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1072, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(266), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1072, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "PAD"
 [LLM API] tagBuffer: PAD
 [LLM API] Accumulated thinking: 1075 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1075, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(267), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1075, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "S"
 [LLM API] tagBuffer: S
 [LLM API] Accumulated thinking: 1076 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1076, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(268), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1076, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 1077 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1077, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(269), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1077, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Process"
 [LLM API] tagBuffer:  Process
 [LLM API] Accumulated thinking: 1085 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1085, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(270), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1085, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1086 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1086, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(271), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1086, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1088 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1088, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(272), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1088, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 1093 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1093, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(273), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1093, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " includes"
 [LLM API] tagBuffer:  includes
 [LLM API] Accumulated thinking: 1102 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1102, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(274), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1102, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " definitions"
 [LLM API] tagBuffer:  definitions
 [LLM API] Accumulated thinking: 1114 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1114, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(275), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1114, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1118 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1118, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(276), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1118, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " processes"
 [LLM API] tagBuffer:  processes
 [LLM API] Accumulated thinking: 1128 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1128, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(277), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1128, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 1136 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1136, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(278), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1136, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1139 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1139, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(279), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1139, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 1142 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1142, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(280), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1142, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1145 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1145, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(281), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1145, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1150 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1150, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(282), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1150, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1157 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1157, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(283), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1157, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 1160 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1160, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(284), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1160, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "From"
 [LLM API] tagBuffer: From
 [LLM API] Accumulated thinking: 1164 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1164, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(285), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1164, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1168 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1168, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(286), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1168, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 1175 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1175, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(287), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1175, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 1183 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1183, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(288), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1183, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1184 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1184, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(289), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1184, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " it"
 [LLM API] tagBuffer:  it
 [LLM API] Accumulated thinking: 1187 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1187, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(290), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1187, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 1195 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1195, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(291), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1195, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 1200 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1200, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(292), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1200, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated thinking: 1206 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1206, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(293), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1206, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 1210 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1210, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(294), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1210, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " multiple"
 [LLM API] tagBuffer:  multiple
 [LLM API] Accumulated thinking: 1219 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1219, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(295), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1219, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 1230 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1230, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(296), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1230, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " involved"
 [LLM API] tagBuffer:  involved
 [LLM API] Accumulated thinking: 1239 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1239, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(297), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1239, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 1242 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1242, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(298), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1242, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " managing"
 [LLM API] tagBuffer:  managing
 [LLM API] Accumulated thinking: 1251 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1251, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(299), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1251, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 1254 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1254, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(300), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1254, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1257 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1257, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(301), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1257, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1262 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1262, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(302), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1262, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1269 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1269, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(303), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1269, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1270 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1270, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(304), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1270, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " but"
 [LLM API] tagBuffer:  but
 [LLM API] Accumulated thinking: 1274 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1274, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(305), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1274, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1278 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1278, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(306), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1278, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " most"
 [LLM API] tagBuffer:  most
 [LLM API] Accumulated thinking: 1283 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1283, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(307), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1283, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 1297 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1297, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(308), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1297, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1301 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1301, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(309), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1301, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " directly"
 [LLM API] tagBuffer:  directly
 [LLM API] Accumulated thinking: 1310 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1310, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(310), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1310, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 1318 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1318, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(311), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1318, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " seem"
 [LLM API] tagBuffer:  seem
 [LLM API] Accumulated thinking: 1323 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1323, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(312), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1323, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1326 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1326, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(313), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1326, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 1329 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1329, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(314), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1329, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 1332 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1332, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(315), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1332, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 1333 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1333, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(316), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1333, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1334 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1334, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(317), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1334, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1337 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1337, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(318), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1337, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1339 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1339, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(319), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1339, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1341 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1341, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(320), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1341, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1342 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1342, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(321), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1342, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1343 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1343, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(322), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1343, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1345 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1345, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(323), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1345, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 1347 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1347, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(324), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1347, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1349 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1349, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(325), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1349, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1351 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1351, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(326), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1351, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Background"
 [LLM API] tagBuffer:  Background
 [LLM API] Accumulated thinking: 1362 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1362, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(327), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1362, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated thinking: 1377 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1377, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(328), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1377, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1381 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1381, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(329), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1381, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 1384 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1384, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(330), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1384, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1387 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1387, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(331), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1387, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1392 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1392, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(332), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1392, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1399 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1399, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(333), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1399, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated thinking: 1400 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1400, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(334), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1400, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 1401 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1401, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(335), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1401, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1402 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1402, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(336), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1402, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1405 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1405, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(337), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1405, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1407 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1407, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(338), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1407, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1409 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1409, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(339), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1409, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1410 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1410, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(340), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1410, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1411 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1411, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(341), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1411, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1413 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1413, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(342), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1413, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated thinking: 1415 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1415, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(343), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1415, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1417 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1417, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(344), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1417, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1419 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1419, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(345), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1419, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated thinking: 1424 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1424, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(346), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1424, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 1430 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1430, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(347), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1430, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Bad"
 [LLM API] tagBuffer:  Bad
 [LLM API] Accumulated thinking: 1434 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1434, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(348), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1434, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated thinking: 1438 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1438, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(349), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1438, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Procedure"
 [LLM API] tagBuffer:  Procedure
 [LLM API] Accumulated thinking: 1448 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1448, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(350), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1448, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \n"
 [LLM API] tagBuffer:  

 [LLM API] Accumulated thinking: 1450 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1450, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(351), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1450, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 1451 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1451, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(352), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1451, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1452 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1452, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(353), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1452, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1455 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1455, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(354), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1455, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1457 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1457, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(355), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1457, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1459 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1459, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(356), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1459, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1460 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1460, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(357), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1460, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1461 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1461, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(358), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1461, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1463 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1463, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(359), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1463, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 1465 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1465, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(360), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1465, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1467 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1467, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(361), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1467, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1469 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1469, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(362), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1469, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " PV"
 [LLM API] tagBuffer:  PV
 [LLM API] Accumulated thinking: 1472 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1472, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(363), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1472, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "NG"
 [LLM API] tagBuffer: NG
 [LLM API] Accumulated thinking: 1474 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1474, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(364), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1474, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "S"
 [LLM API] tagBuffer: S
 [LLM API] Accumulated thinking: 1475 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1475, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(365), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1475, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 1478 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1478, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(366), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1478, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1481 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1481, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(367), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1481, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1486 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1486, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(368), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1486, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1493 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1493, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(369), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1493, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Screening"
 [LLM API] tagBuffer:  Screening
 [LLM API] Accumulated thinking: 1503 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1503, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(370), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1503, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\n\n"
 [LLM API] tagBuffer: 


 [LLM API] Accumulated thinking: 1505 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1505, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(371), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1505, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "However"
 [LLM API] tagBuffer: However
 [LLM API] Accumulated thinking: 1512 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1512, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(372), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1512, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1513 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1513, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(373), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1513, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1516 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1516, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(374), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1516, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 1519 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1519, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(375), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1519, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " thorough"
 [LLM API] tagBuffer:  thorough
 [LLM API] Accumulated thinking: 1528 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1528, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(376), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1528, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1529 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1529, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(377), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1529, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 1531 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1531, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(378), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1531, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " should"
 [LLM API] tagBuffer:  should
 [LLM API] Accumulated thinking: 1538 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1538, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(379), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1538, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " check"
 [LLM API] tagBuffer:  check
 [LLM API] Accumulated thinking: 1544 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1544, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(380), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1544, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " if"
 [LLM API] tagBuffer:  if
 [LLM API] Accumulated thinking: 1547 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1547, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(381), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1547, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated thinking: 1553 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1553, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(382), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1553, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 1557 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1557, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(383), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1557, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " any"
 [LLM API] tagBuffer:  any
 [LLM API] Accumulated thinking: 1561 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1561, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(384), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1561, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " other"
 [LLM API] tagBuffer:  other
 [LLM API] Accumulated thinking: 1567 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1567, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(385), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1567, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 1578 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1578, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(386), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1578, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 1583 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1583, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(387), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1583, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " might"
 [LLM API] tagBuffer:  might
 [LLM API] Accumulated thinking: 1589 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1589, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(388), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1589, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 1592 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1592, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(389), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1592, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " considered"
 [LLM API] tagBuffer:  considered
 [LLM API] Accumulated thinking: 1603 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1603, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(390), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1603, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1607 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1607, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(391), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1607, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " primary"
 [LLM API] tagBuffer:  primary
 [LLM API] Accumulated thinking: 1615 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1615, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(392), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1615, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 1617 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1617, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(393), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1617, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "man"
 [LLM API] tagBuffer: man
 [LLM API] Accumulated thinking: 1620 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1620, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(394), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1620, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "aging"
 [LLM API] tagBuffer: aging
 [LLM API] Accumulated thinking: 1625 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1625, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(395), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1625, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1626 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1626, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(396), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1626, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 1636 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1636, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(397), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1636, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1637 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1637, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(398), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1637, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 1641 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1641, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(399), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1641, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 1644 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1644, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(400), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1644, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 1651 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1651, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(401), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1651, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1655 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1655, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(402), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1655, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " more"
 [LLM API] tagBuffer:  more
 [LLM API] Accumulated thinking: 1660 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1660, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(403), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1660, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " specific"
 [LLM API] tagBuffer:  specific
 [LLM API] Accumulated thinking: 1669 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1669, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(404), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1669, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " terms"
 [LLM API] tagBuffer:  terms
 [LLM API] Accumulated thinking: 1675 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1675, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(405), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1675, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1678 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1678, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(406), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1678, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 1682 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1682, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(407), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1682, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " if"
 [LLM API] tagBuffer:  if
 [LLM API] Accumulated thinking: 1685 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1685, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(408), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1685, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated thinking: 1691 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1691, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(409), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1691, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "'s"
 [LLM API] tagBuffer: 's
 [LLM API] Accumulated thinking: 1693 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1693, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(410), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1693, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 1695 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1695, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(411), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1695, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " higher"
 [LLM API] tagBuffer:  higher
 [LLM API] Accumulated thinking: 1702 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1702, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(412), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1702, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "-level"
 [LLM API] tagBuffer: -level
 [LLM API] Accumulated thinking: 1708 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1708, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(413), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1708, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 1718 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1718, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(414), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1718, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 1723 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1723, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(415), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1723, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " coordinates"
 [LLM API] tagBuffer:  coordinates
 [LLM API] Accumulated thinking: 1735 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1735, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(416), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1735, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " these"
 [LLM API] tagBuffer:  these
 [LLM API] Accumulated thinking: 1741 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1741, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(417), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1741, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: " activities"
 [LLM API] tagBuffer:  activities
 [LLM API] Accumulated thinking: 1752 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1752, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(418), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1752, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1753 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(419), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(420), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(421), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1753, toolingLength: 71, responseLength: 0}
 [LLM API] Processing line: tool: "{\"action\": \"searching for additional une
 [LLM API] FOUND TOOL EVENT, line: tool: "{\"action\": \"searching for additional unescorted access procedures\"}"
 [LLM API] Tool string to parse: "{\"action\": \"searching for additional unescorted access procedures\"}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'searching for additional unescorted access procedures'}
 [LLM API] toolJson.action value: searching for additional unescorted access procedures
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: searching for additional unescorted access procedures
 [LLM API] Received tool event: searching for additional unescorted access procedures
 [LLM API] Sending chunk after tool event: {thinkingLength: 1753, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(422), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1753, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 1753, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(423), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1753, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "Now"
 [LLM API] tagBuffer: Now
 [LLM API] Accumulated thinking: 1756 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1756, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(424), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1756, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 1758 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1758, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(425), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1758, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " have"
 [LLM API] tagBuffer:  have
 [LLM API] Accumulated thinking: 1763 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1763, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(426), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1763, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " more"
 [LLM API] tagBuffer:  more
 [LLM API] Accumulated thinking: 1768 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1768, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(427), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1768, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " information"
 [LLM API] tagBuffer:  information
 [LLM API] Accumulated thinking: 1780 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1780, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(428), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1780, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " about"
 [LLM API] tagBuffer:  about
 [LLM API] Accumulated thinking: 1786 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1786, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(429), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1786, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1793 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1793, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(430), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1793, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " authorization"
 [LLM API] tagBuffer:  authorization
 [LLM API] Accumulated thinking: 1807 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1807, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(431), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1807, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 1818 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1818, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(432), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1818, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1819 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1819, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(433), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1819, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 1823 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1823, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(434), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1823, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 1826 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1826, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(435), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1826, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 1833 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1833, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(436), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1833, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " specifically"
 [LLM API] tagBuffer:  specifically
 [LLM API] Accumulated thinking: 1846 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1846, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(437), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1846, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1850 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1850, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(438), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1850, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1854 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1854, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(439), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1854, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 1856 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1856, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(440), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1856, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "Access"
 [LLM API] tagBuffer: Access
 [LLM API] Accumulated thinking: 1862 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1862, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(441), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1862, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated thinking: 1876 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1876, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(442), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1876, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1877 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1877, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(443), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1877, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 1887 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1887, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(444), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1887, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 1892 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1892, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(445), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1892, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " seems"
 [LLM API] tagBuffer:  seems
 [LLM API] Accumulated thinking: 1898 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1898, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(446), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1898, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1901 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1901, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(447), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1901, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 1904 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1904, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(448), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1904, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1908 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1908, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(449), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1908, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " main"
 [LLM API] tagBuffer:  main
 [LLM API] Accumulated thinking: 1913 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1913, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(450), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1913, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 1923 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1923, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(451), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1923, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " referenced"
 [LLM API] tagBuffer:  referenced
 [LLM API] Accumulated thinking: 1934 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1934, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(452), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1934, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " multiple"
 [LLM API] tagBuffer:  multiple
 [LLM API] Accumulated thinking: 1943 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1943, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(453), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1943, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: " times"
 [LLM API] tagBuffer:  times
 [LLM API] Accumulated thinking: 1949 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1949, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(454), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1949, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1950 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(455), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(456), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(457), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1950, toolingLength: 53, responseLength: 0}
 [LLM API] Processing line: tool: "{\"action\": \"searching for specific proce
 [LLM API] FOUND TOOL EVENT, line: tool: "{\"action\": \"searching for specific procedure\"}"
 [LLM API] Tool string to parse: "{\"action\": \"searching for specific procedure\"}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'searching for specific procedure'}
 [LLM API] toolJson.action value: searching for specific procedure
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: searching for specific procedure
 [LLM API] Received tool event: searching for specific procedure
 [LLM API] Sending chunk after tool event: {thinkingLength: 1950, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(458), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1950, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 1950, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(459), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1950, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "Now"
 [LLM API] tagBuffer: Now
 [LLM API] Accumulated thinking: 1953 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1953, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(460), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1953, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 1955 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1955, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(461), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1955, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " have"
 [LLM API] tagBuffer:  have
 [LLM API] Accumulated thinking: 1960 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1960, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(462), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1960, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 1966 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1966, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(463), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1966, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1970 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1970, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(464), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1970, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated thinking: 1974 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1974, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(465), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1974, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 1983 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1983, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(466), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1983, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1984 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1984, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(467), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1984, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 1988 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1988, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(468), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1988, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 1991 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1991, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(469), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1991, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 1998 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1998, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(470), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1998, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " specifically"
 [LLM API] tagBuffer:  specifically
 [LLM API] Accumulated thinking: 2011 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2011, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(471), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2011, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2015 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2015, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(472), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2015, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2019 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2019, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(473), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2019, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 2020 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2020, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(474), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2020, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2022 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2022, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(475), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2022, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2024 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2024, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(476), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2024, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2025 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2025, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(477), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2025, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2026 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2026, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(478), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2026, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2028 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2028, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(479), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2028, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 2030 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2030, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(480), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2030, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 2039 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2039, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(481), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2039, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2042 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2042, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(482), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2042, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " get"
 [LLM API] tagBuffer:  get
 [LLM API] Accumulated thinking: 2046 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2046, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(483), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2046, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " its"
 [LLM API] tagBuffer:  its
 [LLM API] Accumulated thinking: 2050 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2050, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(484), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2050, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 2057 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2057, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(485), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2057, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2066 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2066, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(486), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2066, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " information"
 [LLM API] tagBuffer:  information
 [LLM API] Accumulated thinking: 2078 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2078, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(487), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2078, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2081 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2081, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(488), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2081, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 2089 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2089, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(489), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2089, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2093 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2093, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(490), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2093, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " most"
 [LLM API] tagBuffer:  most
 [LLM API] Accumulated thinking: 2098 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2098, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(491), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2098, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " accurate"
 [LLM API] tagBuffer:  accurate
 [LLM API] Accumulated thinking: 2107 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2107, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(492), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2107, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: " answer"
 [LLM API] tagBuffer:  answer
 [LLM API] Accumulated thinking: 2114 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2114, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(493), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2114, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2115 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(494), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(495), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(496), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2115, toolingLength: 32, responseLength: 0}
 [LLM API] Processing line: tool: "{\"action\": \"searching for the specific d
 [LLM API] FOUND TOOL EVENT, line: tool: "{\"action\": \"searching for the specific document\"}"
 [LLM API] Tool string to parse: "{\"action\": \"searching for the specific document\"}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'searching for the specific document'}
 [LLM API] toolJson.action value: searching for the specific document
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: searching for the specific document
 [LLM API] Received tool event: searching for the specific document
 [LLM API] Sending chunk after tool event: {thinkingLength: 2115, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(497), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2115, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2115, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(498), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2115, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "Now"
 [LLM API] tagBuffer: Now
 [LLM API] Accumulated thinking: 2118 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2118, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(499), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2118, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2120 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2120, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(500), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2120, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " have"
 [LLM API] tagBuffer:  have
 [LLM API] Accumulated thinking: 2125 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2125, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(501), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2125, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2129 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2129, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(502), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2129, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 2136 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2136, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(503), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2136, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2145 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2145, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(504), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2145, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2149 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2149, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(505), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2149, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 2150 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2150, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(506), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2150, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2152 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2152, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(507), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2152, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2154 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2154, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(508), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2154, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2155 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2155, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(509), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2155, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2156 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2156, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(510), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2156, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2158 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2158, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(511), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2158, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 2160 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2160, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(512), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2160, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2161 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2161, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(513), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2161, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 2165 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2165, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(514), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2165, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 2168 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2168, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(515), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2168, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " also"
 [LLM API] tagBuffer:  also
 [LLM API] Accumulated thinking: 2173 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2173, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(516), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2173, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " check"
 [LLM API] tagBuffer:  check
 [LLM API] Accumulated thinking: 2179 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2179, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(517), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2179, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2183 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2183, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(518), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2183, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2187 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2187, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(519), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2187, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated thinking: 2198 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2198, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(520), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2198, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated thinking: 2213 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2213, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(521), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2213, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2223 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2223, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(522), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2223, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2226 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2226, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(523), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2226, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 2230 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2230, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(524), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2230, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " if"
 [LLM API] tagBuffer:  if
 [LLM API] Accumulated thinking: 2233 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2233, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(525), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2233, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2238 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2238, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(526), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2238, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "'s"
 [LLM API] tagBuffer: 's
 [LLM API] Accumulated thinking: 2240 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2240, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(527), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2240, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " also"
 [LLM API] tagBuffer:  also
 [LLM API] Accumulated thinking: 2245 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2245, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(528), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2245, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 2247 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2247, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(529), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2247, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated thinking: 2251 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2251, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(530), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2251, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2261 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2261, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(531), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2261, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2265 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2265, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(532), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2265, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " managing"
 [LLM API] tagBuffer:  managing
 [LLM API] Accumulated thinking: 2274 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2274, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(533), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2274, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2277 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2277, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(534), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2277, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2280 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2280, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(535), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2280, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2285 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2285, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(536), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2285, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2292 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2292, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(537), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2292, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2293 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(538), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(539), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(540), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2293, toolingLength: 35, responseLength: 0}
 [LLM API] Processing line: tool: "{\n    \"action\": \"thinking about checkin
 [LLM API] FOUND TOOL EVENT, line: tool: "{\n    \"action\": \"thinking about checking the background investigations procedure\"\n}"
 [LLM API] Tool string to parse: "{\n    \"action\": \"thinking about checking the background investigations procedure\"\n}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'thinking about checking the background investigations procedure'}
 [LLM API] toolJson.action value: thinking about checking the background investigations procedure
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: thinking about checking the background investigations procedure
 [LLM API] Received tool event: thinking about checking the background investigations procedure
 [LLM API] Sending chunk after tool event: {thinkingLength: 2293, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(541), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2293, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2293, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(542), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2293, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "Interesting"
 [LLM API] tagBuffer: Interesting
 [LLM API] Accumulated thinking: 2304 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2304, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(543), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2304, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2305 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2305, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(544), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2305, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2309 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2309, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(545), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2309, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 2310 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2310, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(546), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2310, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2312 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2312, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(547), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2312, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2314 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2314, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(548), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2314, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2315 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2315, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(549), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2315, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2316 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2316, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(550), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2316, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2318 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2318, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(551), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2318, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 2320 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2320, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(552), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2320, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 2329 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2329, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(553), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2329, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " isn"
 [LLM API] tagBuffer:  isn
 [LLM API] Accumulated thinking: 2333 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2333, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(554), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2333, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "'t"
 [LLM API] tagBuffer: 't
 [LLM API] Accumulated thinking: 2335 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2335, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(555), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2335, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 2338 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2338, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(556), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2338, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2342 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2342, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(557), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2342, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 2349 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2349, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(558), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2349, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2358 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2358, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(559), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2358, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " index"
 [LLM API] tagBuffer:  index
 [LLM API] Accumulated thinking: 2364 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2364, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(560), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2364, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2365 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2365, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(561), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2365, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " which"
 [LLM API] tagBuffer:  which
 [LLM API] Accumulated thinking: 2371 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2371, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(562), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2371, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " suggests"
 [LLM API] tagBuffer:  suggests
 [LLM API] Accumulated thinking: 2380 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2380, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(563), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2380, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " it"
 [LLM API] tagBuffer:  it
 [LLM API] Accumulated thinking: 2383 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2383, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(564), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2383, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " might"
 [LLM API] tagBuffer:  might
 [LLM API] Accumulated thinking: 2389 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2389, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(565), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2389, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " not"
 [LLM API] tagBuffer:  not
 [LLM API] Accumulated thinking: 2393 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2393, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(566), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2393, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 2396 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2396, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(567), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2396, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2405 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2405, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(568), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2405, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " controlled"
 [LLM API] tagBuffer:  controlled
 [LLM API] Accumulated thinking: 2416 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2416, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(569), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2416, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2417 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2417, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(570), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2417, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 2421 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2421, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(571), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2421, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 2424 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2424, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(572), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2424, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " also"
 [LLM API] tagBuffer:  also
 [LLM API] Accumulated thinking: 2429 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2429, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(573), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2429, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " check"
 [LLM API] tagBuffer:  check
 [LLM API] Accumulated thinking: 2435 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2435, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(574), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2435, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2439 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2439, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(575), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2439, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " bad"
 [LLM API] tagBuffer:  bad
 [LLM API] Accumulated thinking: 2443 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2443, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(576), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2443, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated thinking: 2447 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2447, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(577), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2447, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2457 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2457, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(578), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2457, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2461 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2461, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(579), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2461, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " its"
 [LLM API] tagBuffer:  its
 [LLM API] Accumulated thinking: 2465 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2465, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(580), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2465, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 2472 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2472, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(581), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2472, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2481 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2481, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(582), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2481, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2482 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(583), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(584), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(585), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2482, toolingLength: 63, responseLength: 0}
 [LLM API] Processing line: tool: "{\n    \"action\": \"thinking about the 20D
 [LLM API] FOUND TOOL EVENT, line: tool: "{\n    \"action\": \"thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision\"\n}"
 [LLM API] Tool string to parse: "{\n    \"action\": \"thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision\"\n}"
 [LLM API] Detected double-encoded tool JSON, parsed twice
 [LLM API] Parsed tool JSON: {action: 'thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision'}
 [LLM API] toolJson.action value: thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision
 [LLM API] toolJson.action type: string
 [LLM API] toolJson.action truthy?: true
 [LLM API] toolJson keys: ['action']
 [LLM API] Set currentTooling to: thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision
 [LLM API] Received tool event: thinking about the 20DP-0SK11 document and checking the badging procedure for its latest revision
 [LLM API] Sending chunk after tool event: {thinkingLength: 2482, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(586), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2482, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2482, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(587), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2482, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "Based"
 [LLM API] tagBuffer: Based
 [LLM API] Accumulated thinking: 2487 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2487, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(588), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2487, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated thinking: 2490 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2490, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(589), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2490, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " my"
 [LLM API] tagBuffer:  my
 [LLM API] Accumulated thinking: 2493 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2493, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(590), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2493, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " research"
 [LLM API] tagBuffer:  research
 [LLM API] Accumulated thinking: 2502 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2502, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(591), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2502, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2503 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2503, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(592), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2503, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2505 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2505, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(593), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2505, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " can"
 [LLM API] tagBuffer:  can
 [LLM API] Accumulated thinking: 2509 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2509, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(594), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2509, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " now"
 [LLM API] tagBuffer:  now
 [LLM API] Accumulated thinking: 2513 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2513, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(595), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2513, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 2521 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2521, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(596), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2521, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 2523 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2523, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(597), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2523, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 2537 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2537, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(598), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2537, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " answer"
 [LLM API] tagBuffer:  answer
 [LLM API] Accumulated thinking: 2544 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2544, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(599), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2544, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " about"
 [LLM API] tagBuffer:  about
 [LLM API] Accumulated thinking: 2550 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2550, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(600), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2550, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " which"
 [LLM API] tagBuffer:  which
 [LLM API] Accumulated thinking: 2556 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2556, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(601), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2556, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2566 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2566, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(602), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2566, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated thinking: 2574 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2574, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(603), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2574, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2577 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2577, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(604), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2577, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2580 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2580, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(605), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2580, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2585 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2585, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(606), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2585, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2592 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2592, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(607), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2592, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2593 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2593, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(608), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2593, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " From"
 [LLM API] tagBuffer:  From
 [LLM API] Accumulated thinking: 2598 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2598, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(609), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2598, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2602 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2602, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(610), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2602, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 2609 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2609, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(611), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2609, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 2617 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2617, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(612), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2617, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2618 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2618, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(613), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2618, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2620 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2620, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(614), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2620, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " can"
 [LLM API] tagBuffer:  can
 [LLM API] Accumulated thinking: 2624 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2624, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(615), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2624, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 2628 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2628, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(616), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2628, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2633 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2633, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(617), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2633, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 2636 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2636, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(618), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2636, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 2637 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2637, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(619), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2637, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2638 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2638, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(620), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2638, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 2641 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2641, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(621), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2641, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2643 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2643, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(622), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2643, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2645 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2645, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(623), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2645, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2646 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2646, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(624), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2646, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2647 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2647, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(625), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2647, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2649 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2649, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(626), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2649, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 2651 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2651, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(627), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2651, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 2653 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2653, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(628), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2653, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 2655 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2655, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(629), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2655, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "Access"
 [LLM API] tagBuffer: Access
 [LLM API] Accumulated thinking: 2661 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2661, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(630), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2661, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated thinking: 2675 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2675, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(631), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2675, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 2676 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2676, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(632), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2676, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 2679 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2679, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(633), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2679, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2683 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2683, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(634), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2683, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " main"
 [LLM API] tagBuffer:  main
 [LLM API] Accumulated thinking: 2688 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2688, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(635), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2688, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2698 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2698, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(636), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2698, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2703 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2703, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(637), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2703, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated thinking: 2711 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2711, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(638), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2711, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2714 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2714, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(639), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2714, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2717 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2717, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(640), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2717, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2722 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(641), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2729 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2729, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(642), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2729, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2730 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2730, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(643), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2730, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 2735 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2735, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(644), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2735, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 2738 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2738, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(645), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2738, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " referenced"
 [LLM API] tagBuffer:  referenced
 [LLM API] Accumulated thinking: 2749 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2749, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(646), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2749, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " extensively"
 [LLM API] tagBuffer:  extensively
 [LLM API] Accumulated thinking: 2761 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2761, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(647), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2761, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 2764 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2764, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(648), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2764, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " other"
 [LLM API] tagBuffer:  other
 [LLM API] Accumulated thinking: 2770 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2770, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(649), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2770, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 2781 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2781, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(650), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2781, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2785 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2785, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(651), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2785, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 2793 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2793, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(652), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2793, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2796 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2796, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(653), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2796, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 2799 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2799, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(654), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2799, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2803 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2803, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(655), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2803, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " central"
 [LLM API] tagBuffer:  central
 [LLM API] Accumulated thinking: 2811 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2811, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(656), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2811, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " process"
 [LLM API] tagBuffer:  process
 [LLM API] Accumulated thinking: 2819 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2819, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(657), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2819, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2823 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2823, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(658), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2823, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " author"
 [LLM API] tagBuffer:  author
 [LLM API] Accumulated thinking: 2830 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2830, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(659), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2830, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "izing"
 [LLM API] tagBuffer: izing
 [LLM API] Accumulated thinking: 2835 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2835, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(660), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2835, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2838 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2838, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(661), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2838, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2841 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2841, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(662), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2841, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2846 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2846, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(663), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2846, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2853 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2853, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(664), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2853, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 2856 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2856, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(665), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2856, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 2857 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2857, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(666), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2857, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2858 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2858, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(667), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2858, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 2861 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2861, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(668), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2861, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2863 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2863, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(669), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2863, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2865 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2865, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(670), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2865, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2866 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2866, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(671), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2866, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2867 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2867, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(672), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2867, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2869 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2869, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(673), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2869, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated thinking: 2871 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2871, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(674), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2871, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 2873 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2873, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(675), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2873, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 2875 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2875, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(676), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2875, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "P"
 [LLM API] tagBuffer: P
 [LLM API] Accumulated thinking: 2876 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2876, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(677), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2876, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "alo"
 [LLM API] tagBuffer: alo
 [LLM API] Accumulated thinking: 2879 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2879, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(678), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2879, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 2885 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2885, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(679), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2885, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Bad"
 [LLM API] tagBuffer:  Bad
 [LLM API] Accumulated thinking: 2889 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2889, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(680), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2889, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated thinking: 2893 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2893, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(681), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2893, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Procedure"
 [LLM API] tagBuffer:  Procedure
 [LLM API] Accumulated thinking: 2903 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2903, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(682), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2903, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 2904 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2904, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(683), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2904, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " also"
 [LLM API] tagBuffer:  also
 [LLM API] Accumulated thinking: 2909 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2909, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(684), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2909, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " contains"
 [LLM API] tagBuffer:  contains
 [LLM API] Accumulated thinking: 2918 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2918, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(685), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2918, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " significant"
 [LLM API] tagBuffer:  significant
 [LLM API] Accumulated thinking: 2930 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2930, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(686), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2930, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " information"
 [LLM API] tagBuffer:  information
 [LLM API] Accumulated thinking: 2942 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2942, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(687), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2942, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " about"
 [LLM API] tagBuffer:  about
 [LLM API] Accumulated thinking: 2948 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2948, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(688), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2948, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2951 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2951, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(689), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2951, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2954 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2954, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(690), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2954, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2959 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2959, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(691), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2959, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2966 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2966, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(692), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2966, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " processes"
 [LLM API] tagBuffer:  processes
 [LLM API] Accumulated thinking: 2976 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2976, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(693), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2976, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2977 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2977, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(694), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2977, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " particularly"
 [LLM API] tagBuffer:  particularly
 [LLM API] Accumulated thinking: 2990 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2990, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(695), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2990, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 2998 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2998, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(696), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2998, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 3001 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3001, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(697), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3001, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " AC"
 [LLM API] tagBuffer:  AC
 [LLM API] Accumulated thinking: 3004 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3004, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(698), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3004, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "AD"
 [LLM API] tagBuffer: AD
 [LLM API] Accumulated thinking: 3006 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3006, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(699), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3006, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " badge"
 [LLM API] tagBuffer:  badge
 [LLM API] Accumulated thinking: 3012 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3012, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(700), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3012, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " issuance"
 [LLM API] tagBuffer:  issuance
 [LLM API] Accumulated thinking: 3021 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3021, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(701), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3021, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 3025 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3025, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(702), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3025, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated thinking: 3038 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3038, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(703), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3038, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 3041 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3041, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(704), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3041, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 3042 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3042, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(705), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3042, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 3043 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3043, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(706), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3043, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 3046 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3046, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(707), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3046, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 3048 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3048, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(708), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3048, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 3050 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3050, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(709), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3050, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3051 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3051, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(710), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3051, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 3052 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3052, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(711), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3052, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 3054 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3054, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(712), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3054, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 3056 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3056, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(713), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3056, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 3058 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3058, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(714), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3058, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 3060 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3060, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(715), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3060, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "Background"
 [LLM API] tagBuffer: Background
 [LLM API] Accumulated thinking: 3070 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3070, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(716), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3070, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated thinking: 3085 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3085, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(717), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3085, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 3089 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3089, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(718), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3089, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 3092 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3092, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(719), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3092, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 3095 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3095, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(720), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3095, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 3100 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3100, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(721), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3100, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 3107 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3107, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(722), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3107, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 3108 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3108, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(723), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3108, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 3116 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3116, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(724), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3116, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 3119 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3119, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(725), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3119, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 3122 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3122, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(726), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3122, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " another"
 [LLM API] tagBuffer:  another
 [LLM API] Accumulated thinking: 3130 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3130, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(727), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3130, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " supporting"
 [LLM API] tagBuffer:  supporting
 [LLM API] Accumulated thinking: 3141 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3141, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(728), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3141, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 3151 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3151, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(729), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3151, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 3152 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3152, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(730), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3152, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " but"
 [LLM API] tagBuffer:  but
 [LLM API] Accumulated thinking: 3156 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3156, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(731), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3156, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " it"
 [LLM API] tagBuffer:  it
 [LLM API] Accumulated thinking: 3159 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3159, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(732), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3159, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " may"
 [LLM API] tagBuffer:  may
 [LLM API] Accumulated thinking: 3163 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3163, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(733), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3163, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " not"
 [LLM API] tagBuffer:  not
 [LLM API] Accumulated thinking: 3167 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3167, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(734), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3167, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 3170 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3170, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(735), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3170, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 3179 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3179, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(736), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3179, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-controlled"
 [LLM API] tagBuffer: -controlled
 [LLM API] Accumulated thinking: 3190 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3190, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(737), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3190, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 3193 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3193, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(738), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3193, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "The"
 [LLM API] tagBuffer: The
 [LLM API] Accumulated thinking: 3196 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3196, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(739), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3196, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated thinking: 3200 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3200, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(740), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3200, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " findings"
 [LLM API] tagBuffer:  findings
 [LLM API] Accumulated thinking: 3209 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3209, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(741), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3209, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " from"
 [LLM API] tagBuffer:  from
 [LLM API] Accumulated thinking: 3214 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3214, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(742), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3214, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 3218 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3218, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(743), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3218, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 3225 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3225, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(744), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3225, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 3233 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3233, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(745), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3233, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " show"
 [LLM API] tagBuffer:  show
 [LLM API] Accumulated thinking: 3238 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3238, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(746), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3238, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 3243 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3243, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(747), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3243, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 3246 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3246, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(748), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3246, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3247 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3247, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(749), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3247, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 3250 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3250, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(750), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3250, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 3252 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3252, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(751), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3252, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 3254 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3254, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(752), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3254, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3255 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3255, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(753), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3255, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 3256 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3256, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(754), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3256, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 3258 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3258, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(755), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3258, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated thinking: 3260 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3260, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(756), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3260, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 3262 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3262, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(757), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3262, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 3265 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3265, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(758), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3265, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " listed"
 [LLM API] tagBuffer:  listed
 [LLM API] Accumulated thinking: 3272 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3272, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(759), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3272, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " as"
 [LLM API] tagBuffer:  as
 [LLM API] Accumulated thinking: 3275 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3275, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(760), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3275, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 3279 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3279, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(761), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3279, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " primary"
 [LLM API] tagBuffer:  primary
 [LLM API] Accumulated thinking: 3287 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3287, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(762), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3287, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 3297 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3297, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(763), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3297, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 3302 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3302, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(764), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3302, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 3305 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3305, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(765), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3305, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 3308 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3308, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(766), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3308, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 3313 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3313, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(767), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3313, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 3320 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3320, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(768), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3320, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " requests"
 [LLM API] tagBuffer:  requests
 [LLM API] Accumulated thinking: 3329 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3329, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(769), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3329, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 3333 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3333, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(770), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3333, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " processed"
 [LLM API] tagBuffer:  processed
 [LLM API] Accumulated thinking: 3343 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3343, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(771), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3343, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " through"
 [LLM API] tagBuffer:  through
 [LLM API] Accumulated thinking: 3351 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3351, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(772), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3351, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated thinking: 3352 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3352, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(773), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3352, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3353 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3353, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(774), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3353, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " All"
 [LLM API] tagBuffer:  All
 [LLM API] Accumulated thinking: 3357 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3357, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(775), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3357, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 3361 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3361, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(776), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3361, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated thinking: 3374 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3374, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(777), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3374, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 3378 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3378, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(778), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3378, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 3381 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3381, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(779), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3381, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 3384 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3384, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(780), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3384, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 3389 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3389, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(781), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3389, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 3396 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3396, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(782), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3396, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " must"
 [LLM API] tagBuffer:  must
 [LLM API] Accumulated thinking: 3401 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3401, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(783), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3401, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 3404 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3404, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(784), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3404, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " met"
 [LLM API] tagBuffer:  met
 [LLM API] Accumulated thinking: 3408 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3408, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(785), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3408, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " per"
 [LLM API] tagBuffer:  per
 [LLM API] Accumulated thinking: 3412 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3412, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(786), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3412, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " this"
 [LLM API] tagBuffer:  this
 [LLM API] Accumulated thinking: 3417 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3417, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(787), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3417, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 3427 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3427, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(788), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3427, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated thinking: 3428 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3428, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(789), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3428, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3429 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3429, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(790), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3429, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " The"
 [LLM API] tagBuffer:  The
 [LLM API] Accumulated thinking: 3433 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3433, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(791), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3433, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated thinking: 3438 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3438, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(792), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3438, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 3444 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3444, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(793), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3444, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Bad"
 [LLM API] tagBuffer:  Bad
 [LLM API] Accumulated thinking: 3448 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3448, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(794), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3448, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated thinking: 3452 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3452, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(795), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3452, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Procedure"
 [LLM API] tagBuffer:  Procedure
 [LLM API] Accumulated thinking: 3462 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3462, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(796), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3462, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 3464 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3464, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(797), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3464, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 3466 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3466, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(798), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3466, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 3468 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3468, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(799), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3468, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3469 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3469, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(800), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3469, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 3470 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3470, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(801), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3470, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 3472 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3472, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(802), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3472, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated thinking: 3474 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3474, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(803), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3474, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 3475 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3475, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(804), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3475, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " references"
 [LLM API] tagBuffer:  references
 [LLM API] Accumulated thinking: 3486 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3486, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(805), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3486, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " this"
 [LLM API] tagBuffer:  this
 [LLM API] Accumulated thinking: 3491 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3491, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(806), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3491, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 3501 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3501, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(807), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3501, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " extensively"
 [LLM API] tagBuffer:  extensively
 [LLM API] Accumulated thinking: 3513 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3513, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(808), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3513, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 3517 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3517, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(809), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3517, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 3520 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3520, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(810), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3520, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 3523 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3523, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(811), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3523, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 3528 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3528, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(812), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3528, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 3535 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3535, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(813), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3535, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " processing"
 [LLM API] tagBuffer:  processing
 [LLM API] Accumulated thinking: 3546 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3546, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(814), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3546, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated thinking: 3547 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3547, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(815), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3547, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3548 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3548, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(816), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3548, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " The"
 [LLM API] tagBuffer:  The
 [LLM API] Accumulated thinking: 3552 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3552, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(817), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3552, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Background"
 [LLM API] tagBuffer:  Background
 [LLM API] Accumulated thinking: 3563 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3563, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(818), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3563, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated thinking: 3578 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3578, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(819), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3578, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 3588 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3588, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(820), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3588, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 3590 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3590, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(821), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3590, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 3592 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3592, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(822), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3592, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 3594 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3594, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(823), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3594, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 3595 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3595, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(824), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3595, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 3596 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3596, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(825), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3596, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 3598 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3598, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(826), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3598, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 3600 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3600, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(827), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3600, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated thinking: 3601 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3601, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(828), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3601, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " provides"
 [LLM API] tagBuffer:  provides
 [LLM API] Accumulated thinking: 3610 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3610, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(829), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3610, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 3614 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3614, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(830), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3614, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " investigative"
 [LLM API] tagBuffer:  investigative
 [LLM API] Accumulated thinking: 3628 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3628, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(831), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3628, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " framework"
 [LLM API] tagBuffer:  framework
 [LLM API] Accumulated thinking: 3638 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3638, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(832), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3638, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 3642 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3642, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(833), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3642, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 3645 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3645, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(834), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3645, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 3648 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3648, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(835), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3648, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 3653 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3653, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(836), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3653, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 3660 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3660, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(837), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3660, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n\n"
 [LLM API] tagBuffer: 


 [LLM API] Accumulated thinking: 3662 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3662, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(838), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3662, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "Let"
 [LLM API] tagBuffer: Let
 [LLM API] Accumulated thinking: 3665 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3665, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(839), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3665, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 3668 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3668, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(840), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3668, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 3676 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3676, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(841), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3676, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 3678 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3678, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(842), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3678, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 3692 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3692, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(843), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3692, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " answer"
 [LLM API] tagBuffer:  answer
 [LLM API] Accumulated thinking: 3699 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3699, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(844), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3699, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 3704 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3704, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(845), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3704, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " proper"
 [LLM API] tagBuffer:  proper
 [LLM API] Accumulated thinking: 3711 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3711, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(846), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3711, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: " citations"
 [LLM API] tagBuffer:  citations
 [LLM API] Accumulated thinking: 3721 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3721, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(847), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3721, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 3722 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(848), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(849), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(850), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "<"
 [LLM API] tagBuffer: 
<
 [LLM API] Keeping potential partial tag in buffer: 
<
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(851), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: "response"
 [LLM API] tagBuffer: 
<response
 [LLM API] Keeping potential partial tag in buffer: 
<response
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(852), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 0}
 [LLM API] Processing line: data: ">\n"
 [LLM API] tagBuffer: 
<response>

 [LLM API] Entered <response> tag, remaining buffer: 

 [LLM API] Accumulated response: 1 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1}
 [ChatService] Streaming callback invoked {chunks: Array(853), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1 first 100 chars: 

 [LLM API] Processing line: data: "Based"
 [LLM API] tagBuffer: Based
 [LLM API] Accumulated response: 6 chars content: Based
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 6}
 [ChatService] Streaming callback invoked {chunks: Array(854), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 6}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 6 first 100 chars: 
Based
 [MarkdownContent] Content changed: 
Based
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated response: 9 chars content:  on
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 9}
 [ChatService] Streaming callback invoked {chunks: Array(855), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 9}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 9 first 100 chars: 
Based on
 [LLM API] Processing line: data: " my"
 [LLM API] tagBuffer:  my
 [LLM API] Accumulated response: 12 chars content:  my
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 12}
 [ChatService] Streaming callback invoked {chunks: Array(856), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 12}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 12 first 100 chars: 
Based on my
 [MarkdownContent] Content changed: 
Based on my
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated response: 19 chars content:  search
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 19}
 [ChatService] Streaming callback invoked {chunks: Array(857), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 19}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 19 first 100 chars: 
Based on my search
 [LLM API] Processing line: data: " of"
 [LLM API] tagBuffer:  of
 [LLM API] Accumulated response: 22 chars content:  of
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 22}
 [ChatService] Streaming callback invoked {chunks: Array(858), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 22}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 22 first 100 chars: 
Based on my search of
 [MarkdownContent] Content changed: 
Based on my search of
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated response: 27 chars content:  Palo
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 27}
 [ChatService] Streaming callback invoked {chunks: Array(859), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 27}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 27 first 100 chars: 
Based on my search of Palo
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated response: 33 chars content:  Verde
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 33}
 [ChatService] Streaming callback invoked {chunks: Array(860), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 33}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 33 first 100 chars: 
Based on my search of Palo Verde
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated response: 44 chars content:  procedures
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 44}
 [ChatService] Streaming callback invoked {chunks: Array(861), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 44}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 44 first 100 chars: 
Based on my search of Palo Verde procedures
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 45 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 45}
 [ChatService] Streaming callback invoked {chunks: Array(862), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 45}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 45 first 100 chars: 
Based on my search of Palo Verde procedures,
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated response: 51 chars content:  there
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 51}
 [ChatService] Streaming callback invoked {chunks: Array(863), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 51}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 51 first 100 chars: 
Based on my search of Palo Verde procedures, there
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated response: 55 chars content:  are
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 55}
 [ChatService] Streaming callback invoked {chunks: Array(864), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 55}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 55 first 100 chars: 
Based on my search of Palo Verde procedures, there are
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " several"
 [LLM API] tagBuffer:  several
 [LLM API] Accumulated response: 63 chars content:  several
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 63}
 [ChatService] Streaming callback invoked {chunks: Array(865), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 63}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 63 first 100 chars: 
Based on my search of Palo Verde procedures, there are several
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated response: 67 chars content:  key
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 67}
 [ChatService] Streaming callback invoked {chunks: Array(866), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 67}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 67 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated response: 78 chars content:  procedures
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 78}
 [ChatService] Streaming callback invoked {chunks: Array(867), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 78}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 78 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated response: 83 chars content:  that
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 83}
 [ChatService] Streaming callback invoked {chunks: Array(868), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 83}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 83 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that
 [LLM API] Processing line: data: " manage"
 [LLM API] tagBuffer:  manage
 [LLM API] Accumulated response: 90 chars content:  manage
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 90}
 [ChatService] Streaming callback invoked {chunks: Array(869), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 90}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 90 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 93 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 93}
 [ChatService] Streaming callback invoked {chunks: Array(870), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 93}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 93 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage un
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 96 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 96}
 [ChatService] Streaming callback invoked {chunks: Array(871), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 96}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 96 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unesc
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unesc
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 101 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 101}
 [ChatService] Streaming callback invoked {chunks: Array(872), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 101}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 101 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 108 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 108}
 [ChatService] Streaming callback invoked {chunks: Array(873), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 108}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 108 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 109 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 109}
 [ChatService] Streaming callback invoked {chunks: Array(874), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 109}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 109 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated response: 114 chars content:  with
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 114}
 [ChatService] Streaming callback invoked {chunks: Array(875), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 114}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 114 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 117 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 117}
 [ChatService] Streaming callback invoked {chunks: Array(876), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 117}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 117 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 119 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 119}
 [ChatService] Streaming callback invoked {chunks: Array(877), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 119}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 119 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 121 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 121}
 [ChatService] Streaming callback invoked {chunks: Array(878), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 121}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 121 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 122 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 122}
 [ChatService] Streaming callback invoked {chunks: Array(879), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 122}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 122 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 123 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 123}
 [ChatService] Streaming callback invoked {chunks: Array(880), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 123}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 123 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 125 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 125}
 [ChatService] Streaming callback invoked {chunks: Array(881), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 125}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 125 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated response: 127 chars content: 40
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 127}
 [ChatService] Streaming callback invoked {chunks: Array(882), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 127}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 127 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 128 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 128}
 [ChatService] Streaming callback invoked {chunks: Array(883), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 128}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 128 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 135 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 135}
 [ChatService] Streaming callback invoked {chunks: Array(884), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 135}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 135 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 149 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 149}
 [ChatService] Streaming callback invoked {chunks: Array(885), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 149}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 149 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 151 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 151}
 [ChatService] Streaming callback invoked {chunks: Array(886), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 151}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 151 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " being"
 [LLM API] tagBuffer:  being
 [LLM API] Accumulated response: 157 chars content:  being
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 157}
 [ChatService] Streaming callback invoked {chunks: Array(887), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 157}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 157 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 161 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 161}
 [ChatService] Streaming callback invoked {chunks: Array(888), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 161}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 161 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " primary"
 [LLM API] tagBuffer:  primary
 [LLM API] Accumulated response: 169 chars content:  primary
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 169}
 [ChatService] Streaming callback invoked {chunks: Array(889), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 169}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 169 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 179 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 179}
 [ChatService] Streaming callback invoked {chunks: Array(890), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 179}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 179 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated response: 184 chars content:  that
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 184}
 [ChatService] Streaming callback invoked {chunks: Array(891), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 184}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 184 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated response: 192 chars content:  manages
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 192}
 [ChatService] Streaming callback invoked {chunks: Array(892), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 192}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 192 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 195 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 195}
 [ChatService] Streaming callback invoked {chunks: Array(893), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 195}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 195 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 198 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 198}
 [ChatService] Streaming callback invoked {chunks: Array(894), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 198}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 198 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 203 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 203}
 [ChatService] Streaming callback invoked {chunks: Array(895), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 203}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 203 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 210 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 210}
 [ChatService] Streaming callback invoked {chunks: Array(896), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 210}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 210 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated response: 213 chars content: .


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 213}
 [ChatService] Streaming callback invoked {chunks: Array(897), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 213}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 213 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "##"
 [LLM API] tagBuffer: ##
 [LLM API] Accumulated response: 215 chars content: ##
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 215}
 [ChatService] Streaming callback invoked {chunks: Array(898), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 215}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 215 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Primary"
 [LLM API] tagBuffer:  Primary
 [LLM API] Accumulated response: 223 chars content:  Primary
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 223}
 [ChatService] Streaming callback invoked {chunks: Array(899), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 223}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 223 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Procedure"
 [LLM API] tagBuffer:  Procedure
 [LLM API] Accumulated response: 233 chars content:  Procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 233}
 [ChatService] Streaming callback invoked {chunks: Array(900), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 233}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 233 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 234 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 234}
 [ChatService] Streaming callback invoked {chunks: Array(901), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 234}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 234 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 235 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 235}
 [ChatService] Streaming callback invoked {chunks: Array(902), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 235}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 235 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 237 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 237}
 [ChatService] Streaming callback invoked {chunks: Array(903), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 237}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 237 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 239 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 239}
 [ChatService] Streaming callback invoked {chunks: Array(904), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 239}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 239 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 240 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 240}
 [ChatService] Streaming callback invoked {chunks: Array(905), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 240}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 240 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 241 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 241}
 [ChatService] Streaming callback invoked {chunks: Array(906), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 241}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 241 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 243 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 243}
 [ChatService] Streaming callback invoked {chunks: Array(907), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 243}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 243 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated response: 245 chars content: 40
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 245}
 [ChatService] Streaming callback invoked {chunks: Array(908), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 245}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 245 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 247 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 247}
 [ChatService] Streaming callback invoked {chunks: Array(909), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 247}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 247 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "Access"
 [LLM API] tagBuffer: Access
 [LLM API] Accumulated response: 253 chars content: Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 253}
 [ChatService] Streaming callback invoked {chunks: Array(910), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 253}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 253 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 267 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 267}
 [ChatService] Streaming callback invoked {chunks: Array(911), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 267}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 267 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated response: 268 chars content: )
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 268}
 [ChatService] Streaming callback invoked {chunks: Array(912), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 268}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 268 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated response: 270 chars content:  -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 270}
 [ChatService] Streaming callback invoked {chunks: Array(913), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 270}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 270 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated response: 274 chars content:  Rev
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 274}
 [ChatService] Streaming callback invoked {chunks: Array(914), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 274}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 274 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 275 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 275}
 [ChatService] Streaming callback invoked {chunks: Array(915), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 275}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 275 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 276 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 276}
 [ChatService] Streaming callback invoked {chunks: Array(916), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 276}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 276 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 277 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 277}
 [ChatService] Streaming callback invoked {chunks: Array(917), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 277}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 277 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "50"
 [LLM API] tagBuffer: 50
 [LLM API] Accumulated response: 279 chars content: 50
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 279}
 [ChatService] Streaming callback invoked {chunks: Array(918), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 279}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 279 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n\n"
 [LLM API] tagBuffer: 


 [LLM API] Accumulated response: 281 chars content: 


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 281}
 [ChatService] Streaming callback invoked {chunks: Array(919), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 281}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 281 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "This"
 [LLM API] tagBuffer: This
 [LLM API] Accumulated response: 285 chars content: This
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 285}
 [ChatService] Streaming callback invoked {chunks: Array(920), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 285}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 285 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated response: 288 chars content:  is
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 288}
 [ChatService] Streaming callback invoked {chunks: Array(921), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 288}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 288 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 292 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 292}
 [ChatService] Streaming callback invoked {chunks: Array(922), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 292}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 292 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " main"
 [LLM API] tagBuffer:  main
 [LLM API] Accumulated response: 297 chars content:  main
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 297}
 [ChatService] Streaming callback invoked {chunks: Array(923), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 297}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 297 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 307 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 307}
 [ChatService] Streaming callback invoked {chunks: Array(924), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 307}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 307 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated response: 312 chars content:  that
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 312}
 [ChatService] Streaming callback invoked {chunks: Array(925), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 312}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 312 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated response: 320 chars content:  manages
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 320}
 [ChatService] Streaming callback invoked {chunks: Array(926), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 320}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 320 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 324 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 324}
 [ChatService] Streaming callback invoked {chunks: Array(927), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 324}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 324 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 327 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 327}
 [ChatService] Streaming callback invoked {chunks: Array(928), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 327}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 327 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 330 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 330}
 [ChatService] Streaming callback invoked {chunks: Array(929), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 330}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 330 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 335 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 335}
 [ChatService] Streaming callback invoked {chunks: Array(930), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 335}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 335 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 342 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 342}
 [ChatService] Streaming callback invoked {chunks: Array(931), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 342}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 342 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " authorization"
 [LLM API] tagBuffer:  authorization
 [LLM API] Accumulated response: 356 chars content:  authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 356}
 [ChatService] Streaming callback invoked {chunks: Array(932), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 356}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 356 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " process"
 [LLM API] tagBuffer:  process
 [LLM API] Accumulated response: 364 chars content:  process
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 364}
 [ChatService] Streaming callback invoked {chunks: Array(933), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 364}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 364 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated response: 367 chars content:  at
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 367}
 [ChatService] Streaming callback invoked {chunks: Array(934), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 367}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 367 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated response: 372 chars content:  Palo
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 372}
 [ChatService] Streaming callback invoked {chunks: Array(935), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 372}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 372 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated response: 378 chars content:  Verde
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 378}
 [ChatService] Streaming callback invoked {chunks: Array(936), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 378}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 378 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 379 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 379}
 [ChatService] Streaming callback invoked {chunks: Array(937), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 379}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 379 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Key"
 [LLM API] tagBuffer:  Key
 [LLM API] Accumulated response: 383 chars content:  Key
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 383}
 [ChatService] Streaming callback invoked {chunks: Array(938), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 383}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 383 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " functions"
 [LLM API] tagBuffer:  functions
 [LLM API] Accumulated response: 393 chars content:  functions
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 393}
 [ChatService] Streaming callback invoked {chunks: Array(939), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 393}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 393 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " include"
 [LLM API] tagBuffer:  include
 [LLM API] Accumulated response: 401 chars content:  include
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 401}
 [ChatService] Streaming callback invoked {chunks: Array(940), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 401}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 401 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 404 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 404}
 [ChatService] Streaming callback invoked {chunks: Array(941), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 404}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 404 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 405 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 405}
 [ChatService] Streaming callback invoked {chunks: Array(942), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 405}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 405 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 408 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 408}
 [ChatService] Streaming callback invoked {chunks: Array(943), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 408}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 408 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "Initial"
 [LLM API] tagBuffer: Initial
 [LLM API] Accumulated response: 415 chars content: Initial
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 415}
 [ChatService] Streaming callback invoked {chunks: Array(944), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 415}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 415 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 418 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 418}
 [ChatService] Streaming callback invoked {chunks: Array(945), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 418}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 418 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 421 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 421}
 [ChatService] Streaming callback invoked {chunks: Array(946), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 421}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 421 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 426 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 426}
 [ChatService] Streaming callback invoked {chunks: Array(947), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 426}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 426 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 433 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 433}
 [ChatService] Streaming callback invoked {chunks: Array(948), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 433}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 433 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 447 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 447}
 [ChatService] Streaming callback invoked {chunks: Array(949), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 447}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 447 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 449 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 449}
 [ChatService] Streaming callback invoked {chunks: Array(950), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 449}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 449 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "U"
 [LLM API] tagBuffer: U
 [LLM API] Accumulated response: 450 chars content: U
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 450}
 [ChatService] Streaming callback invoked {chunks: Array(951), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 450}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 450 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "AA"
 [LLM API] tagBuffer: AA
 [LLM API] Accumulated response: 452 chars content: AA
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 452}
 [ChatService] Streaming callback invoked {chunks: Array(952), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 452}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 452 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ")**"
 [LLM API] tagBuffer: )**
 [LLM API] Accumulated response: 455 chars content: )**
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 455}
 [ChatService] Streaming callback invoked {chunks: Array(953), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 455}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 455 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " processing"
 [LLM API] tagBuffer:  processing
 [LLM API] Accumulated response: 466 chars content:  processing
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 466}
 [ChatService] Streaming callback invoked {chunks: Array(954), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 466}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 466 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 467 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 467}
 [ChatService] Streaming callback invoked {chunks: Array(955), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 467}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 467 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 468 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 468}
 [ChatService] Streaming callback invoked {chunks: Array(956), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 468}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 468 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 471 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 471}
 [ChatService] Streaming callback invoked {chunks: Array(957), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 471}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 471 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Updated"
 [LLM API] tagBuffer: Updated
 [LLM API] Accumulated response: 478 chars content: Updated
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 478}
 [ChatService] Streaming callback invoked {chunks: Array(958), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 478}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 478 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 481 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 481}
 [ChatService] Streaming callback invoked {chunks: Array(959), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 481}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 481 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 484 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 484}
 [ChatService] Streaming callback invoked {chunks: Array(960), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 484}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 484 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 489 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 489}
 [ChatService] Streaming callback invoked {chunks: Array(961), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 489}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 489 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 496 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 496}
 [ChatService] Streaming callback invoked {chunks: Array(962), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 496}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 496 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 510 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 510}
 [ChatService] Streaming callback invoked {chunks: Array(963), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 510}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 510 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 512 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 512}
 [ChatService] Streaming callback invoked {chunks: Array(964), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 512}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 512 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated response: 525 chars content:  requirements
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 525}
 [ChatService] Streaming callback invoked {chunks: Array(965), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 525}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 525 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "  \n"
 [LLM API] tagBuffer:   

 [LLM API] Accumulated response: 528 chars content:   

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 528}
 [ChatService] Streaming callback invoked {chunks: Array(966), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 528}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 528 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 529 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 529}
 [ChatService] Streaming callback invoked {chunks: Array(967), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 529}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 529 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 532 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 532}
 [ChatService] Streaming callback invoked {chunks: Array(968), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 532}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 532 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Re"
 [LLM API] tagBuffer: Re
 [LLM API] Accumulated response: 534 chars content: Re
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 534}
 [ChatService] Streaming callback invoked {chunks: Array(969), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 534}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 534 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "inst"
 [LLM API] tagBuffer: inst
 [LLM API] Accumulated response: 538 chars content: inst
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 538}
 [ChatService] Streaming callback invoked {chunks: Array(970), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 538}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 538 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "atement"
 [LLM API] tagBuffer: atement
 [LLM API] Accumulated response: 545 chars content: atement
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 545}
 [ChatService] Streaming callback invoked {chunks: Array(971), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 545}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 545 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " of"
 [LLM API] tagBuffer:  of
 [LLM API] Accumulated response: 548 chars content:  of
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 548}
 [ChatService] Streaming callback invoked {chunks: Array(972), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 548}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 548 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 551 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 551}
 [ChatService] Streaming callback invoked {chunks: Array(973), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 551}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 551 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 554 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 554}
 [ChatService] Streaming callback invoked {chunks: Array(974), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 554}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 554 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 559 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 559}
 [ChatService] Streaming callback invoked {chunks: Array(975), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 559}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 559 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 566 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 566}
 [ChatService] Streaming callback invoked {chunks: Array(976), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 566}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 566 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 580 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 580}
 [ChatService] Streaming callback invoked {chunks: Array(977), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 580}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 580 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 582 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 582}
 [ChatService] Streaming callback invoked {chunks: Array(978), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 582}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 582 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 584 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 584}
 [ChatService] Streaming callback invoked {chunks: Array(979), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 584}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 584 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "both"
 [LLM API] tagBuffer: both
 [LLM API] Accumulated response: 588 chars content: both
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 588}
 [ChatService] Streaming callback invoked {chunks: Array(980), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 588}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 588 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " within"
 [LLM API] tagBuffer:  within
 [LLM API] Accumulated response: 595 chars content:  within
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 595}
 [ChatService] Streaming callback invoked {chunks: Array(981), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 595}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 595 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 596 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 596}
 [ChatService] Streaming callback invoked {chunks: Array(982), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 596}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 596 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "30"
 [LLM API] tagBuffer: 30
 [LLM API] Accumulated response: 598 chars content: 30
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 598}
 [ChatService] Streaming callback invoked {chunks: Array(983), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 598}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 598 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " days"
 [LLM API] tagBuffer:  days
 [LLM API] Accumulated response: 603 chars content:  days
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 603}
 [ChatService] Streaming callback invoked {chunks: Array(984), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 603}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 603 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 607 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 607}
 [ChatService] Streaming callback invoked {chunks: Array(985), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 607}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 607 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 608 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 608}
 [ChatService] Streaming callback invoked {chunks: Array(986), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 608}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 608 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "31"
 [LLM API] tagBuffer: 31
 [LLM API] Accumulated response: 610 chars content: 31
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 610}
 [ChatService] Streaming callback invoked {chunks: Array(987), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 610}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 610 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 611 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 611}
 [ChatService] Streaming callback invoked {chunks: Array(988), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 611}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 611 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "365"
 [LLM API] tagBuffer: 365
 [LLM API] Accumulated response: 614 chars content: 365
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 614}
 [ChatService] Streaming callback invoked {chunks: Array(989), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 614}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 614 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " days"
 [LLM API] tagBuffer:  days
 [LLM API] Accumulated response: 619 chars content:  days
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 619}
 [ChatService] Streaming callback invoked {chunks: Array(990), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 619}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 619 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " away"
 [LLM API] tagBuffer:  away
 [LLM API] Accumulated response: 624 chars content:  away
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 624}
 [ChatService] Streaming callback invoked {chunks: Array(991), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 624}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 624 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ")\n"
 [LLM API] tagBuffer: )

 [LLM API] Accumulated response: 626 chars content: )

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 626}
 [ChatService] Streaming callback invoked {chunks: Array(992), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 626}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 626 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 627 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 627}
 [ChatService] Streaming callback invoked {chunks: Array(993), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 627}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 627 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 630 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 630}
 [ChatService] Streaming callback invoked {chunks: Array(994), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 630}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 630 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Maint"
 [LLM API] tagBuffer: Maint
 [LLM API] Accumulated response: 635 chars content: Maint
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 635}
 [ChatService] Streaming callback invoked {chunks: Array(995), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 635}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 635 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "aining"
 [LLM API] tagBuffer: aining
 [LLM API] Accumulated response: 641 chars content: aining
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 641}
 [ChatService] Streaming callback invoked {chunks: Array(996), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 641}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 641 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " U"
 [LLM API] tagBuffer:  U
 [LLM API] Accumulated response: 643 chars content:  U
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 643}
 [ChatService] Streaming callback invoked {chunks: Array(997), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 643}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 643 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "AA"
 [LLM API] tagBuffer: AA
 [LLM API] Accumulated response: 645 chars content: AA
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 645}
 [ChatService] Streaming callback invoked {chunks: Array(998), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 645}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 645 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "/"
 [LLM API] tagBuffer: /
 [LLM API] Accumulated response: 646 chars content: /
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 646}
 [ChatService] Streaming callback invoked {chunks: Array(999), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 646}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 646 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "UA"
 [LLM API] tagBuffer: UA
 [LLM API] Accumulated response: 648 chars content: UA
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 648}
 [ChatService] Streaming callback invoked {chunks: Array(1000), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 648}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 648 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 650 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 650}
 [ChatService] Streaming callback invoked {chunks: Array(1001), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 650}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 650 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " status"
 [LLM API] tagBuffer:  status
 [LLM API] Accumulated response: 657 chars content:  status
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 657}
 [ChatService] Streaming callback invoked {chunks: Array(1002), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 657}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 657 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 658 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 658}
 [ChatService] Streaming callback invoked {chunks: Array(1003), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 658}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 658 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 659 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 659}
 [ChatService] Streaming callback invoked {chunks: Array(1004), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 659}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 659 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 662 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 662}
 [ChatService] Streaming callback invoked {chunks: Array(1005), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 662}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 662 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "All"
 [LLM API] tagBuffer: All
 [LLM API] Accumulated response: 665 chars content: All
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 665}
 [ChatService] Streaming callback invoked {chunks: Array(1006), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 665}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 665 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 676 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 676}
 [ChatService] Streaming callback invoked {chunks: Array(1007), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 676}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 676 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " screening"
 [LLM API] tagBuffer:  screening
 [LLM API] Accumulated response: 686 chars content:  screening
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 686}
 [ChatService] Streaming callback invoked {chunks: Array(1008), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 686}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 686 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 690 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 690}
 [ChatService] Streaming callback invoked {chunks: Array(1009), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 690}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 690 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " investigation"
 [LLM API] tagBuffer:  investigation
 [LLM API] Accumulated response: 704 chars content:  investigation
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 704}
 [ChatService] Streaming callback invoked {chunks: Array(1010), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 704}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 704 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 706 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 706}
 [ChatService] Streaming callback invoked {chunks: Array(1011), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 706}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 706 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated response: 719 chars content:  requirements
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 719}
 [ChatService] Streaming callback invoked {chunks: Array(1012), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 719}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 719 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ["
 [LLM API] tagBuffer:  [
 [LLM API] Accumulated response: 721 chars content:  [
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 721}
 [ChatService] Streaming callback invoked {chunks: Array(1013), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 721}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 721 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "Source"
 [LLM API] tagBuffer: Source
 [LLM API] Accumulated response: 727 chars content: Source
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 727}
 [ChatService] Streaming callback invoked {chunks: Array(1014), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 727}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 727 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 728 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 728}
 [ChatService] Streaming callback invoked {chunks: Array(1015), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 728}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 728 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 729 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 729}
 [ChatService] Streaming callback invoked {chunks: Array(1016), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 729}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 729 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 731 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 731}
 [ChatService] Streaming callback invoked {chunks: Array(1017), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 731}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 731 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 733 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 733}
 [ChatService] Streaming callback invoked {chunks: Array(1018), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 733}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 733 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 734 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 734}
 [ChatService] Streaming callback invoked {chunks: Array(1019), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 734}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 734 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 735 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 735}
 [ChatService] Streaming callback invoked {chunks: Array(1020), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 735}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 735 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 737 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 737}
 [ChatService] Streaming callback invoked {chunks: Array(1021), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 737}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 737 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated response: 739 chars content: 40
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 739}
 [ChatService] Streaming callback invoked {chunks: Array(1022), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 739}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 739 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "]"
 [LLM API] tagBuffer: ]
 [LLM API] Accumulated response: 740 chars content: ]
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 740}
 [ChatService] Streaming callback invoked {chunks: Array(1023), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 740}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 740 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " \n\n"
 [LLM API] tagBuffer:  


 [LLM API] Accumulated response: 743 chars content:  


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 743}
 [ChatService] Streaming callback invoked {chunks: Array(1024), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 743}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 743 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "##"
 [LLM API] tagBuffer: ##
 [LLM API] Accumulated response: 745 chars content: ##
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 745}
 [ChatService] Streaming callback invoked {chunks: Array(1025), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 745}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 745 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Supporting"
 [LLM API] tagBuffer:  Supporting
 [LLM API] Accumulated response: 756 chars content:  Supporting
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 756}
 [ChatService] Streaming callback invoked {chunks: Array(1026), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 756}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 756 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Procedures"
 [LLM API] tagBuffer:  Procedures
 [LLM API] Accumulated response: 767 chars content:  Procedures
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 767}
 [ChatService] Streaming callback invoked {chunks: Array(1027), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 767}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 767 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 770 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 770}
 [ChatService] Streaming callback invoked {chunks: Array(1028), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 770}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 770 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "###"
 [LLM API] tagBuffer: ###
 [LLM API] Accumulated response: 773 chars content: ###
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 773}
 [ChatService] Streaming callback invoked {chunks: Array(1029), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 773}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 773 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 774 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 774}
 [ChatService] Streaming callback invoked {chunks: Array(1030), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 774}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 774 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 776 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 776}
 [ChatService] Streaming callback invoked {chunks: Array(1031), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 776}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 776 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 778 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 778}
 [ChatService] Streaming callback invoked {chunks: Array(1032), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 778}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 778 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 779 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 779}
 [ChatService] Streaming callback invoked {chunks: Array(1033), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 779}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 779 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 780 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 780}
 [ChatService] Streaming callback invoked {chunks: Array(1034), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 780}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 780 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 782 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 782}
 [ChatService] Streaming callback invoked {chunks: Array(1035), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 782}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 782 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated response: 784 chars content: 39
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 784}
 [ChatService] Streaming callback invoked {chunks: Array(1036), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 784}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 784 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 786 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 786}
 [ChatService] Streaming callback invoked {chunks: Array(1037), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 786}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 786 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "P"
 [LLM API] tagBuffer: P
 [LLM API] Accumulated response: 787 chars content: P
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 787}
 [ChatService] Streaming callback invoked {chunks: Array(1038), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 787}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 787 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "alo"
 [LLM API] tagBuffer: alo
 [LLM API] Accumulated response: 790 chars content: alo
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 790}
 [ChatService] Streaming callback invoked {chunks: Array(1039), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 790}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 790 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated response: 796 chars content:  Verde
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 796}
 [ChatService] Streaming callback invoked {chunks: Array(1040), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 796}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 796 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Bad"
 [LLM API] tagBuffer:  Bad
 [LLM API] Accumulated response: 800 chars content:  Bad
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 800}
 [ChatService] Streaming callback invoked {chunks: Array(1041), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 800}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 800 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated response: 804 chars content: ging
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 804}
 [ChatService] Streaming callback invoked {chunks: Array(1042), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 804}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 804 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Procedure"
 [LLM API] tagBuffer:  Procedure
 [LLM API] Accumulated response: 814 chars content:  Procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 814}
 [ChatService] Streaming callback invoked {chunks: Array(1043), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 814}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 814 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ")"
 [LLM API] tagBuffer: )
 [LLM API] Accumulated response: 815 chars content: )
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 815}
 [ChatService] Streaming callback invoked {chunks: Array(1044), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 815}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 815 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated response: 817 chars content:  -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 817}
 [ChatService] Streaming callback invoked {chunks: Array(1045), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 817}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 817 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated response: 821 chars content:  Rev
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 821}
 [ChatService] Streaming callback invoked {chunks: Array(1046), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 821}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 821 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 822 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 822}
 [ChatService] Streaming callback invoked {chunks: Array(1047), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 822}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 822 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 823 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 823}
 [ChatService] Streaming callback invoked {chunks: Array(1048), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 823}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 823 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "04"
 [LLM API] tagBuffer: 04
 [LLM API] Accumulated response: 825 chars content: 04
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 825}
 [ChatService] Streaming callback invoked {chunks: Array(1049), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 825}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 825 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated response: 826 chars content: 2
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 826}
 [ChatService] Streaming callback invoked {chunks: Array(1050), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 826}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 826 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 827 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 827}
 [ChatService] Streaming callback invoked {chunks: Array(1051), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 827}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 827 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "This"
 [LLM API] tagBuffer: This
 [LLM API] Accumulated response: 831 chars content: This
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 831}
 [ChatService] Streaming callback invoked {chunks: Array(1052), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 831}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 831 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 841 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 841}
 [ChatService] Streaming callback invoked {chunks: Array(1053), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 841}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 841 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " contains"
 [LLM API] tagBuffer:  contains
 [LLM API] Accumulated response: 850 chars content:  contains
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 850}
 [ChatService] Streaming callback invoked {chunks: Array(1054), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 850}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 850 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 854 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 854}
 [ChatService] Streaming callback invoked {chunks: Array(1055), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 854}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 854 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " AC"
 [LLM API] tagBuffer:  AC
 [LLM API] Accumulated response: 857 chars content:  AC
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 857}
 [ChatService] Streaming callback invoked {chunks: Array(1056), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 857}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 857 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "AD"
 [LLM API] tagBuffer: AD
 [LLM API] Accumulated response: 859 chars content: AD
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 859}
 [ChatService] Streaming callback invoked {chunks: Array(1057), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 859}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 859 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " badge"
 [LLM API] tagBuffer:  badge
 [LLM API] Accumulated response: 865 chars content:  badge
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 865}
 [ChatService] Streaming callback invoked {chunks: Array(1058), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 865}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 865 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated response: 878 chars content:  requirements
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 878}
 [ChatService] Streaming callback invoked {chunks: Array(1059), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 878}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 878 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 882 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 882}
 [ChatService] Streaming callback invoked {chunks: Array(1060), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 882}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 882 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " processes"
 [LLM API] tagBuffer:  processes
 [LLM API] Accumulated response: 892 chars content:  processes
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 892}
 [ChatService] Streaming callback invoked {chunks: Array(1061), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 892}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 892 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated response: 896 chars content:  for
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 896}
 [ChatService] Streaming callback invoked {chunks: Array(1062), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 896}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 896 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 899 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 899}
 [ChatService] Streaming callback invoked {chunks: Array(1063), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 899}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 899 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 902 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 902}
 [ChatService] Streaming callback invoked {chunks: Array(1064), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 902}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 902 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 907 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 907}
 [ChatService] Streaming callback invoked {chunks: Array(1065), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 907}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 907 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 914 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 914}
 [ChatService] Streaming callback invoked {chunks: Array(1066), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 914}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 914 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 915 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 915}
 [ChatService] Streaming callback invoked {chunks: Array(1067), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 915}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 915 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " including"
 [LLM API] tagBuffer:  including
 [LLM API] Accumulated response: 925 chars content:  including
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 925}
 [ChatService] Streaming callback invoked {chunks: Array(1068), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 925}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 925 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 928 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 928}
 [ChatService] Streaming callback invoked {chunks: Array(1069), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 928}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 928 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 929 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 929}
 [ChatService] Streaming callback invoked {chunks: Array(1070), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 929}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 929 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Processing"
 [LLM API] tagBuffer:  Processing
 [LLM API] Accumulated response: 940 chars content:  Processing
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 940}
 [ChatService] Streaming callback invoked {chunks: Array(1071), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 940}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 940 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 943 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 943}
 [ChatService] Streaming callback invoked {chunks: Array(1072), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 943}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 943 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 946 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 946}
 [ChatService] Streaming callback invoked {chunks: Array(1073), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 946}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 946 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 951 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 951}
 [ChatService] Streaming callback invoked {chunks: Array(1074), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 951}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 951 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 958 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 958}
 [ChatService] Streaming callback invoked {chunks: Array(1075), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 958}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 958 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " requests"
 [LLM API] tagBuffer:  requests
 [LLM API] Accumulated response: 967 chars content:  requests
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 967}
 [ChatService] Streaming callback invoked {chunks: Array(1076), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 967}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 967 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " through"
 [LLM API] tagBuffer:  through
 [LLM API] Accumulated response: 975 chars content:  through
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 975}
 [ChatService] Streaming callback invoked {chunks: Array(1077), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 975}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 975 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 979 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 979}
 [ChatService] Streaming callback invoked {chunks: Array(1078), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 979}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 979 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Security"
 [LLM API] tagBuffer:  Security
 [LLM API] Accumulated response: 988 chars content:  Security
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 988}
 [ChatService] Streaming callback invoked {chunks: Array(1079), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 988}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 988 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Screening"
 [LLM API] tagBuffer:  Screening
 [LLM API] Accumulated response: 998 chars content:  Screening
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 998}
 [ChatService] Streaming callback invoked {chunks: Array(1080), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 998}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 998 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Information"
 [LLM API] tagBuffer:  Information
 [LLM API] Accumulated response: 1010 chars content:  Information
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1010}
 [ChatService] Streaming callback invoked {chunks: Array(1081), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1010}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1010 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " System"
 [LLM API] tagBuffer:  System
 [LLM API] Accumulated response: 1017 chars content:  System
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1017}
 [ChatService] Streaming callback invoked {chunks: Array(1082), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1017}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1017 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 1019 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1019}
 [ChatService] Streaming callback invoked {chunks: Array(1083), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1019}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1019 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "SS"
 [LLM API] tagBuffer: SS
 [LLM API] Accumulated response: 1021 chars content: SS
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1021}
 [ChatService] Streaming callback invoked {chunks: Array(1084), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1021}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1021 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "IS"
 [LLM API] tagBuffer: IS
 [LLM API] Accumulated response: 1023 chars content: IS
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1023}
 [ChatService] Streaming callback invoked {chunks: Array(1085), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1023}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1023 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ")\n"
 [LLM API] tagBuffer: )

 [LLM API] Accumulated response: 1025 chars content: )

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1025}
 [ChatService] Streaming callback invoked {chunks: Array(1086), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1025}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1025 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1026 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1026}
 [ChatService] Streaming callback invoked {chunks: Array(1087), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1026}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1026 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Ens"
 [LLM API] tagBuffer:  Ens
 [LLM API] Accumulated response: 1030 chars content:  Ens
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1030}
 [ChatService] Streaming callback invoked {chunks: Array(1088), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1030}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1030 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "uring"
 [LLM API] tagBuffer: uring
 [LLM API] Accumulated response: 1035 chars content: uring
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1035}
 [ChatService] Streaming callback invoked {chunks: Array(1089), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1035}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1035 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " all"
 [LLM API] tagBuffer:  all
 [LLM API] Accumulated response: 1039 chars content:  all
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1039}
 [ChatService] Streaming callback invoked {chunks: Array(1090), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1039}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1039 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated response: 1052 chars content:  requirements
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1052}
 [ChatService] Streaming callback invoked {chunks: Array(1091), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1052}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1052 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated response: 1056 chars content:  are
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1056}
 [ChatService] Streaming callback invoked {chunks: Array(1092), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1056}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1056 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " met"
 [LLM API] tagBuffer:  met
 [LLM API] Accumulated response: 1060 chars content:  met
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1060}
 [ChatService] Streaming callback invoked {chunks: Array(1093), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1060}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1060 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " per"
 [LLM API] tagBuffer:  per
 [LLM API] Accumulated response: 1064 chars content:  per
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1064}
 [ChatService] Streaming callback invoked {chunks: Array(1094), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1064}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1064 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1068 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1068}
 [ChatService] Streaming callback invoked {chunks: Array(1095), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1068}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1068 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 1075 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1075}
 [ChatService] Streaming callback invoked {chunks: Array(1096), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1075}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1075 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 1089 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1089}
 [ChatService] Streaming callback invoked {chunks: Array(1097), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1089}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1089 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 1099 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1099}
 [ChatService] Streaming callback invoked {chunks: Array(1098), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1099}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1099 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 1100 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1100}
 [ChatService] Streaming callback invoked {chunks: Array(1099), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1100}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1100 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1102 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1102}
 [ChatService] Streaming callback invoked {chunks: Array(1100), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1102}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1102 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1104 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1104}
 [ChatService] Streaming callback invoked {chunks: Array(1101), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1104}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1104 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1105 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1105}
 [ChatService] Streaming callback invoked {chunks: Array(1102), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1105}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1105 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1106 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1106}
 [ChatService] Streaming callback invoked {chunks: Array(1103), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1106}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1106 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1108 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1108}
 [ChatService] Streaming callback invoked {chunks: Array(1104), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1108}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1108 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated response: 1110 chars content: 40
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1110}
 [ChatService] Streaming callback invoked {chunks: Array(1105), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1110}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1110 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 1111 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1111}
 [ChatService] Streaming callback invoked {chunks: Array(1106), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1111}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1111 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1112 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1112}
 [ChatService] Streaming callback invoked {chunks: Array(1107), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1112}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1112 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Managing"
 [LLM API] tagBuffer:  Managing
 [LLM API] Accumulated response: 1121 chars content:  Managing
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1121}
 [ChatService] Streaming callback invoked {chunks: Array(1108), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1121}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1121 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " AC"
 [LLM API] tagBuffer:  AC
 [LLM API] Accumulated response: 1124 chars content:  AC
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1124}
 [ChatService] Streaming callback invoked {chunks: Array(1109), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1124}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1124 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "AD"
 [LLM API] tagBuffer: AD
 [LLM API] Accumulated response: 1126 chars content: AD
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1126}
 [ChatService] Streaming callback invoked {chunks: Array(1110), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1126}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1126 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " badge"
 [LLM API] tagBuffer:  badge
 [LLM API] Accumulated response: 1132 chars content:  badge
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1132}
 [ChatService] Streaming callback invoked {chunks: Array(1111), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1132}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1132 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " issuance"
 [LLM API] tagBuffer:  issuance
 [LLM API] Accumulated response: 1141 chars content:  issuance
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1141}
 [ChatService] Streaming callback invoked {chunks: Array(1112), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1141}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1141 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 1145 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1145}
 [ChatService] Streaming callback invoked {chunks: Array(1113), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1145}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1145 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " enrollment"
 [LLM API] tagBuffer:  enrollment
 [LLM API] Accumulated response: 1156 chars content:  enrollment
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1156}
 [ChatService] Streaming callback invoked {chunks: Array(1114), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1156}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1156 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated response: 1159 chars content:  in
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1159}
 [ChatService] Streaming callback invoked {chunks: Array(1115), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1159}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1159 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1163 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1163}
 [ChatService] Streaming callback invoked {chunks: Array(1116), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1163}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1163 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Bi"
 [LLM API] tagBuffer:  Bi
 [LLM API] Accumulated response: 1166 chars content:  Bi
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1166}
 [ChatService] Streaming callback invoked {chunks: Array(1117), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1166}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1166 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "ometrics"
 [LLM API] tagBuffer: ometrics
 [LLM API] Accumulated response: 1174 chars content: ometrics
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1174}
 [ChatService] Streaming callback invoked {chunks: Array(1118), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1174}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1174 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " System"
 [LLM API] tagBuffer:  System
 [LLM API] Accumulated response: 1181 chars content:  System
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1181}
 [ChatService] Streaming callback invoked {chunks: Array(1119), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1181}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1181 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 1182 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1182}
 [ChatService] Streaming callback invoked {chunks: Array(1120), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1182}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1182 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1183 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1183}
 [ChatService] Streaming callback invoked {chunks: Array(1121), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1183}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1183 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Handling"
 [LLM API] tagBuffer:  Handling
 [LLM API] Accumulated response: 1192 chars content:  Handling
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1192}
 [ChatService] Streaming callback invoked {chunks: Array(1122), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1192}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1192 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 1195 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1195}
 [ChatService] Streaming callback invoked {chunks: Array(1123), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1195}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1195 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 1198 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1198}
 [ChatService] Streaming callback invoked {chunks: Array(1124), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1198}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1198 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 1203 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1203}
 [ChatService] Streaming callback invoked {chunks: Array(1125), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1203}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1203 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 1210 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1210}
 [ChatService] Streaming callback invoked {chunks: Array(1126), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1210}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1210 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " termin"
 [LLM API] tagBuffer:  termin
 [LLM API] Accumulated response: 1217 chars content:  termin
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1217}
 [ChatService] Streaming callback invoked {chunks: Array(1127), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1217}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1217 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "ations"
 [LLM API] tagBuffer: ations
 [LLM API] Accumulated response: 1223 chars content: ations
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1223}
 [ChatService] Streaming callback invoked {chunks: Array(1128), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1223}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1223 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " ["
 [LLM API] tagBuffer:  [
 [LLM API] Accumulated response: 1225 chars content:  [
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1225}
 [ChatService] Streaming callback invoked {chunks: Array(1129), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1225}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1225 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "Source"
 [LLM API] tagBuffer: Source
 [LLM API] Accumulated response: 1231 chars content: Source
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1231}
 [ChatService] Streaming callback invoked {chunks: Array(1130), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1231}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1231 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 1232 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1232}
 [ChatService] Streaming callback invoked {chunks: Array(1131), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1232}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1232 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 1233 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1233}
 [ChatService] Streaming callback invoked {chunks: Array(1132), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1233}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1233 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1235 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1235}
 [ChatService] Streaming callback invoked {chunks: Array(1133), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1235}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1235 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1237 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1237}
 [ChatService] Streaming callback invoked {chunks: Array(1134), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1237}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1237 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1238 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1238}
 [ChatService] Streaming callback invoked {chunks: Array(1135), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1238}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1238 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1239 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1239}
 [ChatService] Streaming callback invoked {chunks: Array(1136), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1239}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1239 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1241 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1241}
 [ChatService] Streaming callback invoked {chunks: Array(1137), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1241}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1241 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated response: 1243 chars content: 39
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1243}
 [ChatService] Streaming callback invoked {chunks: Array(1138), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1243}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1243 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "]\n\n"
 [LLM API] tagBuffer: ]


 [LLM API] Accumulated response: 1246 chars content: ]


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1246}
 [ChatService] Streaming callback invoked {chunks: Array(1139), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1246}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1246 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "###"
 [LLM API] tagBuffer: ###
 [LLM API] Accumulated response: 1249 chars content: ###
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1249}
 [ChatService] Streaming callback invoked {chunks: Array(1140), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1249}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1249 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Background"
 [LLM API] tagBuffer:  Background
 [LLM API] Accumulated response: 1260 chars content:  Background
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1260}
 [ChatService] Streaming callback invoked {chunks: Array(1141), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1260}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1260 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated response: 1275 chars content:  Investigations
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1275}
 [ChatService] Streaming callback invoked {chunks: Array(1142), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1275}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1275 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated response: 1279 chars content:  for
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1279}
 [ChatService] Streaming callback invoked {chunks: Array(1143), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1279}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1279 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 1282 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1282}
 [ChatService] Streaming callback invoked {chunks: Array(1144), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1282}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1282 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 1285 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1285}
 [ChatService] Streaming callback invoked {chunks: Array(1145), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1285}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1285 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 1290 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1290}
 [ChatService] Streaming callback invoked {chunks: Array(1146), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1290}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1290 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 1297 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1297}
 [ChatService] Streaming callback invoked {chunks: Array(1147), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1297}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1297 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated response: 1299 chars content:  -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1299}
 [ChatService] Streaming callback invoked {chunks: Array(1148), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1299}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1299 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 1300 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1300}
 [ChatService] Streaming callback invoked {chunks: Array(1149), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1300}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1300 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1302 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1302}
 [ChatService] Streaming callback invoked {chunks: Array(1150), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1302}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1302 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1304 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1304}
 [ChatService] Streaming callback invoked {chunks: Array(1151), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1304}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1304 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1305 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1305}
 [ChatService] Streaming callback invoked {chunks: Array(1152), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1305}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1305 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1306 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1306}
 [ChatService] Streaming callback invoked {chunks: Array(1153), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1306}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1306 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1308 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1308}
 [ChatService] Streaming callback invoked {chunks: Array(1154), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1308}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1308 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated response: 1310 chars content: 11
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1310}
 [ChatService] Streaming callback invoked {chunks: Array(1155), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1310}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1310 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 1311 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1311}
 [ChatService] Streaming callback invoked {chunks: Array(1156), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1311}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1311 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "This"
 [LLM API] tagBuffer: This
 [LLM API] Accumulated response: 1315 chars content: This
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1315}
 [ChatService] Streaming callback invoked {chunks: Array(1157), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1315}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1315 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 1325 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1325}
 [ChatService] Streaming callback invoked {chunks: Array(1158), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1325}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1325 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " provides"
 [LLM API] tagBuffer:  provides
 [LLM API] Accumulated response: 1334 chars content:  provides
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1334}
 [ChatService] Streaming callback invoked {chunks: Array(1159), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1334}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1334 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1338 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1338}
 [ChatService] Streaming callback invoked {chunks: Array(1160), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1338}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1338 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " investigative"
 [LLM API] tagBuffer:  investigative
 [LLM API] Accumulated response: 1352 chars content:  investigative
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1352}
 [ChatService] Streaming callback invoked {chunks: Array(1161), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1352}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1352 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " framework"
 [LLM API] tagBuffer:  framework
 [LLM API] Accumulated response: 1362 chars content:  framework
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1362}
 [ChatService] Streaming callback invoked {chunks: Array(1162), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1362}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1362 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 1366 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1366}
 [ChatService] Streaming callback invoked {chunks: Array(1163), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1366}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1366 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " methods"
 [LLM API] tagBuffer:  methods
 [LLM API] Accumulated response: 1374 chars content:  methods
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1374}
 [ChatService] Streaming callback invoked {chunks: Array(1164), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1374}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1374 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated response: 1378 chars content:  for
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1378}
 [ChatService] Streaming callback invoked {chunks: Array(1165), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1378}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1378 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " conducting"
 [LLM API] tagBuffer:  conducting
 [LLM API] Accumulated response: 1389 chars content:  conducting
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1389}
 [ChatService] Streaming callback invoked {chunks: Array(1166), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1389}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1389 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 1400 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1400}
 [ChatService] Streaming callback invoked {chunks: Array(1167), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1400}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1400 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated response: 1415 chars content:  investigations
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1415}
 [ChatService] Streaming callback invoked {chunks: Array(1168), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1415}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1415 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated response: 1418 chars content:  on
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1418}
 [ChatService] Streaming callback invoked {chunks: Array(1169), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1418}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1418 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " individuals"
 [LLM API] tagBuffer:  individuals
 [LLM API] Accumulated response: 1430 chars content:  individuals
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1430}
 [ChatService] Streaming callback invoked {chunks: Array(1170), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1430}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1430 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " seeking"
 [LLM API] tagBuffer:  seeking
 [LLM API] Accumulated response: 1438 chars content:  seeking
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1438}
 [ChatService] Streaming callback invoked {chunks: Array(1171), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1438}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1438 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 1441 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1441}
 [ChatService] Streaming callback invoked {chunks: Array(1172), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1441}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1441 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 1444 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1444}
 [ChatService] Streaming callback invoked {chunks: Array(1173), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1444}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1444 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 1449 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1449}
 [ChatService] Streaming callback invoked {chunks: Array(1174), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1449}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1449 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 1456 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1456}
 [ChatService] Streaming callback invoked {chunks: Array(1175), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1456}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1456 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " ["
 [LLM API] tagBuffer:  [
 [LLM API] Accumulated response: 1458 chars content:  [
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1458}
 [ChatService] Streaming callback invoked {chunks: Array(1176), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1458}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1458 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "Source"
 [LLM API] tagBuffer: Source
 [LLM API] Accumulated response: 1464 chars content: Source
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1464}
 [ChatService] Streaming callback invoked {chunks: Array(1177), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1464}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1464 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 1465 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1465}
 [ChatService] Streaming callback invoked {chunks: Array(1178), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1465}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1465 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 1466 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1466}
 [ChatService] Streaming callback invoked {chunks: Array(1179), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1466}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1466 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1468 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1468}
 [ChatService] Streaming callback invoked {chunks: Array(1180), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1468}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1468 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1470 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1470}
 [ChatService] Streaming callback invoked {chunks: Array(1181), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1470}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1470 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1471 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1471}
 [ChatService] Streaming callback invoked {chunks: Array(1182), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1471}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1471 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1472 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1472}
 [ChatService] Streaming callback invoked {chunks: Array(1183), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1472}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1472 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1474 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1474}
 [ChatService] Streaming callback invoked {chunks: Array(1184), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1474}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1474 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated response: 1476 chars content: 11
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1476}
 [ChatService] Streaming callback invoked {chunks: Array(1185), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1476}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1476 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "]\n\n"
 [LLM API] tagBuffer: ]


 [LLM API] Accumulated response: 1479 chars content: ]


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1479}
 [ChatService] Streaming callback invoked {chunks: Array(1186), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1479}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1479 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "##"
 [LLM API] tagBuffer: ##
 [LLM API] Accumulated response: 1481 chars content: ##
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1481}
 [ChatService] Streaming callback invoked {chunks: Array(1187), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1481}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1481 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " How"
 [LLM API] tagBuffer:  How
 [LLM API] Accumulated response: 1485 chars content:  How
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1485}
 [ChatService] Streaming callback invoked {chunks: Array(1188), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1485}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1485 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " They"
 [LLM API] tagBuffer:  They
 [LLM API] Accumulated response: 1490 chars content:  They
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1490}
 [ChatService] Streaming callback invoked {chunks: Array(1189), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1490}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1490 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Work"
 [LLM API] tagBuffer:  Work
 [LLM API] Accumulated response: 1495 chars content:  Work
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1495}
 [ChatService] Streaming callback invoked {chunks: Array(1190), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1495}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1495 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Together"
 [LLM API] tagBuffer:  Together
 [LLM API] Accumulated response: 1504 chars content:  Together
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1504}
 [ChatService] Streaming callback invoked {chunks: Array(1191), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1504}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1504 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 1507 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1507}
 [ChatService] Streaming callback invoked {chunks: Array(1192), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1507}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1507 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated response: 1508 chars content: 1
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1508}
 [ChatService] Streaming callback invoked {chunks: Array(1193), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1508}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1508 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 1509 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1509}
 [ChatService] Streaming callback invoked {chunks: Array(1194), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1509}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1509 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 1512 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1512}
 [ChatService] Streaming callback invoked {chunks: Array(1195), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1512}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1512 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1514 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1514}
 [ChatService] Streaming callback invoked {chunks: Array(1196), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1514}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1514 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1516 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1516}
 [ChatService] Streaming callback invoked {chunks: Array(1197), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1516}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1516 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1517 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1517}
 [ChatService] Streaming callback invoked {chunks: Array(1198), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1517}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1517 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1518 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1518}
 [ChatService] Streaming callback invoked {chunks: Array(1199), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1518}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1518 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1520 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1520}
 [ChatService] Streaming callback invoked {chunks: Array(1200), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1520}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1520 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "40"
 [LLM API] tagBuffer: 40
 [LLM API] Accumulated response: 1522 chars content: 40
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1522}
 [ChatService] Streaming callback invoked {chunks: Array(1201), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1522}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1522 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 1524 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1524}
 [ChatService] Streaming callback invoked {chunks: Array(1202), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1524}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1524 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated response: 1527 chars content:  is
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1527}
 [ChatService] Streaming callback invoked {chunks: Array(1203), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1527}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1527 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1531 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1531}
 [ChatService] Streaming callback invoked {chunks: Array(1204), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1531}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1531 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " overarching"
 [LLM API] tagBuffer:  overarching
 [LLM API] Accumulated response: 1543 chars content:  overarching
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1543}
 [ChatService] Streaming callback invoked {chunks: Array(1205), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1543}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1543 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated response: 1553 chars content:  procedure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1553}
 [ChatService] Streaming callback invoked {chunks: Array(1206), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1553}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1553 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated response: 1558 chars content:  that
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1558}
 [ChatService] Streaming callback invoked {chunks: Array(1207), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1558}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1558 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " author"
 [LLM API] tagBuffer:  author
 [LLM API] Accumulated response: 1565 chars content:  author
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1565}
 [ChatService] Streaming callback invoked {chunks: Array(1208), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1565}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1565 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "izes"
 [LLM API] tagBuffer: izes
 [LLM API] Accumulated response: 1569 chars content: izes
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1569}
 [ChatService] Streaming callback invoked {chunks: Array(1209), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1569}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1569 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 1572 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1572}
 [ChatService] Streaming callback invoked {chunks: Array(1210), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1572}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1572 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 1575 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1575}
 [ChatService] Streaming callback invoked {chunks: Array(1211), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1575}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1575 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 1580 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1580}
 [ChatService] Streaming callback invoked {chunks: Array(1212), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1580}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1580 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 1587 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1587}
 [ChatService] Streaming callback invoked {chunks: Array(1213), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1587}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1587 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 1588 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1588}
 [ChatService] Streaming callback invoked {chunks: Array(1214), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1588}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1588 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated response: 1589 chars content: 2
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1589}
 [ChatService] Streaming callback invoked {chunks: Array(1215), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1589}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1589 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 1590 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1590}
 [ChatService] Streaming callback invoked {chunks: Array(1216), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1590}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1590 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 1593 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1593}
 [ChatService] Streaming callback invoked {chunks: Array(1217), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1593}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1593 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1595 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1595}
 [ChatService] Streaming callback invoked {chunks: Array(1218), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1595}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1595 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1597 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1597}
 [ChatService] Streaming callback invoked {chunks: Array(1219), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1597}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1597 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1598 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1598}
 [ChatService] Streaming callback invoked {chunks: Array(1220), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1598}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1598 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1599 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1599}
 [ChatService] Streaming callback invoked {chunks: Array(1221), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1599}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1599 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1601 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1601}
 [ChatService] Streaming callback invoked {chunks: Array(1222), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1601}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1601 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "39"
 [LLM API] tagBuffer: 39
 [LLM API] Accumulated response: 1603 chars content: 39
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1603}
 [ChatService] Streaming callback invoked {chunks: Array(1223), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1603}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1603 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 1605 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1605}
 [ChatService] Streaming callback invoked {chunks: Array(1224), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1605}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1605 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " provides"
 [LLM API] tagBuffer:  provides
 [LLM API] Accumulated response: 1614 chars content:  provides
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1614}
 [ChatService] Streaming callback invoked {chunks: Array(1225), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1614}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1614 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1618 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1618}
 [ChatService] Streaming callback invoked {chunks: Array(1226), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1618}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1618 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " bad"
 [LLM API] tagBuffer:  bad
 [LLM API] Accumulated response: 1622 chars content:  bad
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1622}
 [ChatService] Streaming callback invoked {chunks: Array(1227), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1622}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1622 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "ging"
 [LLM API] tagBuffer: ging
 [LLM API] Accumulated response: 1626 chars content: ging
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1626}
 [ChatService] Streaming callback invoked {chunks: Array(1228), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1626}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1626 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 1630 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1630}
 [ChatService] Streaming callback invoked {chunks: Array(1229), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1630}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1630 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " administrative"
 [LLM API] tagBuffer:  administrative
 [LLM API] Accumulated response: 1645 chars content:  administrative
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1645}
 [ChatService] Streaming callback invoked {chunks: Array(1230), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1645}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1645 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " implementation"
 [LLM API] tagBuffer:  implementation
 [LLM API] Accumulated response: 1660 chars content:  implementation
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1660}
 [ChatService] Streaming callback invoked {chunks: Array(1231), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1660}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1660 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " \n"
 [LLM API] tagBuffer:  

 [LLM API] Accumulated response: 1662 chars content:  

 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1662}
 [ChatService] Streaming callback invoked {chunks: Array(1232), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1662}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1662 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated response: 1663 chars content: 3
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1663}
 [ChatService] Streaming callback invoked {chunks: Array(1233), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1663}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1663 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 1664 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1664}
 [ChatService] Streaming callback invoked {chunks: Array(1234), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1664}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1664 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 1667 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1667}
 [ChatService] Streaming callback invoked {chunks: Array(1235), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1667}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1667 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1669 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1669}
 [ChatService] Streaming callback invoked {chunks: Array(1236), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1669}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1669 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1671 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1671}
 [ChatService] Streaming callback invoked {chunks: Array(1237), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1671}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1671 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 1672 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1672}
 [ChatService] Streaming callback invoked {chunks: Array(1238), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1672}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1672 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 1673 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1673}
 [ChatService] Streaming callback invoked {chunks: Array(1239), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1673}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1673 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 1675 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1675}
 [ChatService] Streaming callback invoked {chunks: Array(1240), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1675}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1675 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated response: 1677 chars content: 11
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1677}
 [ChatService] Streaming callback invoked {chunks: Array(1241), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1677}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1677 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 1679 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1679}
 [ChatService] Streaming callback invoked {chunks: Array(1242), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1679}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1679 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " provides"
 [LLM API] tagBuffer:  provides
 [LLM API] Accumulated response: 1688 chars content:  provides
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1688}
 [ChatService] Streaming callback invoked {chunks: Array(1243), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1688}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1688 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 1692 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1692}
 [ChatService] Streaming callback invoked {chunks: Array(1244), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1692}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1692 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 1703 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1703}
 [ChatService] Streaming callback invoked {chunks: Array(1245), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1703}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1703 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " investigation"
 [LLM API] tagBuffer:  investigation
 [LLM API] Accumulated response: 1717 chars content:  investigation
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1717}
 [ChatService] Streaming callback invoked {chunks: Array(1246), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1717}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1717 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " requirements"
 [LLM API] tagBuffer:  requirements
 [LLM API] Accumulated response: 1730 chars content:  requirements
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1730}
 [ChatService] Streaming callback invoked {chunks: Array(1247), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1730}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1730 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "\n\n"
 [LLM API] tagBuffer: 


 [LLM API] Accumulated response: 1732 chars content: 


 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1732}
 [ChatService] Streaming callback invoked {chunks: Array(1248), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1732}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1732 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "All"
 [LLM API] tagBuffer: All
 [LLM API] Accumulated response: 1735 chars content: All
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1735}
 [ChatService] Streaming callback invoked {chunks: Array(1249), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1735}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1735 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated response: 1746 chars content:  procedures
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1746}
 [ChatService] Streaming callback invoked {chunks: Array(1250), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1746}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1746 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " reference"
 [LLM API] tagBuffer:  reference
 [LLM API] Accumulated response: 1756 chars content:  reference
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1756}
 [ChatService] Streaming callback invoked {chunks: Array(1251), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1756}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1756 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " each"
 [LLM API] tagBuffer:  each
 [LLM API] Accumulated response: 1761 chars content:  each
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1761}
 [ChatService] Streaming callback invoked {chunks: Array(1252), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1761}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1761 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " other"
 [LLM API] tagBuffer:  other
 [LLM API] Accumulated response: 1767 chars content:  other
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1767}
 [ChatService] Streaming callback invoked {chunks: Array(1253), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1767}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1767 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated response: 1770 chars content:  to
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1770}
 [ChatService] Streaming callback invoked {chunks: Array(1254), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1770}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1770 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ensure"
 [LLM API] tagBuffer:  ensure
 [LLM API] Accumulated response: 1777 chars content:  ensure
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1777}
 [ChatService] Streaming callback invoked {chunks: Array(1255), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1777}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1777 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated response: 1791 chars content:  comprehensive
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1791}
 [ChatService] Streaming callback invoked {chunks: Array(1256), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1791}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1791 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 1794 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1794}
 [ChatService] Streaming callback invoked {chunks: Array(1257), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1794}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1794 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 1797 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1797}
 [ChatService] Streaming callback invoked {chunks: Array(1258), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1797}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1797 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 1802 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1802}
 [ChatService] Streaming callback invoked {chunks: Array(1259), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1802}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1802 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 1809 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1809}
 [ChatService] Streaming callback invoked {chunks: Array(1260), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1809}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1809 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " management"
 [LLM API] tagBuffer:  management
 [LLM API] Accumulated response: 1820 chars content:  management
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1820}
 [ChatService] Streaming callback invoked {chunks: Array(1261), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1820}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1820 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated response: 1823 chars content:  at
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1823}
 [ChatService] Streaming callback invoked {chunks: Array(1262), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1823}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1823 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated response: 1828 chars content:  Palo
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1828}
 [ChatService] Streaming callback invoked {chunks: Array(1263), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1828}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1828 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated response: 1834 chars content:  Verde
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1834}
 [ChatService] Streaming callback invoked {chunks: Array(1264), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1834}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1834 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 1835 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1835}
 [ChatService] Streaming callback invoked {chunks: Array(1265), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1835}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1835 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated response: 1840 chars content:  with
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1840}
 [ChatService] Streaming callback invoked {chunks: Array(1266), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1840}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1840 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 1847 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1847}
 [ChatService] Streaming callback invoked {chunks: Array(1267), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1847}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1847 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " Authorization"
 [LLM API] tagBuffer:  Authorization
 [LLM API] Accumulated response: 1861 chars content:  Authorization
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1861}
 [ChatService] Streaming callback invoked {chunks: Array(1268), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1861}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1861 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated response: 1863 chars content:  (
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1863}
 [ChatService] Streaming callback invoked {chunks: Array(1269), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1863}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1863 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 1865 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1865}
 [ChatService] Streaming callback invoked {chunks: Array(1270), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1865}
 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1865 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 1867 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1867}
 [ChatService] Streaming callback invoked {chunks: Array(1271), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1867}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1867 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "-"
llm-api.service.ts:174 [LLM API] tagBuffer: -
llm-api.service.ts:280 [LLM API] Accumulated response: 1868 chars content: -
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1868}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1272), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1868}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1868 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "0"
llm-api.service.ts:174 [LLM API] tagBuffer: 0
llm-api.service.ts:280 [LLM API] Accumulated response: 1869 chars content: 0
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1869}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1273), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1869}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1869 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "SK"
llm-api.service.ts:174 [LLM API] tagBuffer: SK
llm-api.service.ts:280 [LLM API] Accumulated response: 1871 chars content: SK
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1871}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1274), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1871}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1871 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "40"
llm-api.service.ts:174 [LLM API] tagBuffer: 40
llm-api.service.ts:280 [LLM API] Accumulated response: 1873 chars content: 40
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1873}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1275), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1873}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1873 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: ")"
llm-api.service.ts:174 [LLM API] tagBuffer: )
llm-api.service.ts:280 [LLM API] Accumulated response: 1874 chars content: )
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1874}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1276), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1874}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1874 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " serving"
llm-api.service.ts:174 [LLM API] tagBuffer:  serving
llm-api.service.ts:280 [LLM API] Accumulated response: 1882 chars content:  serving
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1882}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1277), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1882}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1882 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " as"
llm-api.service.ts:174 [LLM API] tagBuffer:  as
llm-api.service.ts:280 [LLM API] Accumulated response: 1885 chars content:  as
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1885}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1278), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1885}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1885 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " the"
llm-api.service.ts:174 [LLM API] tagBuffer:  the
llm-api.service.ts:280 [LLM API] Accumulated response: 1889 chars content:  the
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1889}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1279), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1889}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1889 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " central"
llm-api.service.ts:174 [LLM API] tagBuffer:  central
llm-api.service.ts:280 [LLM API] Accumulated response: 1897 chars content:  central
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1897}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1280), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1897}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1897 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " coordinating"
llm-api.service.ts:174 [LLM API] tagBuffer:  coordinating
llm-api.service.ts:280 [LLM API] Accumulated response: 1910 chars content:  coordinating
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1910}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1281), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1910}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1910 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: " procedure"
llm-api.service.ts:174 [LLM API] tagBuffer:  procedure
llm-api.service.ts:280 [LLM API] Accumulated response: 1920 chars content:  procedure
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1920}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1282), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1920}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1920 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: ".\n"
llm-api.service.ts:174 [LLM API] tagBuffer: .

llm-api.service.ts:280 [LLM API] Accumulated response: 1922 chars content: .

llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1922}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1283), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1922}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1922 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "</"
llm-api.service.ts:174 [LLM API] tagBuffer: </
llm-api.service.ts:280 [LLM API] Accumulated response: 1924 chars content: </
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1924}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1284), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1924}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1924 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
llm-api.service.ts:157 [LLM API] Processing line: data: "response"
llm-api.service.ts:174 [LLM API] tagBuffer: response
llm-api.service.ts:280 [LLM API] Accumulated response: 1932 chars content: response
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1932}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1285), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1932}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1932 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
markdown-content.component.ts:39 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
markdown-content.component.ts:40 [MarkdownContent] RAG docs: 0
markdown-content.component.ts:41 [MarkdownContent] Citation metadata: undefined
markdown-content.component.ts:42 [MarkdownContent] Citation metadata keys: 0
markdown-content.component.ts:81 [MarkdownContent] Found 0 citation links to attach handlers to
llm-api.service.ts:157 [LLM API] Processing line: data: ">"
llm-api.service.ts:174 [LLM API] tagBuffer: >
llm-api.service.ts:280 [LLM API] Accumulated response: 1933 chars content: >
llm-api.service.ts:303 [LLM API] Calling onChunk with: {thinkingLength: 3722, toolingLength: 97, responseLength: 1933}
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1286), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1933}
chat.service.ts:324 [ChatService] updateMessageConent called, messageId: ypoid0pym content length: 1933 first 100 chars: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
markdown-content.component.ts:39 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
markdown-content.component.ts:40 [MarkdownContent] RAG docs: 0
markdown-content.component.ts:41 [MarkdownContent] Citation metadata: undefined
markdown-content.component.ts:42 [MarkdownContent] Citation metadata keys: 0
markdown-content.component.ts:81 [MarkdownContent] Found 0 citation links to attach handlers to
llm-api.service.ts:157 [LLM API] Processing line: followup_and_topic_questions: "{\n    \"topic\": \
llm-api.service.ts:157 [LLM API] Processing line: metadata: {"{C387180F-5A45-4B5A-96C3-C26F0D11D6CB"
llm-api.service.ts:412 [LLM API] Received metadata with 20 documents
llm-api.service.ts:413 [LLM API] First 3 metadata keys: (3) ['{C387180F-5A45-4B5A-96C3-C26F0D11D6CB', '{CB9F6C4E-4FF9-4AF7-B398-5A66F92758B1', '{FA205FD1-7739-C377-84CE-7B63C3A00000']
chat.service.ts:98 [ChatService] Streaming callback invoked {chunks: Array(1287), currentChunk: {…}, isComplete: true, error: undefined, messageId: undefined}
chat.service.ts:118 [ChatService] Processing chunk: {thinkingLength: 3722, toolingLength: 97, responseLength: 1933}
chat.service.ts:142 [ChatService] Updating citation metadata with 20 keys
chat.service.ts:296 [ChatService] updateMessageCitationMetadata called for message ypoid0pym with metadata keys: (20) ['{C387180F-5A45-4B5A-96C3-C26F0D11D6CB', '{CB9F6C4E-4FF9-4AF7-B398-5A66F92758B1', '{FA205FD1-7739-C377-84CE-7B63C3A00000', '{293EE29E-A38F-4044-BB23-2F20D35E2300', '{5745EE79-863B-4777-A1C1-3ECF6E4FCFF2', '{9F69364A-E6E6-4D01-A1AC-A7E9A1793E10', '{11AF8B8B-7F17-4101-9649-1094CE3909AA', '{C2DE6CFD-E6A0-4825-8F02-381BA55349B5', '{CBCD67CC-60E7-46EE-811F-D8EB5D07E72A', '{C32A2B4C-E8F2-4B8E-88CE-E26D178C0AB1', '{73FF30FA-FE19-C5C0-9F01-71F171C00000', '{AF8146CC-E8D5-C2A3-9421-71F171C00000', '{D8805DBE-6C3F-C4BE-9EF2-7B63C3900000', '{4999779D-E7E3-4E66-A029-046AD2CED1B2', '{0A7369D5-0CBB-CB9E-97CD-828469F00000', '{DF06D4F8-E1CF-49A6-A839-1FDE62086027', '{876A0C2F-617D-C01B-9CCE-93B296A00000', '{DCB447B9-FA52-42E0-A3DA-B3FB16C160D9', '{4EF4DD1D-E964-4EF4-A850-22CD98C13E3A', '{393DDF27-812F-C387-9E24-828469F00000']
chat.service.ts:307 [ChatService] Citation metadata updated in conversations
markdown-content.component.ts:39 [MarkdownContent] Content changed: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorte
markdown-content.component.ts:40 [MarkdownContent] RAG docs: 0
markdown-content.component.ts:41 [MarkdownContent] Citation metadata: {{C387180F-5A45-4B5A-96C3-C26F0D11D6CB: {…}, {CB9F6C4E-4FF9-4AF7-B398-5A66F92758B1: {…}, {FA205FD1-7739-C377-84CE-7B63C3A00000: {…}, {293EE29E-A38F-4044-BB23-2F20D35E2300: {…}, {5745EE79-863B-4777-A1C1-3ECF6E4FCFF2: {…}, …}
markdown-content.component.ts:42 [MarkdownContent] Citation metadata keys: 20
source-citation.service.ts:147 [SourceCitationService] Processing content: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorted access, with **20DP-0SK40, Access Authorization** being the primary procedure that manages unescor
source-citation.service.ts:148 [SourceCitationService] RAG documents count: 0
source-citation.service.ts:150 [SourceCitationService] Citation metadata: present with 20 keys: (3) ['{C387180F-5A45-4B5A-96C3-C26F0D11D6CB', '{CB9F6C4E-4FF9-4AF7-B398-5A66F92758B1', '{FA205FD1-7739-C377-84CE-7B63C3A00000']
source-citation.service.ts:174 [SourceCitationService] Found citation: [Source: 20DP-0SK40] identifiers: 20DP-0SK40
source-citation.service.ts:181 [SourceCitationService] hasUUIDs: false citationMetadata exists: true
source-citation.service.ts:342  [SourceCitationService] No document found for source: 20DP-0SK40
(anonymous) @ source-citation.service.ts:342
replaceSourceCitationsWithHTML @ source-citation.service.ts:173
(anonymous) @ markdown-content.component.ts:48
run @ resource-DalzMB4W.mjs:205
runEffectsInView @ debug_node-DTOmNMDH.mjs:8756
refreshView @ debug_node-DTOmNMDH.mjs:8916
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
then @ zone.js:2732
(anonymous) @ backend_bundle.js:62
invoke @ zone.js:398
run @ zone.js:113
In @ backend_bundle.js:4
2 @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
profiler @ debug_node-DTOmNMDH.mjs:660
executeTemplate @ debug_node-DTOmNMDH.mjs:7139
refreshView @ debug_node-DTOmNMDH.mjs:8888
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
source-citation.service.ts:174 [SourceCitationService] Found citation: [Source: 20DP-0SK39] identifiers: 20DP-0SK39
source-citation.service.ts:181 [SourceCitationService] hasUUIDs: false citationMetadata exists: true
source-citation.service.ts:342  [SourceCitationService] No document found for source: 20DP-0SK39
(anonymous) @ source-citation.service.ts:342
replaceSourceCitationsWithHTML @ source-citation.service.ts:173
(anonymous) @ markdown-content.component.ts:48
run @ resource-DalzMB4W.mjs:205
runEffectsInView @ debug_node-DTOmNMDH.mjs:8756
refreshView @ debug_node-DTOmNMDH.mjs:8916
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
then @ zone.js:2732
(anonymous) @ backend_bundle.js:62
invoke @ zone.js:398
run @ zone.js:113
In @ backend_bundle.js:4
2 @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
profiler @ debug_node-DTOmNMDH.mjs:660
executeTemplate @ debug_node-DTOmNMDH.mjs:7139
refreshView @ debug_node-DTOmNMDH.mjs:8888
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
source-citation.service.ts:174 [SourceCitationService] Found citation: [Source: 20DP-0SK11] identifiers: 20DP-0SK11
source-citation.service.ts:181 [SourceCitationService] hasUUIDs: false citationMetadata exists: true
source-citation.service.ts:342  [SourceCitationService] No document found for source: 20DP-0SK11
(anonymous) @ source-citation.service.ts:342
replaceSourceCitationsWithHTML @ source-citation.service.ts:173
(anonymous) @ markdown-content.component.ts:48
run @ resource-DalzMB4W.mjs:205
runEffectsInView @ debug_node-DTOmNMDH.mjs:8756
refreshView @ debug_node-DTOmNMDH.mjs:8916
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
detectChangesInView @ debug_node-DTOmNMDH.mjs:9120
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInEmbeddedViews @ debug_node-DTOmNMDH.mjs:9025
refreshView @ debug_node-DTOmNMDH.mjs:8917
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
then @ zone.js:2732
(anonymous) @ backend_bundle.js:62
invoke @ zone.js:398
run @ zone.js:113
In @ backend_bundle.js:4
2 @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
(anonymous) @ backend_bundle.js:62
profiler @ debug_node-DTOmNMDH.mjs:660
executeTemplate @ debug_node-DTOmNMDH.mjs:7139
refreshView @ debug_node-DTOmNMDH.mjs:8888
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewIfAttached @ debug_node-DTOmNMDH.mjs:9068
detectChangesInComponent @ debug_node-DTOmNMDH.mjs:9056
detectChangesInChildComponents @ debug_node-DTOmNMDH.mjs:9134
refreshView @ debug_node-DTOmNMDH.mjs:8943
detectChangesInView @ debug_node-DTOmNMDH.mjs:9108
detectChangesInViewWhileDirty @ debug_node-DTOmNMDH.mjs:8797
detectChangesInternal @ debug_node-DTOmNMDH.mjs:8785
synchronizeOnce @ debug_node-DTOmNMDH.mjs:20117
synchronize @ debug_node-DTOmNMDH.mjs:20076
tickImpl @ debug_node-DTOmNMDH.mjs:20049
_tick @ debug_node-DTOmNMDH.mjs:20038
(anonymous) @ debug_node-DTOmNMDH.mjs:29476
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
run @ debug_node-DTOmNMDH.mjs:16342
next @ debug_node-DTOmNMDH.mjs:29473
ConsumerObserver2.next @ Subscriber.js:96
Subscriber2._next @ Subscriber.js:63
Subscriber2.next @ Subscriber.js:34
(anonymous) @ Subject.js:41
errorContext @ errorContext.js:19
Subject2.next @ Subject.js:31
emit @ debug_node-DTOmNMDH.mjs:16030
checkStable @ debug_node-DTOmNMDH.mjs:16410
onHasTask @ debug_node-DTOmNMDH.mjs:16524
hasTask @ zone.js:451
_updateTaskCount @ zone.js:471
_updateTaskCount @ zone.js:266
runTask @ zone.js:179
drainMicroTaskQueue @ zone.js:612
Promise.then
nativeScheduleMicroTask @ zone.js:588
scheduleMicroTask @ zone.js:599
scheduleTask @ zone.js:420
onScheduleTask @ debug_node-DTOmNMDH.mjs:16155
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
Promise.then
(anonymous) @ zone.js:2779
ZoneAwarePromise @ zone.js:2701
Ctor.then @ zone.js:2778
resolvePromise @ zone.js:2422
resolve @ zone.js:2559
step @ main.js:40
fulfilled @ main.js:28
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
invoke @ zone.js:398
onInvoke @ debug_node-DTOmNMDH.mjs:16496
invoke @ zone.js:397
run @ zone.js:113
(anonymous) @ zone.js:2537
invokeTask @ zone.js:431
(anonymous) @ debug_node-DTOmNMDH.mjs:16160
onInvokeTask @ debug_node-DTOmNMDH.mjs:16160
invokeTask @ zone.js:430
onInvokeTask @ debug_node-DTOmNMDH.mjs:16483
invokeTask @ zone.js:430
runTask @ zone.js:161
drainMicroTaskQueue @ zone.js:612
Zone - Promise.then
onScheduleTask @ debug_node-DTOmNMDH.mjs:16154
scheduleTask @ zone.js:411
onScheduleTask @ zone.js:273
scheduleTask @ zone.js:411
scheduleTask @ zone.js:207
scheduleMicroTask @ zone.js:227
scheduleResolveOrReject @ zone.js:2527
resolvePromise @ zone.js:2461
(anonymous) @ zone.js:2369
(anonymous) @ zone.js:2385
source-citation.service.ts:350 [SourceCitationService] Processed result (first 200 chars): 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorted access, with **20DP-0SK40, Access Authorization** being the primary procedure that manages unescor
markdown-content.component.ts:49 [MarkdownContent] After citation processing: 
Based on my search of Palo Verde procedures, there are several key procedures that manage unescorted access, with **20DP-0SK40, Access Authorization** being the primary procedure that manages unescor
markdown-content.component.ts:81 [MarkdownContent] Found 0 citation links to attach handlers to
[NEW] Explain Console errors by using Copilot in Edge: click
         
         to explain an error. 
        Learn more
        Don't show again
markdown-content.component.ts:81 [MarkdownContent] Found 0 citation links to attach handlers to
