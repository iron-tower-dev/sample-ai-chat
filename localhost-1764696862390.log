 [MarkdownContent] Content changed: Thinking
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 
<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 0, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(1), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 0, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "The"
 [LLM API] tagBuffer: The
 [LLM API] Accumulated thinking: 3 chars
 [LLM API] Calling onChunk with: {thinkingLength: 3, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(2), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 3, toolingLength: 0, responseLength: 0}
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " user"
 [LLM API] tagBuffer:  user
 [LLM API] Accumulated thinking: 8 chars
 [LLM API] Calling onChunk with: {thinkingLength: 8, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(3), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 8, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 11 chars
 [LLM API] Calling onChunk with: {thinkingLength: 11, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(4), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 11, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " asking"
 [LLM API] tagBuffer:  asking
 [LLM API] Accumulated thinking: 18 chars
 [LLM API] Calling onChunk with: {thinkingLength: 18, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(5), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 18, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " about"
 [LLM API] tagBuffer:  about
 [LLM API] Accumulated thinking: 24 chars
 [LLM API] Calling onChunk with: {thinkingLength: 24, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(6), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 24, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 26 chars
 [LLM API] Calling onChunk with: {thinkingLength: 26, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(7), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 26, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 36 chars
 [LLM API] Calling onChunk with: {thinkingLength: 36, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(8), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 36, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 41 chars
 [LLM API] Calling onChunk with: {thinkingLength: 41, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(9), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 41, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " manages"
 [LLM API] tagBuffer:  manages
 [LLM API] Accumulated thinking: 49 chars
 [LLM API] Calling onChunk with: {thinkingLength: 49, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(10), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 49, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 52 chars
 [LLM API] Calling onChunk with: {thinkingLength: 52, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(11), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 52, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 55 chars
 [LLM API] Calling onChunk with: {thinkingLength: 55, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(12), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 55, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 60 chars
 [LLM API] Calling onChunk with: {thinkingLength: 60, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(13), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 60, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 67 chars
 [LLM API] Calling onChunk with: {thinkingLength: 67, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(14), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 67, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated thinking: 70 chars
 [LLM API] Calling onChunk with: {thinkingLength: 70, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(15), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 70, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated thinking: 75 chars
 [LLM API] Calling onChunk with: {thinkingLength: 75, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(16), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 75, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 81 chars
 [LLM API] Calling onChunk with: {thinkingLength: 81, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(17), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 81, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Nuclear"
 [LLM API] tagBuffer:  Nuclear
 [LLM API] Accumulated thinking: 89 chars
 [LLM API] Calling onChunk with: {thinkingLength: 89, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(18), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 89, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Generating"
 [LLM API] tagBuffer:  Generating
 [LLM API] Accumulated thinking: 100 chars
 [LLM API] Calling onChunk with: {thinkingLength: 100, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(19), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 100, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Station"
 [LLM API] tagBuffer:  Station
 [LLM API] Accumulated thinking: 108 chars
 [LLM API] Calling onChunk with: {thinkingLength: 108, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(20), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 108, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 109 chars
 [LLM API] Calling onChunk with: {thinkingLength: 109, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(21), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 109, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 114 chars
 [LLM API] Calling onChunk with: {thinkingLength: 114, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(22), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 114, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 117 chars
 [LLM API] Calling onChunk with: {thinkingLength: 117, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(23), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 117, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 119 chars
 [LLM API] Calling onChunk with: {thinkingLength: 119, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(24), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 119, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedural"
 [LLM API] tagBuffer:  procedural
 [LLM API] Accumulated thinking: 130 chars
 [LLM API] Calling onChunk with: {thinkingLength: 130, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(25), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 130, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " question"
 [LLM API] tagBuffer:  question
 [LLM API] Accumulated thinking: 139 chars
 [LLM API] Calling onChunk with: {thinkingLength: 139, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(26), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 139, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 144 chars
 [LLM API] Calling onChunk with: {thinkingLength: 144, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(27), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 144, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " would"
 [LLM API] tagBuffer:  would
 [LLM API] Accumulated thinking: 150 chars
 [LLM API] Calling onChunk with: {thinkingLength: 150, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(28), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 150, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " likely"
 [LLM API] tagBuffer:  likely
 [LLM API] Accumulated thinking: 157 chars
 [LLM API] Calling onChunk with: {thinkingLength: 157, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(29), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 157, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 160 chars
 [LLM API] Calling onChunk with: {thinkingLength: 160, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(30), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 160, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " covered"
 [LLM API] tagBuffer:  covered
 [LLM API] Accumulated thinking: 168 chars
 [LLM API] Calling onChunk with: {thinkingLength: 168, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(31), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 168, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 171 chars
 [LLM API] Calling onChunk with: {thinkingLength: 171, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(32), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 171, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " security"
 [LLM API] tagBuffer:  security
 [LLM API] Accumulated thinking: 180 chars
 [LLM API] Calling onChunk with: {thinkingLength: 180, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(33), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 180, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " or"
 [LLM API] tagBuffer:  or
 [LLM API] Accumulated thinking: 183 chars
 [LLM API] Calling onChunk with: {thinkingLength: 183, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(34), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 183, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 190 chars
 [LLM API] Calling onChunk with: {thinkingLength: 190, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(35), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 190, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " control"
 [LLM API] tagBuffer:  control
 [LLM API] Accumulated thinking: 198 chars
 [LLM API] Calling onChunk with: {thinkingLength: 198, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(36), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 198, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 209 chars
 [LLM API] Calling onChunk with: {thinkingLength: 209, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(37), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 209, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 210 chars
 [LLM API] Calling onChunk with: {thinkingLength: 210, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(38), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 210, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \n\n"
 [LLM API] tagBuffer:  


 [LLM API] Accumulated thinking: 213 chars
 [LLM API] Calling onChunk with: {thinkingLength: 213, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(39), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 213, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "I"
 [LLM API] tagBuffer: I
 [LLM API] Accumulated thinking: 214 chars
 [LLM API] Calling onChunk with: {thinkingLength: 214, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(40), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 214, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " should"
 [LLM API] tagBuffer:  should
 [LLM API] Accumulated thinking: 221 chars
 [LLM API] Calling onChunk with: {thinkingLength: 221, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(41), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 221, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " use"
 [LLM API] tagBuffer:  use
 [LLM API] Accumulated thinking: 225 chars
 [LLM API] Calling onChunk with: {thinkingLength: 225, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(42), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 225, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 229 chars
 [LLM API] Calling onChunk with: {thinkingLength: 229, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(43), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 229, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 236 chars
 [LLM API] Calling onChunk with: {thinkingLength: 236, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(44), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 236, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "doc"
 [LLM API] tagBuffer: doc
 [LLM API] Accumulated thinking: 239 chars
 [LLM API] Calling onChunk with: {thinkingLength: 239, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(45), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 239, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " function"
 [LLM API] tagBuffer:  function
 [LLM API] Accumulated thinking: 248 chars
 [LLM API] Calling onChunk with: {thinkingLength: 248, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(46), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 248, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 251 chars
 [LLM API] Calling onChunk with: {thinkingLength: 251, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(47), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 251, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 258 chars
 [LLM API] Calling onChunk with: {thinkingLength: 258, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(48), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 258, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 262 chars
 [LLM API] Calling onChunk with: {thinkingLength: 262, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(49), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 262, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 272 chars
 [LLM API] Calling onChunk with: {thinkingLength: 272, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(50), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 272, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 280 chars
 [LLM API] Calling onChunk with: {thinkingLength: 280, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(51), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 280, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 283 chars
 [LLM API] Calling onChunk with: {thinkingLength: 283, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(52), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 283, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 286 chars
 [LLM API] Calling onChunk with: {thinkingLength: 286, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(53), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 286, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 289 chars
 [LLM API] Calling onChunk with: {thinkingLength: 289, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(54), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 289, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 294 chars
 [LLM API] Calling onChunk with: {thinkingLength: 294, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(55), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 294, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 301 chars
 [LLM API] Calling onChunk with: {thinkingLength: 301, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(56), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 301, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 312 chars
 [LLM API] Calling onChunk with: {thinkingLength: 312, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(57), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 312, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 313 chars
 [LLM API] Calling onChunk with: {thinkingLength: 313, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(58), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 313, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 315 chars
 [LLM API] Calling onChunk with: {thinkingLength: 315, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(59), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 315, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "'ll"
 [LLM API] tagBuffer: 'll
 [LLM API] Accumulated thinking: 318 chars
 [LLM API] Calling onChunk with: {thinkingLength: 318, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(60), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 318, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 325 chars
 [LLM API] Calling onChunk with: {thinkingLength: 325, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(61), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 325, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 328 chars
 [LLM API] Calling onChunk with: {thinkingLength: 328, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(62), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 328, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 332 chars
 [LLM API] Calling onChunk with: {thinkingLength: 332, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(63), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 332, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " e"
 [LLM API] tagBuffer:  e
 [LLM API] Accumulated thinking: 334 chars
 [LLM API] Calling onChunk with: {thinkingLength: 334, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(64), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 334, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Doc"
 [LLM API] tagBuffer: Doc
 [LLM API] Accumulated thinking: 337 chars
 [LLM API] Calling onChunk with: {thinkingLength: 337, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(65), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 337, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " collection"
 [LLM API] tagBuffer:  collection
 [LLM API] Accumulated thinking: 348 chars
 [LLM API] Calling onChunk with: {thinkingLength: 348, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(66), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 348, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " since"
 [LLM API] tagBuffer:  since
 [LLM API] Accumulated thinking: 354 chars
 [LLM API] Calling onChunk with: {thinkingLength: 354, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(67), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 354, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 359 chars
 [LLM API] Calling onChunk with: {thinkingLength: 359, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(68), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 359, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " contains"
 [LLM API] tagBuffer:  contains
 [LLM API] Accumulated thinking: 368 chars
 [LLM API] Calling onChunk with: {thinkingLength: 368, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(69), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 368, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " plant"
 [LLM API] tagBuffer:  plant
 [LLM API] Accumulated thinking: 374 chars
 [LLM API] Calling onChunk with: {thinkingLength: 374, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(70), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 374, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-specific"
 [LLM API] tagBuffer: -specific
 [LLM API] Accumulated thinking: 383 chars
 [LLM API] Calling onChunk with: {thinkingLength: 383, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(71), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 383, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 394 chars
 [LLM API] Calling onChunk with: {thinkingLength: 394, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(72), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 394, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 398 chars
 [LLM API] Calling onChunk with: {thinkingLength: 398, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(73), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 398, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 408 chars
 [LLM API] Calling onChunk with: {thinkingLength: 408, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(74), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 408, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 411 chars
 [LLM API] Calling onChunk with: {thinkingLength: 411, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(75), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 411, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Let"
 [LLM API] tagBuffer: Let
 [LLM API] Accumulated thinking: 414 chars
 [LLM API] Calling onChunk with: {thinkingLength: 414, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(76), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 414, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 417 chars
 [LLM API] Calling onChunk with: {thinkingLength: 417, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(77), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 417, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 424 chars
 [LLM API] Calling onChunk with: {thinkingLength: 424, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(78), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 424, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 428 chars
 [LLM API] Calling onChunk with: {thinkingLength: 428, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(79), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 428, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " terms"
 [LLM API] tagBuffer:  terms
 [LLM API] Accumulated thinking: 434 chars
 [LLM API] Calling onChunk with: {thinkingLength: 434, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(80), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 434, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " like"
 [LLM API] tagBuffer:  like
 [LLM API] Accumulated thinking: 439 chars
 [LLM API] Calling onChunk with: {thinkingLength: 439, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(81), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 439, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 441 chars
 [LLM API] Calling onChunk with: {thinkingLength: 441, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(82), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 441, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "un"
 [LLM API] tagBuffer: un
 [LLM API] Accumulated thinking: 443 chars
 [LLM API] Calling onChunk with: {thinkingLength: 443, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(83), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 443, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 446 chars
 [LLM API] Calling onChunk with: {thinkingLength: 446, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(84), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 446, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 451 chars
 [LLM API] Calling onChunk with: {thinkingLength: 451, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(85), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 451, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 458 chars
 [LLM API] Calling onChunk with: {thinkingLength: 458, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(86), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 458, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\","
 [LLM API] tagBuffer: ",
 [LLM API] Accumulated thinking: 460 chars
 [LLM API] Calling onChunk with: {thinkingLength: 460, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(87), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 460, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 462 chars
 [LLM API] Calling onChunk with: {thinkingLength: 462, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(88), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 462, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "access"
 [LLM API] tagBuffer: access
 [LLM API] Accumulated thinking: 468 chars
 [LLM API] Calling onChunk with: {thinkingLength: 468, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(89), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 468, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " control"
 [LLM API] tagBuffer:  control
 [LLM API] Accumulated thinking: 476 chars
 [LLM API] Calling onChunk with: {thinkingLength: 476, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(90), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 476, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\","
 [LLM API] tagBuffer: ",
 [LLM API] Accumulated thinking: 478 chars
 [LLM API] Calling onChunk with: {thinkingLength: 478, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(91), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 478, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " or"
 [LLM API] tagBuffer:  or
 [LLM API] Accumulated thinking: 481 chars
 [LLM API] Calling onChunk with: {thinkingLength: 481, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(92), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 481, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 483 chars
 [LLM API] Calling onChunk with: {thinkingLength: 483, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(93), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 483, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "security"
 [LLM API] tagBuffer: security
 [LLM API] Accumulated thinking: 491 chars
 [LLM API] Calling onChunk with: {thinkingLength: 491, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(94), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 491, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 502 chars
 [LLM API] Calling onChunk with: {thinkingLength: 502, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(95), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 502, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 503 chars
 [LLM API] Calling onChunk with: {thinkingLength: 503, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(96), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 503, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 506 chars
 [LLM API] Calling onChunk with: {thinkingLength: 506, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(97), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 506, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " find"
 [LLM API] tagBuffer:  find
 [LLM API] Accumulated thinking: 511 chars
 [LLM API] Calling onChunk with: {thinkingLength: 511, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(98), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 511, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " relevant"
 [LLM API] tagBuffer:  relevant
 [LLM API] Accumulated thinking: 520 chars
 [LLM API] Calling onChunk with: {thinkingLength: 520, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(99), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 520, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " documents"
 [LLM API] tagBuffer:  documents
 [LLM API] Accumulated thinking: 530 chars
 [LLM API] Calling onChunk with: {thinkingLength: 530, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(100), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 530, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 531 chars
 [LLM API] Calling onChunk with: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(101), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(102), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(103), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: tool: "{\"action\": \"searching for unescorted acc
 [LLM API] FOUND TOOL EVENT, line: tool: "{\"action\": \"searching for unescorted access procedures\"}"
 [LLM API] Tool string to parse: "{\"action\": \"searching for unescorted access procedures\"}"
 [LLM API] Parsed tool JSON: {"action": "searching for unescorted access procedures"}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(104), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 531, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "I"
 [LLM API] tagBuffer: I
 [LLM API] Accumulated thinking: 532 chars
 [LLM API] Calling onChunk with: {thinkingLength: 532, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(105), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 532, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " have"
 [LLM API] tagBuffer:  have
 [LLM API] Accumulated thinking: 537 chars
 [LLM API] Calling onChunk with: {thinkingLength: 537, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(106), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 537, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 543 chars
 [LLM API] Calling onChunk with: {thinkingLength: 543, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(107), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 543, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " several"
 [LLM API] tagBuffer:  several
 [LLM API] Accumulated thinking: 551 chars
 [LLM API] Calling onChunk with: {thinkingLength: 551, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(108), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 551, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 562 chars
 [LLM API] Calling onChunk with: {thinkingLength: 562, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(109), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 562, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " related"
 [LLM API] tagBuffer:  related
 [LLM API] Accumulated thinking: 570 chars
 [LLM API] Calling onChunk with: {thinkingLength: 570, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(110), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 570, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 573 chars
 [LLM API] Calling onChunk with: {thinkingLength: 573, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(111), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 573, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 576 chars
 [LLM API] Calling onChunk with: {thinkingLength: 576, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(112), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 576, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 579 chars
 [LLM API] Calling onChunk with: {thinkingLength: 579, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(113), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 579, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 584 chars
 [LLM API] Calling onChunk with: {thinkingLength: 584, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(114), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 584, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 591 chars
 [LLM API] Calling onChunk with: {thinkingLength: 591, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(115), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 591, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated thinking: 594 chars
 [LLM API] Calling onChunk with: {thinkingLength: 594, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(116), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 594, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated thinking: 599 chars
 [LLM API] Calling onChunk with: {thinkingLength: 599, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(117), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 599, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 605 chars
 [LLM API] Calling onChunk with: {thinkingLength: 605, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(118), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 605, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 606 chars
 [LLM API] Calling onChunk with: {thinkingLength: 606, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(119), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 606, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Looking"
 [LLM API] tagBuffer:  Looking
 [LLM API] Accumulated thinking: 614 chars
 [LLM API] Calling onChunk with: {thinkingLength: 614, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(120), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 614, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated thinking: 617 chars
 [LLM API] Calling onChunk with: {thinkingLength: 617, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(121), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 617, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 621 chars
 [LLM API] Calling onChunk with: {thinkingLength: 621, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(122), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 621, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 628 chars
 [LLM API] Calling onChunk with: {thinkingLength: 628, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(123), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 628, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 636 chars
 [LLM API] Calling onChunk with: {thinkingLength: 636, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(124), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 636, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 637 chars
 [LLM API] Calling onChunk with: {thinkingLength: 637, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(125), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 637, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 639 chars
 [LLM API] Calling onChunk with: {thinkingLength: 639, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(126), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 639, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " can"
 [LLM API] tagBuffer:  can
 [LLM API] Accumulated thinking: 643 chars
 [LLM API] Calling onChunk with: {thinkingLength: 643, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(127), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 643, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 647 chars
 [LLM API] Calling onChunk with: {thinkingLength: 647, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(128), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 647, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated thinking: 653 chars
 [LLM API] Calling onChunk with: {thinkingLength: 653, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(129), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 653, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 657 chars
 [LLM API] Calling onChunk with: {thinkingLength: 657, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(130), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 657, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " multiple"
 [LLM API] tagBuffer:  multiple
 [LLM API] Accumulated thinking: 666 chars
 [LLM API] Calling onChunk with: {thinkingLength: 666, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(131), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 666, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 677 chars
 [LLM API] Calling onChunk with: {thinkingLength: 677, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(132), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 677, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 682 chars
 [LLM API] Calling onChunk with: {thinkingLength: 682, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(133), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 682, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " deal"
 [LLM API] tagBuffer:  deal
 [LLM API] Accumulated thinking: 687 chars
 [LLM API] Calling onChunk with: {thinkingLength: 687, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(134), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 687, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 692 chars
 [LLM API] Calling onChunk with: {thinkingLength: 692, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(135), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 692, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 695 chars
 [LLM API] Calling onChunk with: {thinkingLength: 695, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(136), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 695, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 698 chars
 [LLM API] Calling onChunk with: {thinkingLength: 698, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(137), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 698, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 703 chars
 [LLM API] Calling onChunk with: {thinkingLength: 703, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(138), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 703, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 710 chars
 [LLM API] Calling onChunk with: {thinkingLength: 710, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(139), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 710, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " management"
 [LLM API] tagBuffer:  management
 [LLM API] Accumulated thinking: 721 chars
 [LLM API] Calling onChunk with: {thinkingLength: 721, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(140), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 721, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 722 chars
 [LLM API] Calling onChunk with: {thinkingLength: 722, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(141), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 722, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 726 chars
 [LLM API] Calling onChunk with: {thinkingLength: 726, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(142), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 726, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 729 chars
 [LLM API] Calling onChunk with: {thinkingLength: 729, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(143), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 729, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " identify"
 [LLM API] tagBuffer:  identify
 [LLM API] Accumulated thinking: 738 chars
 [LLM API] Calling onChunk with: {thinkingLength: 738, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(144), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 738, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 742 chars
 [LLM API] Calling onChunk with: {thinkingLength: 742, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(145), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 742, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " key"
 [LLM API] tagBuffer:  key
 [LLM API] Accumulated thinking: 746 chars
 [LLM API] Calling onChunk with: {thinkingLength: 746, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(146), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 746, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 757 chars
 [LLM API] Calling onChunk with: {thinkingLength: 757, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(147), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 757, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 760 chars
 [LLM API] Calling onChunk with: {thinkingLength: 760, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(148), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 760, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 761 chars
 [LLM API] Calling onChunk with: {thinkingLength: 761, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(149), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 761, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 762 chars
 [LLM API] Calling onChunk with: {thinkingLength: 762, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(150), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 762, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 765 chars
 [LLM API] Calling onChunk with: {thinkingLength: 765, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(151), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 765, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 767 chars
 [LLM API] Calling onChunk with: {thinkingLength: 767, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(152), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 767, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 769 chars
 [LLM API] Calling onChunk with: {thinkingLength: 769, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(153), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 769, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 770 chars
 [LLM API] Calling onChunk with: {thinkingLength: 770, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(154), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 770, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 771 chars
 [LLM API] Calling onChunk with: {thinkingLength: 771, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(155), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 771, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 773 chars
 [LLM API] Calling onChunk with: {thinkingLength: 773, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(156), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 773, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 775 chars
 [LLM API] Calling onChunk with: {thinkingLength: 775, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(157), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 775, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 777 chars
 [LLM API] Calling onChunk with: {thinkingLength: 777, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(158), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 777, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 779 chars
 [LLM API] Calling onChunk with: {thinkingLength: 779, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(159), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 779, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 781 chars
 [LLM API] Calling onChunk with: {thinkingLength: 781, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(160), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 781, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "BACKGROUND"
 [LLM API] tagBuffer: BACKGROUND
 [LLM API] Accumulated thinking: 791 chars
 [LLM API] Calling onChunk with: {thinkingLength: 791, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(161), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 791, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " IN"
 [LLM API] tagBuffer:  IN
 [LLM API] Accumulated thinking: 794 chars
 [LLM API] Calling onChunk with: {thinkingLength: 794, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(162), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 794, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "VEST"
 [LLM API] tagBuffer: VEST
 [LLM API] Accumulated thinking: 798 chars
 [LLM API] Calling onChunk with: {thinkingLength: 798, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(163), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 798, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "IG"
 [LLM API] tagBuffer: IG
 [LLM API] Accumulated thinking: 800 chars
 [LLM API] Calling onChunk with: {thinkingLength: 800, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(164), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 800, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ATIONS"
 [LLM API] tagBuffer: ATIONS
 [LLM API] Accumulated thinking: 806 chars
 [LLM API] Calling onChunk with: {thinkingLength: 806, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(165), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 806, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " FOR"
 [LLM API] tagBuffer:  FOR
 [LLM API] Accumulated thinking: 810 chars
 [LLM API] Calling onChunk with: {thinkingLength: 810, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(166), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 810, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " UN"
 [LLM API] tagBuffer:  UN
 [LLM API] Accumulated thinking: 813 chars
 [LLM API] Calling onChunk with: {thinkingLength: 813, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(167), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 813, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ESC"
 [LLM API] tagBuffer: ESC
 [LLM API] Accumulated thinking: 816 chars
 [LLM API] Calling onChunk with: {thinkingLength: 816, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(168), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 816, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ORT"
 [LLM API] tagBuffer: ORT
 [LLM API] Accumulated thinking: 819 chars
 [LLM API] Calling onChunk with: {thinkingLength: 819, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(169), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 819, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ED"
 [LLM API] tagBuffer: ED
 [LLM API] Accumulated thinking: 821 chars
 [LLM API] Calling onChunk with: {thinkingLength: 821, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(170), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 821, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ACCESS"
 [LLM API] tagBuffer:  ACCESS
 [LLM API] Accumulated thinking: 828 chars
 [LLM API] Calling onChunk with: {thinkingLength: 828, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(171), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 828, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 829 chars
 [LLM API] Calling onChunk with: {thinkingLength: 829, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(172), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 829, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 831 chars
 [LLM API] Calling onChunk with: {thinkingLength: 831, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(173), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 831, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Multiple"
 [LLM API] tagBuffer:  Multiple
 [LLM API] Accumulated thinking: 840 chars
 [LLM API] Calling onChunk with: {thinkingLength: 840, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(174), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 840, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revisions"
 [LLM API] tagBuffer:  revisions
 [LLM API] Accumulated thinking: 850 chars
 [LLM API] Calling onChunk with: {thinkingLength: 850, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(175), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 850, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 856 chars
 [LLM API] Calling onChunk with: {thinkingLength: 856, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(176), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 856, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 858 chars
 [LLM API] Calling onChunk with: {thinkingLength: 858, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(177), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 858, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Rev"
 [LLM API] tagBuffer: Rev
 [LLM API] Accumulated thinking: 861 chars
 [LLM API] Calling onChunk with: {thinkingLength: 861, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(178), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 861, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 862 chars
 [LLM API] Calling onChunk with: {thinkingLength: 862, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(179), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 862, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 863 chars
 [LLM API] Calling onChunk with: {thinkingLength: 863, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(180), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 863, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 864 chars
 [LLM API] Calling onChunk with: {thinkingLength: 864, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(181), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 864, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 866 chars
 [LLM API] Calling onChunk with: {thinkingLength: 866, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(182), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 866, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 867 chars
 [LLM API] Calling onChunk with: {thinkingLength: 867, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(183), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 867, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 871 chars
 [LLM API] Calling onChunk with: {thinkingLength: 871, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(184), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 871, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 872 chars
 [LLM API] Calling onChunk with: {thinkingLength: 872, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(185), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 872, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 873 chars
 [LLM API] Calling onChunk with: {thinkingLength: 873, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(186), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 873, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "00"
 [LLM API] tagBuffer: 00
 [LLM API] Accumulated thinking: 875 chars
 [LLM API] Calling onChunk with: {thinkingLength: 875, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(187), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 875, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "8"
 [LLM API] tagBuffer: 8
 [LLM API] Accumulated thinking: 876 chars
 [LLM API] Calling onChunk with: {thinkingLength: 876, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(188), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 876, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ")."
 [LLM API] tagBuffer: ).
 [LLM API] Accumulated thinking: 878 chars
 [LLM API] Calling onChunk with: {thinkingLength: 878, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(189), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 878, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 883 chars
 [LLM API] Calling onChunk with: {thinkingLength: 883, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(190), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 883, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 893 chars
 [LLM API] Calling onChunk with: {thinkingLength: 893, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(191), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 893, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " specifically"
 [LLM API] tagBuffer:  specifically
 [LLM API] Accumulated thinking: 906 chars
 [LLM API] Calling onChunk with: {thinkingLength: 906, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(192), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 906, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " deals"
 [LLM API] tagBuffer:  deals
 [LLM API] Accumulated thinking: 912 chars
 [LLM API] Calling onChunk with: {thinkingLength: 912, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(193), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 912, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 917 chars
 [LLM API] Calling onChunk with: {thinkingLength: 917, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(194), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 917, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated thinking: 928 chars
 [LLM API] Calling onChunk with: {thinkingLength: 928, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(195), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 928, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated thinking: 943 chars
 [LLM API] Calling onChunk with: {thinkingLength: 943, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(196), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 943, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 947 chars
 [LLM API] Calling onChunk with: {thinkingLength: 947, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(197), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 947, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 950 chars
 [LLM API] Calling onChunk with: {thinkingLength: 950, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(198), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 950, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 953 chars
 [LLM API] Calling onChunk with: {thinkingLength: 953, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(199), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 953, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 958 chars
 [LLM API] Calling onChunk with: {thinkingLength: 958, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(200), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 958, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 965 chars
 [LLM API] Calling onChunk with: {thinkingLength: 965, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(201), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 965, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 968 chars
 [LLM API] Calling onChunk with: {thinkingLength: 968, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(202), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 968, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 969 chars
 [LLM API] Calling onChunk with: {thinkingLength: 969, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(203), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 969, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 970 chars
 [LLM API] Calling onChunk with: {thinkingLength: 970, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(204), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 970, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 973 chars
 [LLM API] Calling onChunk with: {thinkingLength: 973, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(205), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 973, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 975 chars
 [LLM API] Calling onChunk with: {thinkingLength: 975, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(206), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 975, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 977 chars
 [LLM API] Calling onChunk with: {thinkingLength: 977, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(207), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 977, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 978 chars
 [LLM API] Calling onChunk with: {thinkingLength: 978, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(208), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 978, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 979 chars
 [LLM API] Calling onChunk with: {thinkingLength: 979, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(209), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 979, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 981 chars
 [LLM API] Calling onChunk with: {thinkingLength: 981, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(210), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 981, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "42"
 [LLM API] tagBuffer: 42
 [LLM API] Accumulated thinking: 983 chars
 [LLM API] Calling onChunk with: {thinkingLength: 983, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(211), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 983, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 985 chars
 [LLM API] Calling onChunk with: {thinkingLength: 985, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(212), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 985, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 987 chars
 [LLM API] Calling onChunk with: {thinkingLength: 987, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(213), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 987, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 989 chars
 [LLM API] Calling onChunk with: {thinkingLength: 989, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(214), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 989, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "PERSON"
 [LLM API] tagBuffer: PERSON
 [LLM API] Accumulated thinking: 995 chars
 [LLM API] Calling onChunk with: {thinkingLength: 995, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(215), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 995, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "NEL"
 [LLM API] tagBuffer: NEL
 [LLM API] Accumulated thinking: 998 chars
 [LLM API] Calling onChunk with: {thinkingLength: 998, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(216), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 998, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ACCESS"
 [LLM API] tagBuffer:  ACCESS
 [LLM API] Accumulated thinking: 1005 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1005, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(217), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1005, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " TO"
 [LLM API] tagBuffer:  TO
 [LLM API] Accumulated thinking: 1008 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1008, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(218), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1008, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " PRO"
 [LLM API] tagBuffer:  PRO
 [LLM API] Accumulated thinking: 1012 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1012, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(219), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1012, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "TECTED"
 [LLM API] tagBuffer: TECTED
 [LLM API] Accumulated thinking: 1018 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1018, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(220), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1018, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " AND"
 [LLM API] tagBuffer:  AND
 [LLM API] Accumulated thinking: 1022 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1022, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(221), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1022, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " V"
 [LLM API] tagBuffer:  V
 [LLM API] Accumulated thinking: 1024 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1024, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(222), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1024, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ITAL"
 [LLM API] tagBuffer: ITAL
 [LLM API] Accumulated thinking: 1028 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1028, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(223), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1028, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ARE"
 [LLM API] tagBuffer:  ARE
 [LLM API] Accumulated thinking: 1032 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1032, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(224), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1032, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AS"
 [LLM API] tagBuffer: AS
 [LLM API] Accumulated thinking: 1034 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1034, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(225), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1034, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1035 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1035, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(226), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1035, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1037 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1037, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(227), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1037, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Multiple"
 [LLM API] tagBuffer:  Multiple
 [LLM API] Accumulated thinking: 1046 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1046, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(228), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1046, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revisions"
 [LLM API] tagBuffer:  revisions
 [LLM API] Accumulated thinking: 1056 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1056, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(229), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1056, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 1062 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1062, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(230), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1062, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1064 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1064, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(231), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1064, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Rev"
 [LLM API] tagBuffer: Rev
 [LLM API] Accumulated thinking: 1067 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1067, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(232), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1067, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1068 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1068, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(233), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1068, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1069 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1069, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(234), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1069, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1070 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1070, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(235), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1070, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "26"
 [LLM API] tagBuffer: 26
 [LLM API] Accumulated thinking: 1072 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1072, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(236), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1072, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1073 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1073, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(237), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1073, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 1077 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1077, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(238), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1077, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1078 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1078, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(239), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1078, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1079 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1079, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(240), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1079, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1080 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1080, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(241), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1080, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "24"
 [LLM API] tagBuffer: 24
 [LLM API] Accumulated thinking: 1082 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1082, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(242), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1082, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1083 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1083, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(243), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1083, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 1087 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1087, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(244), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1087, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1088 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1088, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(245), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1088, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1089 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1089, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(246), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1089, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1090 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1090, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(247), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1090, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "29"
 [LLM API] tagBuffer: 29
 [LLM API] Accumulated thinking: 1092 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1092, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(248), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1092, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ")."
 [LLM API] tagBuffer: ).
 [LLM API] Accumulated thinking: 1094 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1094, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(249), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1094, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 1099 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1099, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(250), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1099, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 1109 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1109, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(251), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1109, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " covers"
 [LLM API] tagBuffer:  covers
 [LLM API] Accumulated thinking: 1116 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1116, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(252), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1116, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " personnel"
 [LLM API] tagBuffer:  personnel
 [LLM API] Accumulated thinking: 1126 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1126, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(253), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1126, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1133 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1133, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(254), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1133, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1136 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1136, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(255), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1136, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " protected"
 [LLM API] tagBuffer:  protected
 [LLM API] Accumulated thinking: 1146 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1146, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(256), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1146, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1150 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1150, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(257), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1150, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " vital"
 [LLM API] tagBuffer:  vital
 [LLM API] Accumulated thinking: 1156 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1156, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(258), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1156, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " areas"
 [LLM API] tagBuffer:  areas
 [LLM API] Accumulated thinking: 1162 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1162, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(259), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1162, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1163 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1163, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(260), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1163, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " including"
 [LLM API] tagBuffer:  including
 [LLM API] Accumulated thinking: 1173 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1173, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(261), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1173, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 1176 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1176, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(262), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1176, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1179 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1179, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(263), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1179, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1184 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1184, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(264), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1184, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1191 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1191, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(265), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1191, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 1194 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1194, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(266), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1194, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 1195 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1195, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(267), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1195, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1196 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1196, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(268), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1196, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1199 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1199, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(269), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1199, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1201 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1201, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(270), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1201, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1203 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1203, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(271), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1203, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1204 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1204, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(272), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1204, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1205 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1205, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(273), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1205, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1207 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1207, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(274), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1207, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "18"
 [LLM API] tagBuffer: 18
 [LLM API] Accumulated thinking: 1209 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1209, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(275), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1209, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1211 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1211, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(276), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1211, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1213 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1213, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(277), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1213, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 1215 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1215, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(278), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1215, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AC"
 [LLM API] tagBuffer: AC
 [LLM API] Accumulated thinking: 1217 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1217, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(279), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1217, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AD"
 [LLM API] tagBuffer: AD
 [LLM API] Accumulated thinking: 1219 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1219, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(280), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1219, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ISSUE"
 [LLM API] tagBuffer:  ISSUE
 [LLM API] Accumulated thinking: 1225 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1225, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(281), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1225, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1226 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1226, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(282), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1226, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1228 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1228, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(283), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1228, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 1232 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1232, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(284), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1232, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1233 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1233, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(285), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1233, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1234 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1234, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(286), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1234, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "00"
 [LLM API] tagBuffer: 00
 [LLM API] Accumulated thinking: 1236 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1236, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(287), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1236, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "6"
 [LLM API] tagBuffer: 6
 [LLM API] Accumulated thinking: 1237 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1237, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(288), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1237, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1238 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1238, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(289), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1238, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 1243 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1243, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(290), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1243, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 1251 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1251, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(291), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1251, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1254 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1254, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(292), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1254, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " deal"
 [LLM API] tagBuffer:  deal
 [LLM API] Accumulated thinking: 1259 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1259, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(293), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1259, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 1264 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1264, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(294), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1264, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1268 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1268, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(295), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1268, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " issue"
 [LLM API] tagBuffer:  issue
 [LLM API] Accumulated thinking: 1274 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1274, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(296), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1274, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " of"
 [LLM API] tagBuffer:  of
 [LLM API] Accumulated thinking: 1277 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1277, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(297), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1277, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " AC"
 [LLM API] tagBuffer:  AC
 [LLM API] Accumulated thinking: 1280 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1280, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(298), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1280, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AD"
 [LLM API] tagBuffer: AD
 [LLM API] Accumulated thinking: 1282 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1282, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(299), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1282, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "s"
 [LLM API] tagBuffer: s
 [LLM API] Accumulated thinking: 1283 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1283, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(300), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1283, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1285 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1285, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(301), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1285, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Authority"
 [LLM API] tagBuffer: Authority
 [LLM API] Accumulated thinking: 1294 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1294, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(302), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1294, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1298 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1298, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(303), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1298, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 1301 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1301, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(304), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1301, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1304 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1304, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(305), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1304, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1309 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1309, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(306), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1309, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1316 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1316, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(307), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1316, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1319 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1319, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(308), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1319, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Protected"
 [LLM API] tagBuffer:  Protected
 [LLM API] Accumulated thinking: 1329 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1329, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(309), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1329, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "/V"
 [LLM API] tagBuffer: /V
 [LLM API] Accumulated thinking: 1331 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1331, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(310), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1331, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ital"
 [LLM API] tagBuffer: ital
 [LLM API] Accumulated thinking: 1335 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1335, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(311), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1335, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Areas"
 [LLM API] tagBuffer:  Areas
 [LLM API] Accumulated thinking: 1341 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1341, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(312), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1341, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ").\n\n"
 [LLM API] tagBuffer: ).


 [LLM API] Accumulated thinking: 1345 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1345, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(313), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1345, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "4"
 [LLM API] tagBuffer: 4
 [LLM API] Accumulated thinking: 1346 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1346, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(314), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1346, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1347 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1347, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(315), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1347, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1350 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1350, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(316), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1350, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1352 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1352, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(317), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1352, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AC"
 [LLM API] tagBuffer: AC
 [LLM API] Accumulated thinking: 1354 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1354, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(318), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1354, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1355 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1355, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(319), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1355, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1356 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1356, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(320), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1356, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1358 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1358, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(321), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1358, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "04"
 [LLM API] tagBuffer: 04
 [LLM API] Accumulated thinking: 1360 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1360, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(322), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1360, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1362 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1362, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(323), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1362, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1364 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1364, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(324), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1364, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 1366 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1366, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(325), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1366, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "PRO"
 [LLM API] tagBuffer: PRO
 [LLM API] Accumulated thinking: 1369 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1369, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(326), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1369, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "TECTED"
 [LLM API] tagBuffer: TECTED
 [LLM API] Accumulated thinking: 1375 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1375, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(327), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1375, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "/V"
 [LLM API] tagBuffer: /V
 [LLM API] Accumulated thinking: 1377 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1377, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(328), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1377, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ITAL"
 [LLM API] tagBuffer: ITAL
 [LLM API] Accumulated thinking: 1381 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1381, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(329), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1381, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " AREA"
 [LLM API] tagBuffer:  AREA
 [LLM API] Accumulated thinking: 1386 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1386, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(330), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1386, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " PERSON"
 [LLM API] tagBuffer:  PERSON
 [LLM API] Accumulated thinking: 1393 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1393, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(331), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1393, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "NEL"
 [LLM API] tagBuffer: NEL
 [LLM API] Accumulated thinking: 1396 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1396, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(332), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1396, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ACCESS"
 [LLM API] tagBuffer:  ACCESS
 [LLM API] Accumulated thinking: 1403 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1403, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(333), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1403, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " CONTROL"
 [LLM API] tagBuffer:  CONTROL
 [LLM API] Accumulated thinking: 1411 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1411, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(334), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1411, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 1412 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1412, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(335), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1412, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1414 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1414, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(336), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1414, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Multiple"
 [LLM API] tagBuffer:  Multiple
 [LLM API] Accumulated thinking: 1423 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1423, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(337), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1423, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revisions"
 [LLM API] tagBuffer:  revisions
 [LLM API] Accumulated thinking: 1433 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1433, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(338), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1433, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 1439 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1439, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(339), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1439, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1441 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1441, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(340), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1441, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Rev"
 [LLM API] tagBuffer: Rev
 [LLM API] Accumulated thinking: 1444 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1444, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(341), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1444, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1445 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1445, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(342), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1445, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1446 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1446, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(343), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1446, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1447 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1447, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(344), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1447, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "15"
 [LLM API] tagBuffer: 15
 [LLM API] Accumulated thinking: 1449 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1449, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(345), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1449, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1450 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1450, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(346), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1450, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Rev"
 [LLM API] tagBuffer:  Rev
 [LLM API] Accumulated thinking: 1454 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1454, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(347), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1454, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1455 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1455, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(348), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1455, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 1456 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1456, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(349), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1456, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1457 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1457, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(350), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1457, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "13"
 [LLM API] tagBuffer: 13
 [LLM API] Accumulated thinking: 1459 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1459, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(351), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1459, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ")."
 [LLM API] tagBuffer: ).
 [LLM API] Accumulated thinking: 1461 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1461, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(352), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1461, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 1466 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1466, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(353), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1466, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " controls"
 [LLM API] tagBuffer:  controls
 [LLM API] Accumulated thinking: 1475 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1475, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(354), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1475, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " both"
 [LLM API] tagBuffer:  both
 [LLM API] Accumulated thinking: 1480 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1480, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(355), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1480, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 1483 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1483, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(356), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1483, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1486 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1486, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(357), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1486, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1491 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1491, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(358), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1491, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1495 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1495, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(359), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1495, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " escorted"
 [LLM API] tagBuffer:  escorted
 [LLM API] Accumulated thinking: 1504 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1504, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(360), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1504, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1511 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1511, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(361), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1511, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 1514 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1514, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(362), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1514, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Looking"
 [LLM API] tagBuffer: Looking
 [LLM API] Accumulated thinking: 1521 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1521, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(363), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1521, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated thinking: 1524 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1524, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(364), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1524, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1528 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1528, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(365), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1528, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 1537 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1537, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(366), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1537, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " titles"
 [LLM API] tagBuffer:  titles
 [LLM API] Accumulated thinking: 1544 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1544, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(367), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1544, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1548 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1548, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(368), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1548, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " content"
 [LLM API] tagBuffer:  content
 [LLM API] Accumulated thinking: 1556 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1556, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(369), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1556, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 1557 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1557, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(370), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1557, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " it"
 [LLM API] tagBuffer:  it
 [LLM API] Accumulated thinking: 1560 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1560, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(371), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1560, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 1568 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1568, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(372), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1568, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 1573 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1573, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(373), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1573, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1577 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1577, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(374), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1577, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " most"
 [LLM API] tagBuffer:  most
 [LLM API] Accumulated thinking: 1582 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1582, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(375), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1582, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 1596 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1596, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(376), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1596, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 1607 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1607, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(377), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1607, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1611 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1611, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(378), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1611, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " managing"
 [LLM API] tagBuffer:  managing
 [LLM API] Accumulated thinking: 1620 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1620, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(379), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1620, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 1623 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1623, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(380), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1623, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1626 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1626, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(381), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1626, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1631 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1631, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(382), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1631, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1638 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1638, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(383), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1638, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 1642 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1642, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(384), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1642, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 1645 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1645, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(385), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1645, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 1646 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1646, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(386), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1646, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1647 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1647, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(387), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1647, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1650 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1650, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(388), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1650, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1652 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1652, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(389), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1652, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1654 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1654, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(390), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1654, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1655 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1655, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(391), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1655, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1656 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1656, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(392), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1656, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1658 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1658, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(393), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1658, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 1660 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1660, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(394), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1660, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1662 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1662, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(395), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1662, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1664 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1664, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(396), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1664, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Background"
 [LLM API] tagBuffer:  Background
 [LLM API] Accumulated thinking: 1675 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1675, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(397), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1675, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated thinking: 1690 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1690, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(398), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1690, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 1694 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1694, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(399), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1694, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 1697 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1697, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(400), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1697, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 1700 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1700, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(401), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1700, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 1705 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1705, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(402), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1705, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1712 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1712, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(403), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1712, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1714 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1714, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(404), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1714, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "this"
 [LLM API] tagBuffer: this
 [LLM API] Accumulated thinking: 1718 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1718, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(405), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1718, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " handles"
 [LLM API] tagBuffer:  handles
 [LLM API] Accumulated thinking: 1726 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1726, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(406), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1726, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1730 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1730, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(407), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1730, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " screening"
 [LLM API] tagBuffer:  screening
 [LLM API] Accumulated thinking: 1740 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1740, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(408), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1740, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " process"
 [LLM API] tagBuffer:  process
 [LLM API] Accumulated thinking: 1748 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1748, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(409), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1748, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ")\n"
 [LLM API] tagBuffer: )

 [LLM API] Accumulated thinking: 1750 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1750, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(410), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1750, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 1751 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1751, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(411), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1751, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1752 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1752, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(412), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1752, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1755 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1755, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(413), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1755, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1757 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1757, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(414), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1757, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 1759 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1759, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(415), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1759, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1760 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1760, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(416), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1760, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1761 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1761, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(417), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1761, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1763 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1763, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(418), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1763, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "42"
 [LLM API] tagBuffer: 42
 [LLM API] Accumulated thinking: 1765 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1765, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(419), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1765, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1767 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1767, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(420), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1767, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1769 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1769, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(421), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1769, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Personnel"
 [LLM API] tagBuffer:  Personnel
 [LLM API] Accumulated thinking: 1779 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1779, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(422), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1779, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1786 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1786, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(423), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1786, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1789 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1789, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(424), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1789, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Protected"
 [LLM API] tagBuffer:  Protected
 [LLM API] Accumulated thinking: 1799 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1799, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(425), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1799, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 1803 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1803, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(426), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1803, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Vital"
 [LLM API] tagBuffer:  Vital
 [LLM API] Accumulated thinking: 1809 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1809, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(427), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1809, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Areas"
 [LLM API] tagBuffer:  Areas
 [LLM API] Accumulated thinking: 1815 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1815, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(428), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1815, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " ("
 [LLM API] tagBuffer:  (
 [LLM API] Accumulated thinking: 1817 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1817, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(429), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1817, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "this"
 [LLM API] tagBuffer: this
 [LLM API] Accumulated thinking: 1821 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1821, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(430), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1821, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " handles"
 [LLM API] tagBuffer:  handles
 [LLM API] Accumulated thinking: 1829 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1829, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(431), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1829, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1833 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1833, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(432), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1833, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 1840 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1840, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(433), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1840, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " control"
 [LLM API] tagBuffer:  control
 [LLM API] Accumulated thinking: 1848 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1848, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(434), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1848, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ")\n"
 [LLM API] tagBuffer: )

 [LLM API] Accumulated thinking: 1850 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1850, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(435), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1850, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 1851 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1851, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(436), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1851, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 1852 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1852, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(437), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1852, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 1855 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1855, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(438), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1855, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 1857 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1857, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(439), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1857, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AC"
 [LLM API] tagBuffer: AC
 [LLM API] Accumulated thinking: 1859 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1859, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(440), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1859, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 1860 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1860, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(441), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1860, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 1861 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1861, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(442), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1861, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 1863 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1863, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(443), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1863, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "04"
 [LLM API] tagBuffer: 04
 [LLM API] Accumulated thinking: 1865 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1865, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(444), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1865, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 1867 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1867, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(445), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1867, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 1869 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1869, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(446), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1869, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Protected"
 [LLM API] tagBuffer:  Protected
 [LLM API] Accumulated thinking: 1879 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1879, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(447), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1879, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "/V"
 [LLM API] tagBuffer: /V
 [LLM API] Accumulated thinking: 1881 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1881, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(448), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1881, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ital"
 [LLM API] tagBuffer: ital
 [LLM API] Accumulated thinking: 1885 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1885, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(449), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1885, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Area"
 [LLM API] tagBuffer:  Area
 [LLM API] Accumulated thinking: 1890 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1890, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(450), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1890, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Personnel"
 [LLM API] tagBuffer:  Personnel
 [LLM API] Accumulated thinking: 1900 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1900, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(451), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1900, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 1907 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1907, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(452), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1907, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Control"
 [LLM API] tagBuffer:  Control
 [LLM API] Accumulated thinking: 1915 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1915, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(453), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1915, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\n\n"
 [LLM API] tagBuffer: 


 [LLM API] Accumulated thinking: 1917 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1917, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(454), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1917, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Let"
 [LLM API] tagBuffer: Let
 [LLM API] Accumulated thinking: 1920 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1920, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(455), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1920, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 1923 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1923, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(456), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1923, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " get"
 [LLM API] tagBuffer:  get
 [LLM API] Accumulated thinking: 1927 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1927, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(457), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1927, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1931 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1931, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(458), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1931, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 1938 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1938, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(459), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1938, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revisions"
 [LLM API] tagBuffer:  revisions
 [LLM API] Accumulated thinking: 1948 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1948, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(460), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1948, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " of"
 [LLM API] tagBuffer:  of
 [LLM API] Accumulated thinking: 1951 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1951, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(461), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1951, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " these"
 [LLM API] tagBuffer:  these
 [LLM API] Accumulated thinking: 1957 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1957, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(462), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1957, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 1968 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1968, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(463), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1968, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 1971 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1971, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(464), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1971, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 1979 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1979, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(465), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1979, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 1983 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1983, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(466), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1983, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " most"
 [LLM API] tagBuffer:  most
 [LLM API] Accumulated thinking: 1988 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1988, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(467), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1988, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " current"
 [LLM API] tagBuffer:  current
 [LLM API] Accumulated thinking: 1996 chars
 [LLM API] Calling onChunk with: {thinkingLength: 1996, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(468), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 1996, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " information"
 [LLM API] tagBuffer:  information
 [LLM API] Accumulated thinking: 2008 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2008, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(469), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2008, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2009 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(470), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "</think>"
 [LLM API] tagBuffer: </think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(471), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(472), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: tool: "{\"action\": \"identifying the key procedur
 [LLM API] FOUND TOOL EVENT, line: tool: "{\"action\": \"identifying the key procedures related to unescorted access\"}"
 [LLM API] Tool string to parse: "{\"action\": \"identifying the key procedures related to unescorted access\"}"
 [LLM API] Parsed tool JSON: {"action": "identifying the key procedures related to unescorted access"}
 [LLM API] Processing line: data: "\n<think>"
 [LLM API] tagBuffer: 

<think>
 [LLM API] Entered <think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(473), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2009, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "I"
 [LLM API] tagBuffer: I
 [LLM API] Accumulated thinking: 2010 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2010, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(474), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2010, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " got"
 [LLM API] tagBuffer:  got
 [LLM API] Accumulated thinking: 2014 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2014, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(475), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2014, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " some"
 [LLM API] tagBuffer:  some
 [LLM API] Accumulated thinking: 2019 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2019, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(476), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2019, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " errors"
 [LLM API] tagBuffer:  errors
 [LLM API] Accumulated thinking: 2026 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2026, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(477), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2026, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " with"
 [LLM API] tagBuffer:  with
 [LLM API] Accumulated thinking: 2031 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2031, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(478), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2031, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2035 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2035, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(479), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2035, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " document"
 [LLM API] tagBuffer:  document
 [LLM API] Accumulated thinking: 2044 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2044, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(480), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2044, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " lookup"
 [LLM API] tagBuffer:  lookup
 [LLM API] Accumulated thinking: 2051 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2051, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(481), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2051, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2052 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2052, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(482), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2052, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " but"
 [LLM API] tagBuffer:  but
 [LLM API] Accumulated thinking: 2056 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2056, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(483), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2056, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2058 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2058, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(484), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2058, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 2064 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2064, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(485), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2064, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2069 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2069, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(486), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2069, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2073 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2073, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(487), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2073, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " latest"
 [LLM API] tagBuffer:  latest
 [LLM API] Accumulated thinking: 2080 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2080, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(488), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2080, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2089 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2089, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(489), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2089, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2093 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2093, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(490), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2093, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 2094 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2094, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(491), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2094, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2096 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2096, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(492), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2096, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2098 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2098, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(493), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2098, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2099 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2099, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(494), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2099, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2100 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2100, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(495), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2100, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2102 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2102, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(496), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2102, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "42"
 [LLM API] tagBuffer: 42
 [LLM API] Accumulated thinking: 2104 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2104, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(497), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2104, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 2107 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2107, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(498), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2107, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " revision"
 [LLM API] tagBuffer:  revision
 [LLM API] Accumulated thinking: 2116 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2116, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(499), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2116, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated thinking: 2117 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2117, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(500), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2117, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "03"
 [LLM API] tagBuffer: 03
 [LLM API] Accumulated thinking: 2119 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2119, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(501), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2119, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "9"
 [LLM API] tagBuffer: 9
 [LLM API] Accumulated thinking: 2120 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2120, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(502), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2120, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2121 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2121, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(503), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2121, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Let"
 [LLM API] tagBuffer:  Let
 [LLM API] Accumulated thinking: 2125 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2125, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(504), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2125, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 2128 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2128, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(505), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2128, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " check"
 [LLM API] tagBuffer:  check
 [LLM API] Accumulated thinking: 2134 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2134, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(506), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2134, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2138 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2138, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(507), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2138, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " specific"
 [LLM API] tagBuffer:  specific
 [LLM API] Accumulated thinking: 2147 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2147, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(508), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2147, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 2158 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2158, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(509), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2158, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2160 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2160, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(510), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2160, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 2166 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2166, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(511), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2166, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " in"
 [LLM API] tagBuffer:  in
 [LLM API] Accumulated thinking: 2169 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2169, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(512), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2169, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2173 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2173, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(513), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2173, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 2180 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2180, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(514), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2180, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2184 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2184, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(515), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2184, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 2192 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2192, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(516), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2192, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 2194 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2194, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(517), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2194, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 2208 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2208, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(518), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2208, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " answer"
 [LLM API] tagBuffer:  answer
 [LLM API] Accumulated thinking: 2215 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2215, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(519), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2215, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2216 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2216, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(520), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2216, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \n\n"
 [LLM API] tagBuffer:  


 [LLM API] Accumulated thinking: 2219 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2219, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(521), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2219, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "From"
 [LLM API] tagBuffer: From
 [LLM API] Accumulated thinking: 2223 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2223, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(522), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2223, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2227 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2227, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(523), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2227, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 2234 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2234, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(524), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2234, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 2242 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2242, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(525), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2242, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2243 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2243, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(526), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2243, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2245 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2245, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(527), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2245, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " can"
 [LLM API] tagBuffer:  can
 [LLM API] Accumulated thinking: 2249 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2249, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(528), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2249, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " see"
 [LLM API] tagBuffer:  see
 [LLM API] Accumulated thinking: 2253 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2253, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(529), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2253, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2258 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2258, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(530), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2258, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated thinking: 2264 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2264, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(531), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2264, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated thinking: 2268 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2268, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(532), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2268, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " several"
 [LLM API] tagBuffer:  several
 [LLM API] Accumulated thinking: 2276 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2276, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(533), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2276, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated thinking: 2287 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2287, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(534), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2287, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated thinking: 2292 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2292, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(535), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2292, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " manage"
 [LLM API] tagBuffer:  manage
 [LLM API] Accumulated thinking: 2299 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2299, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(536), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2299, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2302 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2302, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(537), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2302, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2305 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2305, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(538), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2305, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2310 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2310, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(539), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2310, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2317 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2317, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(540), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2317, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated thinking: 2320 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2320, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(541), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2320, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated thinking: 2325 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2325, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(542), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2325, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated thinking: 2331 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2331, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(543), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2331, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated thinking: 2334 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2334, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(544), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2334, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated thinking: 2335 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2335, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(545), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2335, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2336 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2336, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(546), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2336, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 2339 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2339, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(547), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2339, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2341 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2341, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(548), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2341, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2343 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2343, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(549), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2343, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2344 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2344, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(550), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2344, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2345 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2345, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(551), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2345, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2347 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2347, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(552), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2347, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated thinking: 2349 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2349, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(553), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2349, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 2351 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2351, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(554), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2351, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2353 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2353, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(555), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2353, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 2355 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2355, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(556), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2355, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Background"
 [LLM API] tagBuffer: Background
 [LLM API] Accumulated thinking: 2365 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2365, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(557), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2365, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated thinking: 2380 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2380, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(558), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2380, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2384 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2384, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(559), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2384, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated thinking: 2387 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2387, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(560), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2387, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2390 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2390, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(561), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2390, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2395 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2395, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(562), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2395, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 2402 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2402, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(563), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2402, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 2403 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2403, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(564), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2403, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2405 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2405, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(565), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2405, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 2410 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2410, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(566), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2410, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 2418 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2418, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(567), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2418, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2421 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2421, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(568), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2421, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " be"
 [LLM API] tagBuffer:  be
 [LLM API] Accumulated thinking: 2424 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2424, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(569), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2424, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2428 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2428, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(570), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2428, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " primary"
 [LLM API] tagBuffer:  primary
 [LLM API] Accumulated thinking: 2436 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2436, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(571), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2436, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " procedure"
 [LLM API] tagBuffer:  procedure
 [LLM API] Accumulated thinking: 2446 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2446, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(572), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2446, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2450 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2450, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(573), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2450, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " managing"
 [LLM API] tagBuffer:  managing
 [LLM API] Accumulated thinking: 2459 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2459, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(574), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2459, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2463 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2463, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(575), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2463, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated thinking: 2474 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2474, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(576), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2474, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " investigation"
 [LLM API] tagBuffer:  investigation
 [LLM API] Accumulated thinking: 2488 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2488, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(577), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2488, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " process"
 [LLM API] tagBuffer:  process
 [LLM API] Accumulated thinking: 2496 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2496, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(578), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2496, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated thinking: 2500 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2500, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(579), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2500, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2503 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2503, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(580), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2503, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2506 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2506, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(581), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2506, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2511 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2511, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(582), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2511, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2518 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2518, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(583), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2518, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 2521 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2521, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(584), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2521, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "2"
 [LLM API] tagBuffer: 2
 [LLM API] Accumulated thinking: 2522 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2522, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(585), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2522, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2523 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2523, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(586), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2523, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 2526 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2526, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(587), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2526, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2528 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2528, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(588), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2528, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated thinking: 2530 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2530, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(589), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2530, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2531 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2531, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(590), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2531, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2532 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2532, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(591), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2532, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2534 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2534, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(592), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2534, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "42"
 [LLM API] tagBuffer: 42
 [LLM API] Accumulated thinking: 2536 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2536, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(593), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2536, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 2538 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2538, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(594), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2538, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2540 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2540, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(595), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2540, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 2542 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2542, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(596), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2542, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Person"
 [LLM API] tagBuffer: Person
 [LLM API] Accumulated thinking: 2548 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2548, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(597), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2548, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "nel"
 [LLM API] tagBuffer: nel
 [LLM API] Accumulated thinking: 2551 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2551, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(598), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2551, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 2558 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2558, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(599), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2558, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2561 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2561, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(600), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2561, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Protected"
 [LLM API] tagBuffer:  Protected
 [LLM API] Accumulated thinking: 2571 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2571, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(601), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2571, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2575 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2575, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(602), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2575, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Vital"
 [LLM API] tagBuffer:  Vital
 [LLM API] Accumulated thinking: 2581 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2581, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(603), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2581, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Areas"
 [LLM API] tagBuffer:  Areas
 [LLM API] Accumulated thinking: 2587 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2587, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(604), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2587, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 2588 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2588, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(605), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2588, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2590 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2590, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(606), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2590, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 2595 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2595, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(607), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2595, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " appears"
 [LLM API] tagBuffer:  appears
 [LLM API] Accumulated thinking: 2603 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2603, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(608), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2603, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2606 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2606, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(609), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2606, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " manage"
 [LLM API] tagBuffer:  manage
 [LLM API] Accumulated thinking: 2613 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2613, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(610), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2613, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " how"
 [LLM API] tagBuffer:  how
 [LLM API] Accumulated thinking: 2617 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2617, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(611), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2617, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " personnel"
 [LLM API] tagBuffer:  personnel
 [LLM API] Accumulated thinking: 2627 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2627, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(612), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2627, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2634 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2634, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(613), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2634, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " is"
 [LLM API] tagBuffer:  is
 [LLM API] Accumulated thinking: 2637 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2637, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(614), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2637, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " controlled"
 [LLM API] tagBuffer:  controlled
 [LLM API] Accumulated thinking: 2648 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2648, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(615), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2648, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " into"
 [LLM API] tagBuffer:  into
 [LLM API] Accumulated thinking: 2653 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2653, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(616), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2653, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " protected"
 [LLM API] tagBuffer:  protected
 [LLM API] Accumulated thinking: 2663 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2663, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(617), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2663, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2667 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2667, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(618), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2667, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " vital"
 [LLM API] tagBuffer:  vital
 [LLM API] Accumulated thinking: 2673 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2673, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(619), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2673, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " areas"
 [LLM API] tagBuffer:  areas
 [LLM API] Accumulated thinking: 2679 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2679, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(620), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2679, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated thinking: 2680 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2680, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(621), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2680, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " including"
 [LLM API] tagBuffer:  including
 [LLM API] Accumulated thinking: 2690 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2690, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(622), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2690, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2693 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2693, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(623), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2693, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2696 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2696, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(624), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2696, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2701 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2701, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(625), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2701, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2708 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2708, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(626), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2708, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 2711 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2711, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(627), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2711, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated thinking: 2712 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2712, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(628), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2712, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated thinking: 2713 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2713, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(629), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2713, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated thinking: 2716 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2716, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(630), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2716, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated thinking: 2718 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2718, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(631), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2718, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "AC"
 [LLM API] tagBuffer: AC
 [LLM API] Accumulated thinking: 2720 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2720, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(632), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2720, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated thinking: 2721 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2721, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(633), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2721, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated thinking: 2722 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2722, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(634), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2722, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated thinking: 2724 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2724, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(635), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2724, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "04"
 [LLM API] tagBuffer: 04
 [LLM API] Accumulated thinking: 2726 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2726, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(636), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2726, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated thinking: 2728 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2728, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(637), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2728, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2730 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2730, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(638), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2730, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated thinking: 2732 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2732, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(639), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2732, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Protected"
 [LLM API] tagBuffer: Protected
 [LLM API] Accumulated thinking: 2741 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2741, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(640), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2741, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "/V"
 [LLM API] tagBuffer: /V
 [LLM API] Accumulated thinking: 2743 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2743, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(641), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2743, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "ital"
 [LLM API] tagBuffer: ital
 [LLM API] Accumulated thinking: 2747 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2747, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(642), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2747, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Area"
 [LLM API] tagBuffer:  Area
 [LLM API] Accumulated thinking: 2752 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2752, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(643), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2752, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Personnel"
 [LLM API] tagBuffer:  Personnel
 [LLM API] Accumulated thinking: 2762 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2762, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(644), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2762, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated thinking: 2769 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2769, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(645), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2769, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " Control"
 [LLM API] tagBuffer:  Control
 [LLM API] Accumulated thinking: 2777 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2777, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(646), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2777, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated thinking: 2778 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2778, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(647), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2778, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated thinking: 2780 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2780, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(648), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2780, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " This"
 [LLM API] tagBuffer:  This
 [LLM API] Accumulated thinking: 2785 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2785, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(649), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2785, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " controls"
 [LLM API] tagBuffer:  controls
 [LLM API] Accumulated thinking: 2794 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2794, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(650), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2794, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " both"
 [LLM API] tagBuffer:  both
 [LLM API] Accumulated thinking: 2799 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2799, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(651), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2799, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated thinking: 2802 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2802, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(652), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2802, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated thinking: 2805 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2805, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(653), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2805, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated thinking: 2810 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2810, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(654), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2810, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2814 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2814, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(655), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2814, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " escorted"
 [LLM API] tagBuffer:  escorted
 [LLM API] Accumulated thinking: 2823 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2823, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(656), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2823, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated thinking: 2830 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2830, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(657), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2830, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated thinking: 2833 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2833, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(658), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2833, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " protected"
 [LLM API] tagBuffer:  protected
 [LLM API] Accumulated thinking: 2843 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2843, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(659), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2843, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated thinking: 2847 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2847, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(660), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2847, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " vital"
 [LLM API] tagBuffer:  vital
 [LLM API] Accumulated thinking: 2853 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2853, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(661), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2853, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " areas"
 [LLM API] tagBuffer:  areas
 [LLM API] Accumulated thinking: 2859 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2859, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(662), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2859, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".\n\n"
 [LLM API] tagBuffer: .


 [LLM API] Accumulated thinking: 2862 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2862, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(663), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2862, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "Let"
 [LLM API] tagBuffer: Let
 [LLM API] Accumulated thinking: 2865 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2865, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(664), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2865, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " me"
 [LLM API] tagBuffer:  me
 [LLM API] Accumulated thinking: 2868 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2868, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(665), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2868, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " provide"
 [LLM API] tagBuffer:  provide
 [LLM API] Accumulated thinking: 2876 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2876, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(666), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2876, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " a"
 [LLM API] tagBuffer:  a
 [LLM API] Accumulated thinking: 2878 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2878, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(667), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2878, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " comprehensive"
 [LLM API] tagBuffer:  comprehensive
 [LLM API] Accumulated thinking: 2892 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2892, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(668), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2892, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " answer"
 [LLM API] tagBuffer:  answer
 [LLM API] Accumulated thinking: 2899 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2899, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(669), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2899, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " based"
 [LLM API] tagBuffer:  based
 [LLM API] Accumulated thinking: 2905 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2905, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(670), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2905, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated thinking: 2908 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2908, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(671), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2908, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated thinking: 2912 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2912, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(672), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2912, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated thinking: 2919 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2919, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(673), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2919, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated thinking: 2927 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2927, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(674), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2927, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " I"
 [LLM API] tagBuffer:  I
 [LLM API] Accumulated thinking: 2929 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2929, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(675), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2929, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: " found"
 [LLM API] tagBuffer:  found
 [LLM API] Accumulated thinking: 2935 chars
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(676), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ".</think>"
 [LLM API] tagBuffer: .</think>
 [LLM API] Exited </think> tag, remaining buffer: 
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(677), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Keeping potential partial tag in buffer: 

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(678), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "<"
 [LLM API] tagBuffer: 
<
 [LLM API] Keeping potential partial tag in buffer: 
<
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(679), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: "response"
 [LLM API] tagBuffer: 
<response
 [LLM API] Keeping potential partial tag in buffer: 
<response
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [ChatService] Streaming callback invoked {chunks: Array(680), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 0}
 [LLM API] Processing line: data: ">\n"
 [LLM API] tagBuffer: 
<response>

 [LLM API] Entered <response> tag, remaining buffer: 

 [LLM API] Accumulated response: 1 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 1}
 [ChatService] Streaming callback invoked {chunks: Array(681), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 1}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 1 first 100 chars: 

 [MarkdownContent] Content changed: 

 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [LLM API] Processing line: data: "Based"
 [LLM API] tagBuffer: Based
 [LLM API] Accumulated response: 6 chars content: Based
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 6}
 [ChatService] Streaming callback invoked {chunks: Array(682), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 6}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 6 first 100 chars: 
Based
 [MarkdownContent] Content changed: 
Based
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated response: 9 chars content:  on
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 9}
 [ChatService] Streaming callback invoked {chunks: Array(683), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 9}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 9 first 100 chars: 
Based on
 [LLM API] Processing line: data: " the"
 [LLM API] tagBuffer:  the
 [LLM API] Accumulated response: 13 chars content:  the
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 13}
 [ChatService] Streaming callback invoked {chunks: Array(684), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 13}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 13 first 100 chars: 
Based on the
 [MarkdownContent] Content changed: 
Based on the
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " search"
 [LLM API] tagBuffer:  search
 [LLM API] Accumulated response: 20 chars content:  search
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 20}
 [ChatService] Streaming callback invoked {chunks: Array(685), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 20}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 20 first 100 chars: 
Based on the search
 [LLM API] Processing line: data: " results"
 [LLM API] tagBuffer:  results
 [LLM API] Accumulated response: 28 chars content:  results
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 28}
 [ChatService] Streaming callback invoked {chunks: Array(686), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 28}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 28 first 100 chars: 
Based on the search results
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 29 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 29}
 [ChatService] Streaming callback invoked {chunks: Array(687), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 29}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 29 first 100 chars: 
Based on the search results,
 [MarkdownContent] Content changed: 
Based on the search results,
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " there"
 [LLM API] tagBuffer:  there
 [LLM API] Accumulated response: 35 chars content:  there
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 35}
 [ChatService] Streaming callback invoked {chunks: Array(688), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 35}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 35 first 100 chars: 
Based on the search results, there
 [LLM API] Processing line: data: " are"
 [LLM API] tagBuffer:  are
 [LLM API] Accumulated response: 39 chars content:  are
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 39}
 [ChatService] Streaming callback invoked {chunks: Array(689), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 39}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 39 first 100 chars: 
Based on the search results, there are
 [LLM API] Processing line: data: " several"
 [LLM API] tagBuffer:  several
 [LLM API] Accumulated response: 47 chars content:  several
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 47}
 [ChatService] Streaming callback invoked {chunks: Array(690), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 47}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 47 first 100 chars: 
Based on the search results, there are several
 [MarkdownContent] Content changed: 
Based on the search results, there are several
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated response: 58 chars content:  procedures
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 58}
 [ChatService] Streaming callback invoked {chunks: Array(691), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 58}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 58 first 100 chars: 
Based on the search results, there are several procedures
 [LLM API] Processing line: data: " that"
 [LLM API] tagBuffer:  that
 [LLM API] Accumulated response: 63 chars content:  that
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 63}
 [ChatService] Streaming callback invoked {chunks: Array(692), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 63}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 63 first 100 chars: 
Based on the search results, there are several procedures that
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " manage"
 [LLM API] tagBuffer:  manage
 [LLM API] Accumulated response: 70 chars content:  manage
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 70}
 [ChatService] Streaming callback invoked {chunks: Array(693), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 70}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 70 first 100 chars: 
Based on the search results, there are several procedures that manage
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 73 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 73}
 [ChatService] Streaming callback invoked {chunks: Array(694), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 73}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 73 first 100 chars: 
Based on the search results, there are several procedures that manage un
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage un
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 76 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 76}
 [ChatService] Streaming callback invoked {chunks: Array(695), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 76}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 76 first 100 chars: 
Based on the search results, there are several procedures that manage unesc
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 81 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 81}
 [ChatService] Streaming callback invoked {chunks: Array(696), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 81}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 81 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 88 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 88}
 [ChatService] Streaming callback invoked {chunks: Array(697), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 88}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 88 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access
 [LLM API] Processing line: data: " at"
 [LLM API] tagBuffer:  at
 [LLM API] Accumulated response: 91 chars content:  at
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 91}
 [ChatService] Streaming callback invoked {chunks: Array(698), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 91}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 91 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Palo"
 [LLM API] tagBuffer:  Palo
 [LLM API] Accumulated response: 96 chars content:  Palo
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 96}
 [ChatService] Streaming callback invoked {chunks: Array(699), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 96}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 96 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Verde"
 [LLM API] tagBuffer:  Verde
 [LLM API] Accumulated response: 102 chars content:  Verde
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 102}
 [ChatService] Streaming callback invoked {chunks: Array(700), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 102}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 102 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Nuclear"
 [LLM API] tagBuffer:  Nuclear
 [LLM API] Accumulated response: 110 chars content:  Nuclear
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 110}
 [ChatService] Streaming callback invoked {chunks: Array(701), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 110}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 110 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Generating"
 [LLM API] tagBuffer:  Generating
 [LLM API] Accumulated response: 121 chars content:  Generating
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 121}
 [ChatService] Streaming callback invoked {chunks: Array(702), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 121}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 121 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Station"
 [LLM API] tagBuffer:  Station
 [LLM API] Accumulated response: 129 chars content:  Station
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 129}
 [ChatService] Streaming callback invoked {chunks: Array(703), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 129}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 129 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 130 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 130}
 [ChatService] Streaming callback invoked {chunks: Array(704), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 130}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 130 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " The"
 [LLM API] tagBuffer:  The
 [LLM API] Accumulated response: 134 chars content:  The
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 134}
 [ChatService] Streaming callback invoked {chunks: Array(705), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 134}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 134 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " primary"
 [LLM API] tagBuffer:  primary
 [LLM API] Accumulated response: 142 chars content:  primary
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 142}
 [ChatService] Streaming callback invoked {chunks: Array(706), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 142}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 142 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " procedures"
 [LLM API] tagBuffer:  procedures
 [LLM API] Accumulated response: 153 chars content:  procedures
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 153}
 [ChatService] Streaming callback invoked {chunks: Array(707), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 153}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 153 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " include"
 [LLM API] tagBuffer:  include
 [LLM API] Accumulated response: 161 chars content:  include
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 161}
 [ChatService] Streaming callback invoked {chunks: Array(708), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 161}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 161 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 164 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 164}
 [ChatService] Streaming callback invoked {chunks: Array(709), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 164}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 164 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "##"
 [LLM API] tagBuffer: ##
 [LLM API] Accumulated response: 166 chars content: ##
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 166}
 [ChatService] Streaming callback invoked {chunks: Array(710), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 166}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 166 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Main"
 [LLM API] tagBuffer:  Main
 [LLM API] Accumulated response: 171 chars content:  Main
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 171}
 [ChatService] Streaming callback invoked {chunks: Array(711), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 171}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 171 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Procedures"
 [LLM API] tagBuffer:  Procedures
 [LLM API] Accumulated response: 182 chars content:  Procedures
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 182}
 [ChatService] Streaming callback invoked {chunks: Array(712), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 182}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 182 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Managing"
 [LLM API] tagBuffer:  Managing
 [LLM API] Accumulated response: 191 chars content:  Managing
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 191}
 [ChatService] Streaming callback invoked {chunks: Array(713), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 191}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 191 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 194 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 194}
 [ChatService] Streaming callback invoked {chunks: Array(714), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 194}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 194 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 197 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 197}
 [ChatService] Streaming callback invoked {chunks: Array(715), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 197}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 197 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 202 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 202}
 [ChatService] Streaming callback invoked {chunks: Array(716), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 202}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 202 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 209 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 209}
 [ChatService] Streaming callback invoked {chunks: Array(717), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 209}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 209 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ":\n\n"
 [LLM API] tagBuffer: :


 [LLM API] Accumulated response: 212 chars content: :


 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 212}
 [ChatService] Streaming callback invoked {chunks: Array(718), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 212}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 212 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**"
 [LLM API] tagBuffer: **
 [LLM API] Accumulated response: 214 chars content: **
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 214}
 [ChatService] Streaming callback invoked {chunks: Array(719), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 214}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 214 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "1"
 [LLM API] tagBuffer: 1
 [LLM API] Accumulated response: 215 chars content: 1
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 215}
 [ChatService] Streaming callback invoked {chunks: Array(720), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 215}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 215 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "."
 [LLM API] tagBuffer: .
 [LLM API] Accumulated response: 216 chars content: .
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 216}
 [ChatService] Streaming callback invoked {chunks: Array(721), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 216}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 216 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " "
 [LLM API] tagBuffer:  
 [LLM API] Accumulated response: 217 chars content:  
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 217}
 [ChatService] Streaming callback invoked {chunks: Array(722), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 217}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 217 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "20"
 [LLM API] tagBuffer: 20
 [LLM API] Accumulated response: 219 chars content: 20
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 219}
 [ChatService] Streaming callback invoked {chunks: Array(723), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 219}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 219 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "DP"
 [LLM API] tagBuffer: DP
 [LLM API] Accumulated response: 221 chars content: DP
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 221}
 [ChatService] Streaming callback invoked {chunks: Array(724), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 221}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 221 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 222 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 222}
 [ChatService] Streaming callback invoked {chunks: Array(725), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 222}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 222 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 223 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 223}
 [ChatService] Streaming callback invoked {chunks: Array(726), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 223}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 223 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "SK"
 [LLM API] tagBuffer: SK
 [LLM API] Accumulated response: 225 chars content: SK
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 225}
 [ChatService] Streaming callback invoked {chunks: Array(727), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 225}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 225 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated response: 227 chars content: 11
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 227}
 [ChatService] Streaming callback invoked {chunks: Array(728), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 227}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 227 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " -"
 [LLM API] tagBuffer:  -
 [LLM API] Accumulated response: 229 chars content:  -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 229}
 [ChatService] Streaming callback invoked {chunks: Array(729), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 229}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 229 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " \""
 [LLM API] tagBuffer:  "
 [LLM API] Accumulated response: 231 chars content:  "
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 231}
 [ChatService] Streaming callback invoked {chunks: Array(730), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 231}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 231 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Background"
 [LLM API] tagBuffer: Background
 [LLM API] Accumulated response: 241 chars content: Background
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 241}
 [ChatService] Streaming callback invoked {chunks: Array(731), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 241}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 241 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Investigations"
 [LLM API] tagBuffer:  Investigations
 [LLM API] Accumulated response: 256 chars content:  Investigations
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 256}
 [ChatService] Streaming callback invoked {chunks: Array(732), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 256}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 256 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " for"
 [LLM API] tagBuffer:  for
 [LLM API] Accumulated response: 260 chars content:  for
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 260}
 [ChatService] Streaming callback invoked {chunks: Array(733), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 260}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 260 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Un"
 [LLM API] tagBuffer:  Un
 [LLM API] Accumulated response: 263 chars content:  Un
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 263}
 [ChatService] Streaming callback invoked {chunks: Array(734), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 263}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 263 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 266 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 266}
 [ChatService] Streaming callback invoked {chunks: Array(735), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 266}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 266 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 271 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 271}
 [ChatService] Streaming callback invoked {chunks: Array(736), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 271}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 271 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 278 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 278}
 [ChatService] Streaming callback invoked {chunks: Array(737), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 278}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 278 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "\""
 [LLM API] tagBuffer: "
 [LLM API] Accumulated response: 279 chars content: "
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 279}
 [ChatService] Streaming callback invoked {chunks: Array(738), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 279}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 279 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**\n"
 [LLM API] tagBuffer: **

 [LLM API] Accumulated response: 282 chars content: **

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 282}
 [ChatService] Streaming callback invoked {chunks: Array(739), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 282}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 282 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 283 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 283}
 [ChatService] Streaming callback invoked {chunks: Array(740), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 283}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 283 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 286 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 286}
 [ChatService] Streaming callback invoked {chunks: Array(741), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 286}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 286 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "Purpose"
 [LLM API] tagBuffer: Purpose
 [LLM API] Accumulated response: 293 chars content: Purpose
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 293}
 [ChatService] Streaming callback invoked {chunks: Array(742), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 293}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 293 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**:"
 [LLM API] tagBuffer: **:
 [LLM API] Accumulated response: 296 chars content: **:
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 296}
 [ChatService] Streaming callback invoked {chunks: Array(743), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 296}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 296 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Pres"
 [LLM API] tagBuffer:  Pres
 [LLM API] Accumulated response: 301 chars content:  Pres
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 301}
 [ChatService] Streaming callback invoked {chunks: Array(744), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 301}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 301 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "cribes"
 [LLM API] tagBuffer: cribes
 [LLM API] Accumulated response: 307 chars content: cribes
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 307}
 [ChatService] Streaming callback invoked {chunks: Array(745), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 307}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 307 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " methods"
 [LLM API] tagBuffer:  methods
 [LLM API] Accumulated response: 315 chars content:  methods
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 315}
 [ChatService] Streaming callback invoked {chunks: Array(746), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 315}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 315 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " of"
 [LLM API] tagBuffer:  of
 [LLM API] Accumulated response: 318 chars content:  of
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 318}
 [ChatService] Streaming callback invoked {chunks: Array(747), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 318}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 318 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " conducting"
 [LLM API] tagBuffer:  conducting
 [LLM API] Accumulated response: 329 chars content:  conducting
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 329}
 [ChatService] Streaming callback invoked {chunks: Array(748), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 329}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 329 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 340 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 340}
 [ChatService] Streaming callback invoked {chunks: Array(749), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 340}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 340 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated response: 355 chars content:  investigations
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 355}
 [ChatService] Streaming callback invoked {chunks: Array(750), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 355}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 355 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 359 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 359}
 [ChatService] Streaming callback invoked {chunks: Array(751), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 359}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 359 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " collecting"
 [LLM API] tagBuffer:  collecting
 [LLM API] Accumulated response: 370 chars content:  collecting
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 370}
 [ChatService] Streaming callback invoked {chunks: Array(752), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 370}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 370 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " data"
 [LLM API] tagBuffer:  data
 [LLM API] Accumulated response: 375 chars content:  data
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 375}
 [ChatService] Streaming callback invoked {chunks: Array(753), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 375}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 375 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated response: 378 chars content:  on
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 378}
 [ChatService] Streaming callback invoked {chunks: Array(754), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 378}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 378 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " individuals"
 [LLM API] tagBuffer:  individuals
 [LLM API] Accumulated response: 390 chars content:  individuals
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 390}
 [ChatService] Streaming callback invoked {chunks: Array(755), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 390}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 390 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " seeking"
 [LLM API] tagBuffer:  seeking
 [LLM API] Accumulated response: 398 chars content:  seeking
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 398}
 [ChatService] Streaming callback invoked {chunks: Array(756), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 398}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 398 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 401 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 401}
 [ChatService] Streaming callback invoked {chunks: Array(757), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 401}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 401 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 404 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 404}
 [ChatService] Streaming callback invoked {chunks: Array(758), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 404}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 404 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 409 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 409}
 [ChatService] Streaming callback invoked {chunks: Array(759), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 409}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 409 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 416 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 416}
 [ChatService] Streaming callback invoked {chunks: Array(760), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 416}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 416 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated response: 419 chars content:  to
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 419}
 [ChatService] Streaming callback invoked {chunks: Array(761), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 419}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 419 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " PV"
 [LLM API] tagBuffer:  PV
 [LLM API] Accumulated response: 422 chars content:  PV
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 422}
 [ChatService] Streaming callback invoked {chunks: Array(762), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 422}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 422 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "NG"
 [LLM API] tagBuffer: NG
 [LLM API] Accumulated response: 424 chars content: NG
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 424}
 [ChatService] Streaming callback invoked {chunks: Array(763), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 424}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 424 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "S"
 [LLM API] tagBuffer: S
 [LLM API] Accumulated response: 425 chars content: S
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 425}
 [ChatService] Streaming callback invoked {chunks: Array(764), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 425}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 425 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 426 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 426}
 [ChatService] Streaming callback invoked {chunks: Array(765), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 426}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 426 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 427 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 427}
 [ChatService] Streaming callback invoked {chunks: Array(766), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 427}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 427 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 430 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 430}
 [ChatService] Streaming callback invoked {chunks: Array(767), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 430}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 430 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "Respons"
 [LLM API] tagBuffer: Respons
 [LLM API] Accumulated response: 437 chars content: Respons
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 437}
 [ChatService] Streaming callback invoked {chunks: Array(768), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 437}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 437 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "ibilities"
 [LLM API] tagBuffer: ibilities
 [LLM API] Accumulated response: 446 chars content: ibilities
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 446}
 [ChatService] Streaming callback invoked {chunks: Array(769), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 446}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 446 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**:"
 [LLM API] tagBuffer: **:
 [LLM API] Accumulated response: 449 chars content: **:
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 449}
 [ChatService] Streaming callback invoked {chunks: Array(770), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 449}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 449 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Director"
 [LLM API] tagBuffer:  Director
 [LLM API] Accumulated response: 458 chars content:  Director
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 458}
 [ChatService] Streaming callback invoked {chunks: Array(771), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 458}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 458 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 459 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 459}
 [ChatService] Streaming callback invoked {chunks: Array(772), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 459}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 459 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Emergency"
 [LLM API] tagBuffer:  Emergency
 [LLM API] Accumulated response: 469 chars content:  Emergency
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 469}
 [ChatService] Streaming callback invoked {chunks: Array(773), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 469}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 469 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Services"
 [LLM API] tagBuffer:  Services
 [LLM API] Accumulated response: 478 chars content:  Services
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 478}
 [ChatService] Streaming callback invoked {chunks: Array(774), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 478}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 478 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Division"
 [LLM API] tagBuffer:  Division
 [LLM API] Accumulated response: 487 chars content:  Division
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 487}
 [ChatService] Streaming callback invoked {chunks: Array(775), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 487}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 487 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ";"
 [LLM API] tagBuffer: ;
 [LLM API] Accumulated response: 488 chars content: ;
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 488}
 [ChatService] Streaming callback invoked {chunks: Array(776), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 488}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 488 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 495 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 495}
 [ChatService] Streaming callback invoked {chunks: Array(777), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 495}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 495 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Control"
 [LLM API] tagBuffer:  Control
 [LLM API] Accumulated response: 503 chars content:  Control
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 503}
 [ChatService] Streaming callback invoked {chunks: Array(778), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 503}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 503 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Section"
 [LLM API] tagBuffer:  Section
 [LLM API] Accumulated response: 511 chars content:  Section
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 511}
 [ChatService] Streaming callback invoked {chunks: Array(779), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 511}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 511 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Leader"
 [LLM API] tagBuffer:  Leader
 [LLM API] Accumulated response: 518 chars content:  Leader
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 518}
 [ChatService] Streaming callback invoked {chunks: Array(780), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 518}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 518 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ";"
 [LLM API] tagBuffer: ;
 [LLM API] Accumulated response: 519 chars content: ;
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 519}
 [ChatService] Streaming callback invoked {chunks: Array(781), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 519}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 519 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Access"
 [LLM API] tagBuffer:  Access
 [LLM API] Accumulated response: 526 chars content:  Access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 526}
 [ChatService] Streaming callback invoked {chunks: Array(782), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 526}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 526 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Control"
 [LLM API] tagBuffer:  Control
 [LLM API] Accumulated response: 534 chars content:  Control
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 534}
 [ChatService] Streaming callback invoked {chunks: Array(783), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 534}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 534 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " Personnel"
 [LLM API] tagBuffer:  Personnel
 [LLM API] Accumulated response: 544 chars content:  Personnel
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 544}
 [ChatService] Streaming callback invoked {chunks: Array(784), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 544}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 544 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 545 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 545}
 [ChatService] Streaming callback invoked {chunks: Array(785), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 545}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 545 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 546 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 546}
 [ChatService] Streaming callback invoked {chunks: Array(786), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 546}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 546 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 549 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 549}
 [ChatService] Streaming callback invoked {chunks: Array(787), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 549}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 549 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Scope"
 [LLM API] tagBuffer: Scope
 [LLM API] Accumulated response: 554 chars content: Scope
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 554}
 [ChatService] Streaming callback invoked {chunks: Array(788), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 554}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 554 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "**:"
 [LLM API] tagBuffer: **:
 [LLM API] Accumulated response: 557 chars content: **:
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 557}
 [ChatService] Streaming callback invoked {chunks: Array(789), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 557}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 557 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Applies"
 [LLM API] tagBuffer:  Applies
 [LLM API] Accumulated response: 565 chars content:  Applies
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 565}
 [ChatService] Streaming callback invoked {chunks: Array(790), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 565}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 565 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated response: 568 chars content:  to
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 568}
 [ChatService] Streaming callback invoked {chunks: Array(791), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 568}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 568 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " all"
 [LLM API] tagBuffer:  all
 [LLM API] Accumulated response: 572 chars content:  all
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 572}
 [ChatService] Streaming callback invoked {chunks: Array(792), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 572}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 572 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " personnel"
 [LLM API] tagBuffer:  personnel
 [LLM API] Accumulated response: 582 chars content:  personnel
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 582}
 [ChatService] Streaming callback invoked {chunks: Array(793), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 582}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 582 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " assigned"
 [LLM API] tagBuffer:  assigned
 [LLM API] Accumulated response: 591 chars content:  assigned
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 591}
 [ChatService] Streaming callback invoked {chunks: Array(794), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 591}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 591 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " to"
 [LLM API] tagBuffer:  to
 [LLM API] Accumulated response: 594 chars content:  to
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 594}
 [ChatService] Streaming callback invoked {chunks: Array(795), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 594}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 594 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " processing"
 [LLM API] tagBuffer:  processing
 [LLM API] Accumulated response: 605 chars content:  processing
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 605}
 [ChatService] Streaming callback invoked {chunks: Array(796), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 605}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 605 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 616 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 616}
 [ChatService] Streaming callback invoked {chunks: Array(797), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 616}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 616 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " investigation"
 [LLM API] tagBuffer:  investigation
 [LLM API] Accumulated response: 630 chars content:  investigation
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 630}
 [ChatService] Streaming callback invoked {chunks: Array(798), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 630}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 630 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " data"
 [LLM API] tagBuffer:  data
 [LLM API] Accumulated response: 635 chars content:  data
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 635}
 [ChatService] Streaming callback invoked {chunks: Array(799), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 635}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 635 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " on"
 [LLM API] tagBuffer:  on
 [LLM API] Accumulated response: 638 chars content:  on
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 638}
 [ChatService] Streaming callback invoked {chunks: Array(800), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 638}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 638 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " individuals"
 [LLM API] tagBuffer:  individuals
 [LLM API] Accumulated response: 650 chars content:  individuals
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 650}
 [ChatService] Streaming callback invoked {chunks: Array(801), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 650}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 650 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " seeking"
 [LLM API] tagBuffer:  seeking
 [LLM API] Accumulated response: 658 chars content:  seeking
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 658}
 [ChatService] Streaming callback invoked {chunks: Array(802), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 658}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 658 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " un"
 [LLM API] tagBuffer:  un
 [LLM API] Accumulated response: 661 chars content:  un
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 661}
 [ChatService] Streaming callback invoked {chunks: Array(803), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 661}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 661 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "esc"
 [LLM API] tagBuffer: esc
 [LLM API] Accumulated response: 664 chars content: esc
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 664}
 [ChatService] Streaming callback invoked {chunks: Array(804), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 664}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 664 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "orted"
 [LLM API] tagBuffer: orted
 [LLM API] Accumulated response: 669 chars content: orted
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 669}
 [ChatService] Streaming callback invoked {chunks: Array(805), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 669}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 669 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 676 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 676}
 [ChatService] Streaming callback invoked {chunks: Array(806), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 676}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 676 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "\n"
 [LLM API] tagBuffer: 

 [LLM API] Accumulated response: 677 chars content: 

 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 677}
 [ChatService] Streaming callback invoked {chunks: Array(807), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 677}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 677 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 678 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 678}
 [ChatService] Streaming callback invoked {chunks: Array(808), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 678}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 678 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " **"
 [LLM API] tagBuffer:  **
 [LLM API] Accumulated response: 681 chars content:  **
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 681}
 [ChatService] Streaming callback invoked {chunks: Array(809), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 681}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 681 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Content"
 [LLM API] tagBuffer: Content
 [LLM API] Accumulated response: 688 chars content: Content
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 688}
 [ChatService] Streaming callback invoked {chunks: Array(810), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 688}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 688 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "**:"
 [LLM API] tagBuffer: **:
 [LLM API] Accumulated response: 691 chars content: **:
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 691}
 [ChatService] Streaming callback invoked {chunks: Array(811), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 691}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 691 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " Covers"
 [LLM API] tagBuffer:  Covers
 [LLM API] Accumulated response: 698 chars content:  Covers
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 698}
 [ChatService] Streaming callback invoked {chunks: Array(812), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 698}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 698 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " five"
 [LLM API] tagBuffer:  five
 [LLM API] Accumulated response: 703 chars content:  five
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 703}
 [ChatService] Streaming callback invoked {chunks: Array(813), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 703}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 703 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "-year"
 [LLM API] tagBuffer: -year
 [LLM API] Accumulated response: 708 chars content: -year
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 708}
 [ChatService] Streaming callback invoked {chunks: Array(814), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 708}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 708 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " background"
 [LLM API] tagBuffer:  background
 [LLM API] Accumulated response: 719 chars content:  background
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 719}
 [ChatService] Streaming callback invoked {chunks: Array(815), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 719}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 719 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " investigations"
 [LLM API] tagBuffer:  investigations
 [LLM API] Accumulated response: 734 chars content:  investigations
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 734}
 [ChatService] Streaming callback invoked {chunks: Array(816), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 734}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 734 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 735 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 735}
 [ChatService] Streaming callback invoked {chunks: Array(817), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 735}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 735 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " employment"
 [LLM API] tagBuffer:  employment
 [LLM API] Accumulated response: 746 chars content:  employment
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 746}
 [ChatService] Streaming callback invoked {chunks: Array(818), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 746}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 746 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " ver"
 [LLM API] tagBuffer:  ver
 [LLM API] Accumulated response: 750 chars content:  ver
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 750}
 [ChatService] Streaming callback invoked {chunks: Array(819), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 750}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 750 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "ifications"
 [LLM API] tagBuffer: ifications
 [LLM API] Accumulated response: 760 chars content: ifications
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 760}
 [ChatService] Streaming callback invoked {chunks: Array(820), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 760}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 760 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 761 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 761}
 [ChatService] Streaming callback invoked {chunks: Array(821), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 761}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 761 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " credit"
 [LLM API] tagBuffer:  credit
 [LLM API] Accumulated response: 768 chars content:  credit
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 768}
 [ChatService] Streaming callback invoked {chunks: Array(822), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 768}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 768 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " checks"
 [LLM API] tagBuffer:  checks
 [LLM API] Accumulated response: 775 chars content:  checks
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 775}
 [ChatService] Streaming callback invoked {chunks: Array(823), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 775}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 775 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 776 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 776}
 [ChatService] Streaming callback invoked {chunks: Array(824), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 776}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 776 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " criminal"
 [LLM API] tagBuffer:  criminal
 [LLM API] Accumulated response: 785 chars content:  criminal
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 785}
 [ChatService] Streaming callback invoked {chunks: Array(825), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 785}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 785 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " history"
 [LLM API] tagBuffer:  history
 [LLM API] Accumulated response: 793 chars content:  history
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 793}
 [ChatService] Streaming callback invoked {chunks: Array(826), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 793}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 793 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 794 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 794}
 [ChatService] Streaming callback invoked {chunks: Array(827), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 794}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 794 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " character"
 [LLM API] tagBuffer:  character
 [LLM API] Accumulated response: 804 chars content:  character
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 804}
 [ChatService] Streaming callback invoked {chunks: Array(828), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 804}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 804 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 808 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 808}
 [ChatService] Streaming callback invoked {chunks: Array(829), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 808}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 808 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " reputation"
 [LLM API] tagBuffer:  reputation
 [LLM API] Accumulated response: 819 chars content:  reputation
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 819}
 [ChatService] Streaming callback invoked {chunks: Array(830), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 819}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 819 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " evaluations"
 [LLM API] tagBuffer:  evaluations
 [LLM API] Accumulated response: 831 chars content:  evaluations
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 831}
 [ChatService] Streaming callback invoked {chunks: Array(831), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 831}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 831 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: ","
 [LLM API] tagBuffer: ,
 [LLM API] Accumulated response: 832 chars content: ,
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 832}
 [ChatService] Streaming callback invoked {chunks: Array(832), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 832}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 832 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " and"
 [LLM API] tagBuffer:  and
 [LLM API] Accumulated response: 836 chars content:  and
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 836}
 [ChatService] Streaming callback invoked {chunks: Array(833), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 836}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 836 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " temporary"
 [LLM API] tagBuffer:  temporary
 [LLM API] Accumulated response: 846 chars content:  temporary
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 846}
 [ChatService] Streaming callback invoked {chunks: Array(834), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 846}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 846 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " access"
 [LLM API] tagBuffer:  access
 [LLM API] Accumulated response: 853 chars content:  access
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 853}
 [ChatService] Streaming callback invoked {chunks: Array(835), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 853}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 853 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " author"
 [LLM API] tagBuffer:  author
 [LLM API] Accumulated response: 860 chars content:  author
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 860}
 [ChatService] Streaming callback invoked {chunks: Array(836), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 860}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 860 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "izations"
 [LLM API] tagBuffer: izations
 [LLM API] Accumulated response: 868 chars content: izations
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 868}
 [ChatService] Streaming callback invoked {chunks: Array(837), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 868}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 868 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: " ["
 [LLM API] tagBuffer:  [
 [LLM API] Accumulated response: 870 chars content:  [
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 870}
 [ChatService] Streaming callback invoked {chunks: Array(838), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 870}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 870 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Source"
 [LLM API] tagBuffer: Source
 [LLM API] Accumulated response: 876 chars content: Source
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 876}
 [ChatService] Streaming callback invoked {chunks: Array(839), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 876}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 876 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 877 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 877}
 [ChatService] Streaming callback invoked {chunks: Array(840), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 877}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 877 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " {"
 [LLM API] tagBuffer:  {
 [LLM API] Accumulated response: 879 chars content:  {
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 879}
 [ChatService] Streaming callback invoked {chunks: Array(841), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 879}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 879 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "C"
 [LLM API] tagBuffer: C
 [LLM API] Accumulated response: 880 chars content: C
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 880}
 [ChatService] Streaming callback invoked {chunks: Array(842), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 880}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 880 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "38"
 [LLM API] tagBuffer: 38
 [LLM API] Accumulated response: 882 chars content: 38
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 882}
 [ChatService] Streaming callback invoked {chunks: Array(843), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 882}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 882 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "7"
 [LLM API] tagBuffer: 7
 [LLM API] Accumulated response: 883 chars content: 7
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 883}
 [ChatService] Streaming callback invoked {chunks: Array(844), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 883}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 883 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "180"
 [LLM API] tagBuffer: 180
 [LLM API] Accumulated response: 886 chars content: 180
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 886}
 [ChatService] Streaming callback invoked {chunks: Array(845), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 886}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 886 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "F"
 [LLM API] tagBuffer: F
 [LLM API] Accumulated response: 887 chars content: F
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 887}
 [ChatService] Streaming callback invoked {chunks: Array(846), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 887}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 887 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 888 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 888}
 [ChatService] Streaming callback invoked {chunks: Array(847), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 888}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 888 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "5"
 [LLM API] tagBuffer: 5
 [LLM API] Accumulated response: 889 chars content: 5
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 889}
 [ChatService] Streaming callback invoked {chunks: Array(848), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 889}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 889 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "A"
 [LLM API] tagBuffer: A
 [LLM API] Accumulated response: 890 chars content: A
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 890}
 [ChatService] Streaming callback invoked {chunks: Array(849), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 890}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 890 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "45"
 [LLM API] tagBuffer: 45
 [LLM API] Accumulated response: 892 chars content: 45
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 892}
 [ChatService] Streaming callback invoked {chunks: Array(850), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 892}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 892 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 893 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 893}
 [ChatService] Streaming callback invoked {chunks: Array(851), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 893}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 893 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "4"
 [LLM API] tagBuffer: 4
 [LLM API] Accumulated response: 894 chars content: 4
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 894}
 [ChatService] Streaming callback invoked {chunks: Array(852), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 894}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 894 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "B"
 [LLM API] tagBuffer: B
 [LLM API] Accumulated response: 895 chars content: B
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 895}
 [ChatService] Streaming callback invoked {chunks: Array(853), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 895}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 895 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "5"
 [LLM API] tagBuffer: 5
 [LLM API] Accumulated response: 896 chars content: 5
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 896}
 [ChatService] Streaming callback invoked {chunks: Array(854), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 896}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 896 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "A"
 [LLM API] tagBuffer: A
 [LLM API] Accumulated response: 897 chars content: A
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 897}
 [ChatService] Streaming callback invoked {chunks: Array(855), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 897}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 897 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-"
 [LLM API] tagBuffer: -
 [LLM API] Accumulated response: 898 chars content: -
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 898}
 [ChatService] Streaming callback invoked {chunks: Array(856), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 898}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 898 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "96"
 [LLM API] tagBuffer: 96
 [LLM API] Accumulated response: 900 chars content: 96
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 900}
 [ChatService] Streaming callback invoked {chunks: Array(857), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 900}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 900 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "C"
 [LLM API] tagBuffer: C
 [LLM API] Accumulated response: 901 chars content: C
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 901}
 [ChatService] Streaming callback invoked {chunks: Array(858), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 901}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 901 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "3"
 [LLM API] tagBuffer: 3
 [LLM API] Accumulated response: 902 chars content: 3
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 902}
 [ChatService] Streaming callback invoked {chunks: Array(859), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 902}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 902 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "-C"
 [LLM API] tagBuffer: -C
 [LLM API] Accumulated response: 904 chars content: -C
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 904}
 [ChatService] Streaming callback invoked {chunks: Array(860), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 904}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 904 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "26"
 [LLM API] tagBuffer: 26
 [LLM API] Accumulated response: 906 chars content: 26
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 906}
 [ChatService] Streaming callback invoked {chunks: Array(861), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 906}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 906 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "F"
 [LLM API] tagBuffer: F
 [LLM API] Accumulated response: 907 chars content: F
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 907}
 [ChatService] Streaming callback invoked {chunks: Array(862), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 907}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 907 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "0"
 [LLM API] tagBuffer: 0
 [LLM API] Accumulated response: 908 chars content: 0
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 908}
 [ChatService] Streaming callback invoked {chunks: Array(863), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 908}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 908 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "D"
 [LLM API] tagBuffer: D
 [LLM API] Accumulated response: 909 chars content: D
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 909}
 [ChatService] Streaming callback invoked {chunks: Array(864), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 909}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 909 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "11"
 [LLM API] tagBuffer: 11
 [LLM API] Accumulated response: 911 chars content: 11
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 911}
 [ChatService] Streaming callback invoked {chunks: Array(865), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 911}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 911 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "D"
 [LLM API] tagBuffer: D
 [LLM API] Accumulated response: 912 chars content: D
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 912}
 [ChatService] Streaming callback invoked {chunks: Array(866), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 912}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 912 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "6"
 [LLM API] tagBuffer: 6
 [LLM API] Accumulated response: 913 chars content: 6
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 913}
 [ChatService] Streaming callback invoked {chunks: Array(867), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 913}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 913 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "CB"
 [LLM API] tagBuffer: CB
 [LLM API] Accumulated response: 915 chars content: CB
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 915}
 [ChatService] Streaming callback invoked {chunks: Array(868), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 915}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 915 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "}"
 [LLM API] tagBuffer: }
 [LLM API] Accumulated response: 916 chars content: }
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 916}
 [ChatService] Streaming callback invoked {chunks: Array(869), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 916}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 916 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "]["
 [LLM API] tagBuffer: ][
 [LLM API] Accumulated response: 918 chars content: ][
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 918}
 [ChatService] Streaming callback invoked {chunks: Array(870), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 918}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 918 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "Source"
 [LLM API] tagBuffer: Source
 [LLM API] Accumulated response: 924 chars content: Source
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 924}
 [ChatService] Streaming callback invoked {chunks: Array(871), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 924}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 924 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: ":"
 [LLM API] tagBuffer: :
 [LLM API] Accumulated response: 925 chars content: :
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 925}
 [ChatService] Streaming callback invoked {chunks: Array(872), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 925}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 925 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: " {"
 [LLM API] tagBuffer:  {
 [LLM API] Accumulated response: 927 chars content:  {
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 927}
 [ChatService] Streaming callback invoked {chunks: Array(873), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 927}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 927 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "9"
 [LLM API] tagBuffer: 9
 [LLM API] Accumulated response: 928 chars content: 9
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 928}
 [ChatService] Streaming callback invoked {chunks: Array(874), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 928}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 928 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] Content changed: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [MarkdownContent] RAG docs: 0
 [MarkdownContent] Citation metadata: undefined
 [MarkdownContent] Citation metadata keys: 0
 [MarkdownContent] Found 0 citation links to attach handlers to
 [LLM API] Processing line: data: "B"
 [LLM API] tagBuffer: B
 [LLM API] Accumulated response: 929 chars content: B
 [LLM API] Calling onChunk with: {thinkingLength: 2935, toolingLength: 0, responseLength: 929}
 [ChatService] Streaming callback invoked {chunks: Array(875), currentChunk: {…}, isComplete: false, error: undefined, messageId: undefined}
 [ChatService] Processing chunk: {thinkingLength: 2935, toolingLength: 0, responseLength: 929}
 [ChatService] updateMessageConent called, messageId: 2jjdx3fba content length: 929 first 100 chars: 
Based on the search results, there are several procedures that manage unescorted access at Palo Ver
 [LLM API] Processing line: data: "38"
